{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url = 'https://www.youtube.com/watch?v=kaLkj-6GDb4&list=PLbiZ073RgtF035gZ-NMQu8SppTmrTk-x9&ab_channel=%E8%BD%BB%E6%9D%BE%E5%AD%A6python'\n",
    "url = 'https://www.tutorialspoint.com/beautiful_soup/beautiful_soup_quick_guide.htm'\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " <!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<title>Beautiful Soup - Quick Guide</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"width=device-width,initial-scale=1.0,user-scalable=yes, maximum-scale=6\" name=\"viewport\"/>\n",
       "<meta content=\"Guide, Quick, Soup, Beautiful, HTML, Python, CSS, SQL, JavaScript, Perl, PHP, Java, C, C++, C#, jQuery, Bootstrap, Colors, XML, MySQL, Icons, NodeJS, React, Graphics, Angular, R, AI, Git, Machine Learning, Data Science, Tutorials, Programming, Data Structure, Algorithms, Web Development, Training, Learning, Quiz, Exercises, Courses, References, Computer Science, Management, Finance, Examples, Articles, Demos, Tips, Website\" name=\"Keywords\"/>\n",
       "<meta content=\"Beautiful Soup - Quick Guide - In today's world, we have tons of unstructured data/information (mostly web data) available freely. Sometimes the freely available data is easy to read and sometimes not. No matter how your data is available, web scraping is very useful tool to transform unstructured data into structured data that i\" name=\"Description\"/>\n",
       "<meta content=\"https://www.tutorialspoint.com/images/tp_logo_436.png\" property=\"og:image\"/>\n",
       "<meta content=\"image/png\" property=\"og:image:type\"/>\n",
       "<meta content=\"436\" property=\"og:image:width\"/>\n",
       "<meta content=\"228\" property=\"og:image:height\"/>\n",
       "<meta content=\"Beautiful Soup - Quick Guide\" property=\"og:title\"/>\n",
       "<meta content=\"Beautiful Soup - Quick Guide - In today's world, we have tons of unstructured data/information (mostly web data) available freely. Sometimes the freely available data is easy to read and sometimes not. No matter how your data is available, web scraping is very useful tool to transform unstructured data into structured data that i\" property=\"og:description\"/>\n",
       "<link href=\"https://www.tutorialspoint.com/images/favicon.ico\" rel=\"icon\"/>\n",
       "<link href=\"/images/apple-touch-icon.png\" rel=\"apple-touch-icon\" sizes=\"180x180\"/>\n",
       "<link href=\"/images/favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/>\n",
       "<link href=\"/images/favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/>\n",
       "<link href=\"https://fonts.googleapis.com\" rel=\"preconnect\"/>\n",
       "<link crossorigin=\"\" href=\"https://fonts.gstatic.com\" rel=\"preconnect\"/>\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Nunito:wght@400;500;600;700&amp;family=Lato:wght@400;700&amp;family=Poppins:wght@400;500;600&amp;family=Raleway:wght@500&amp;display=swap\" rel=\"stylesheet\"/>\n",
       "<link href=\"/static/css/lib-style.css?v182.922\" media=\"screen, print\" rel=\"stylesheet\"/>\n",
       "<link href=\"https://www.tutorialspoint.com/beautiful_soup/beautiful_soup_quick_guide.htm\" rel=\"canonical\"/>\n",
       "<script async=\"\" src=\"//www.ezojs.com/ezoic/sa.min.js\"></script>\n",
       "<script>\n",
       "  window.ezstandalone = window.ezstandalone || {};\n",
       "  ezstandalone.cmd = ezstandalone.cmd || [];\n",
       "</script>\n",
       "<style>\n",
       "/* Remove Ezoic Logo Line */\n",
       ".tutorial-toc .reportline{\n",
       "   display:none !important;\n",
       "}\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<button class=\"icon-button--inverted scroll-to-top-button\" title=\"Scroll Up\">\n",
       "<svg fill=\"none\" height=\"24\" style=\"rotate: 180deg\" viewbox=\"0 0 12 12\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M9.52246 5.06689L6.08496 8.50439L2.64746 5.06689\" stroke=\"#fff\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path></svg>\n",
       "</button>\n",
       "<div class=\"accent-header\">\n",
       "<nav class=\"accent-nav library-accent-nav\">\n",
       "<div class=\"accent-nav__content\">\n",
       "<ul class=\"accent-nav__list\">\n",
       "<li class=\"accent-nav__item\">\n",
       "<a class=\"accent-nav__link\" href=\"/index.htm\" title=\"Home\"><i class=\"fa-sharp fa-light fa-home\"></i> Home</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item topMenu_block\">\n",
       "<a class=\"accent-nav__link\" href=\"/tutorialslibrary.htm\"><svg fill=\"none\" height=\"14\" viewbox=\"0 0 15 14\" width=\"15\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M13.7675 0.781179C13.4295 0.49851 13.0333 0.293734 12.6072 0.18139C12.1811 0.0690464 11.7355 0.0518903 11.3021 0.13114L9.00377 0.548464C8.47315 0.645905 7.9907 0.918899 7.63394 1.32358C7.27624 0.9182 6.79241 0.645144 6.2605 0.548464L3.96582 0.13114C3.53235 0.0518209 3.08675 0.0687522 2.66056 0.180735C2.23436 0.292719 1.83799 0.497016 1.4995 0.779166C1.16101 1.06132 0.888682 1.41442 0.701786 1.81349C0.51489 2.21255 0.417998 2.64782 0.417969 3.08848L0.417969 9.57865C0.418003 10.2827 0.665102 10.9644 1.11619 11.5049C1.56729 12.0455 2.19376 12.4106 2.88643 12.5366L6.6664 13.2239C7.30618 13.3402 7.96169 13.3402 8.60148 13.2239L12.3844 12.5366C13.0766 12.4099 13.7023 12.0446 14.1528 11.5041C14.6033 10.9636 14.85 10.2823 14.8499 9.57865V3.08848C14.8502 2.64798 14.7533 2.21283 14.5662 1.81402C14.3792 1.41521 14.1064 1.06256 13.7675 0.781179ZM7.03261 12.0651C6.98209 12.0579 6.93158 12.0495 6.88107 12.0405L3.10171 11.3538C2.68605 11.2781 2.31011 11.059 2.03945 10.7346C1.76879 10.4102 1.62057 10.0011 1.62063 9.57865V3.08848C1.62063 2.61004 1.81069 2.15118 2.14901 1.81287C2.48732 1.47456 2.94617 1.28449 3.42462 1.28449C3.53352 1.28475 3.64218 1.29461 3.74934 1.31396L6.04642 1.73489C6.3228 1.78546 6.57275 1.93121 6.75289 2.14683C6.93303 2.36245 7.032 2.63433 7.03261 2.9153V12.0651ZM13.6472 9.57865C13.6473 10.0011 13.4991 10.4102 13.2284 10.7346C12.9578 11.059 12.5818 11.2781 12.1662 11.3538L8.3868 12.0405C8.33629 12.0495 8.28578 12.0579 8.23527 12.0651V2.9153C8.23522 2.63364 8.33404 2.36091 8.51448 2.14464C8.69492 1.92837 8.94554 1.7823 9.22265 1.73188L11.5203 1.31095C11.7805 1.26361 12.048 1.27406 12.3037 1.34156C12.5594 1.40907 12.7972 1.53198 13.0001 1.70158C13.203 1.87118 13.3662 2.08333 13.478 2.323C13.5899 2.56268 13.6476 2.82401 13.6472 3.08848V9.57865Z\" fill=\"white\"></path></svg> Library</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item\">\n",
       "<a class=\"accent-nav__link\" href=\"/codingground.htm\" title=\"Coding Ground\"><i class=\"fa-sharp fa-light fa-code\"></i>Coding Ground</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item\">\n",
       "<a class=\"accent-nav__link\" href=\"/job_search.php\" title=\"Jobs\"><i class=\"fa-sharp fa-light fa-suitcase\"></i> Jobs</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item\">\n",
       "<a class=\"accent-nav__link\" href=\"/whiteboard.htm\" title=\"Whiteboard\"><i class=\"fa-sharp fa-light fa-chalkboard\"></i>Whiteboard</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item\">\n",
       "<a class=\"accent-nav__link\" href=\"/online_dev_tools.htm\" title=\"Tools\"><i class=\"fa-sharp fa-light fa-tools\"></i>Tools</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item\">\n",
       "<a class=\"accent-nav__link\" href=\"/articles/index.php\" title=\"Articles\"><i class=\"fa-sharp fa-light fa-pen-to-square\"></i>Articles</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item\">\n",
       "<a class=\"accent-nav__link\" href=\"https://www.tutorialspoint.com/articles/write-and-earn.php\"><i class=\"fa-sharp fa-light fa-money-check-dollar-pen\"></i>Write &amp; Earn</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item\">\n",
       "<a class=\"accent-nav__link\" href=\"https://www.tutorialspoint.com/videos/index.php\"><svg height=\"15\" viewbox=\"0 0 448 512\" width=\"15\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M349.4 44.6c5.9-13.7 1.5-29.7-10.6-38.5s-28.6-8-39.9 1.8l-256 224c-10 8.8-13.6 22.9-8.9 35.3S50.7 288 64 288l111.5 0L98.6 467.4c-5.9 13.7-1.5 29.7 10.6 38.5s28.6 8 39.9-1.8l256-224c10-8.8 13.6-22.9 8.9-35.3s-16.6-20.7-30-20.7l-111.5 0L349.4 44.6z\" fill=\"#fff\"></path></svg> Shorts</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item topMenu_block\">\n",
       "<a class=\"accent-nav__link\" href=\"https://www.tutorialspoint.com/market/index.asp\"><svg fill=\"#000\" height=\"14\" viewbox=\"0 0 512 512\" width=\"15\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M464 256A208 208 0 1 0 48 256a208 208 0 1 0 416 0zM0 256a256 256 0 1 1 512 0A256 256 0 1 1 0 256zM188.3 147.1c7.6-4.2 16.8-4.1 24.3 .5l144 88c7.1 4.4 11.5 12.1 11.5 20.5s-4.4 16.1-11.5 20.5l-144 88c-7.4 4.5-16.7 4.7-24.3 .5s-12.3-12.2-12.3-20.9V168c0-8.7 4.7-16.7 12.3-20.9z\"></path></svg> Courses</a>\n",
       "</li>\n",
       "<li class=\"accent-nav__item topMenu_block\">\n",
       "<a class=\"accent-nav__link\" href=\"https://www.tutorialspoint.com/latest/certifications\" title=\"Certifications\"><svg class=\"\" height=\"14\" viewbox=\"0 0 512 512\" width=\"15\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M497.9 97.98L414.02 14.1c-9-9-21.19-14.1-33.89-14.1H176c-26.5.1-47.99 21.6-47.99 48.09V165.7c-5.97 0-11.94-1.68-24.13-5.03-1.7-.46-3.36-.66-4.96-.66-5.56 0-10.43 2.5-13.66 5.79-17.95 18.26-17.07 17.77-41.7 24.5-6.7 1.81-11.97 7.21-13.78 14.07-6.47 24.67-6.09 24.16-24.02 42.32-4.95 5.04-6.9 12.48-5.08 19.43 6.56 24.38 6.52 24.39 0 48.76-1.82 6.95.12 14.4 5.08 19.45 18 18.15 17.58 17.79 24.02 42.29 1.8 6.88 7.08 12.27 13.78 14.1 1.8.48 2.92.8 4.46 1.21V496c0 5.55 2.87 10.69 7.59 13.61 4.66 2.91 10.59 3.16 15.56.7l56.84-28.42 56.84 28.42c2.25 1.12 4.72 1.69 7.16 1.69h272c26.49 0 47.99-21.5 47.99-47.99V131.97c0-12.69-5.1-24.99-14.1-33.99zM384.03 32.59c2.8.7 5.3 2.1 7.4 4.2l83.88 83.88c2.1 2.1 3.5 4.6 4.2 7.4h-95.48V32.59zM33.28 316.68c5.7-22.3 5.7-30.23.01-52.39 15.65-16.2 19.56-22.98 25.63-45.06 21.57-6.13 28.06-9.92 43.88-25.69 9.8 2.62 16.82 4.15 25.21 4.15 8.28 0 15.25-1.49 25.19-4.16 15.56 15.51 22.49 19.58 43.86 25.68 5.98 21.95 9.71 28.63 25.65 45.07-5.77 22.45-5.76 30 0 52.4-15.62 16.17-19.55 22.96-25.61 44.96-14.63 3.92-24 7.36-37.25 19.36-9.94-4.53-20.78-6.89-31.85-6.89s-21.9 2.36-31.85 6.9c-13.18-11.88-22.56-15.34-37.23-19.33-5.97-21.89-9.72-28.57-25.64-45zm101.89 133.01c-4.5-2.25-9.81-2.25-14.31 0l-40.84 20.42V409.9c.12.12.19.17.31.29 3.75 3.82 8.68 5.79 13.64 5.79 3.5 0 7.02-.98 10.16-2.97 7.25-4.59 15.56-6.88 23.87-6.88s16.62 2.29 23.87 6.86c3.16 2.02 6.68 3.01 10.17 3.01 4.96 0 9.87-1.99 13.63-5.79.13-.13.21-.18.34-.32v60.22l-40.84-20.42zm344.84 14.32c0 8.8-7.2 16-16 16h-256V391.9c1.54-.4 2.65-.71 4.44-1.19 6.7-1.82 11.97-7.22 13.77-14.08 6.47-24.68 6.09-24.16 24.03-42.32 4.95-5.04 6.9-12.49 5.07-19.44-6.53-24.33-6.55-24.34 0-48.76 1.83-6.95-.12-14.4-5.07-19.45-18-18.15-17.58-17.79-24.03-42.29-1.8-6.87-7.07-12.27-13.75-14.09-24.23-6.57-23.89-6.23-41.72-24.52-2.94-2.97-6.78-4.52-10.74-5.16V48.09c0-8.8 7.2-16.09 16-16.09h176.03v104.07c0 13.3 10.7 23.93 24 23.93h103.98v304.01z\"></path></svg> Certifications</a>\n",
       "</li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"flex-group\" style=\"gap:0rem;\">\n",
       "<button aria-expanded=\"false\" class=\"accent-nav__toggle\"> Menu <svg fill=\"none\" height=\"8\" viewbox=\"0 0 13 8\" width=\"13\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M1.12891 1.33594L6.40994 6.62214L11.691 1.33594\" stroke=\"white\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.79664\"></path></svg></button>\n",
       "<button aria-expanded=\"false\" class=\"nav-toggle text-white\"> Categories <svg fill=\"none\" height=\"8\" viewbox=\"0 0 13 8\" width=\"13\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M1.12891 1.33594L6.40994 6.62214L11.691 1.33594\" stroke=\"white\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.79664\"></path></svg></button>\n",
       "</div>\n",
       "<a class=\"accent-nav__login-button\" href=\"https://www.tutorialspoint.com/market/login.jsp\"> Login</a>\n",
       "<ul class=\"flex-group accent-nav__right-list\">\n",
       "<li class=\"accent-nav__item\">\n",
       "<button aria-expanded=\"false\" class=\"accent-nav__button theme-toggle\" href=\"/index.htm\"><span class=\"sr-only\">Switch theme</span></button>\n",
       "</li>\n",
       "<li>\n",
       "<a class=\"accent-nav__social-link\" href=\"https://www.facebook.com/tutorialspointindia\" rel=\"nofollow\" target=\"_blank\"><i class=\"fa-sharp fa-light fa-brands fa-facebook\"></i></a>\n",
       "</li>\n",
       "<li>\n",
       "<a class=\"accent-nav__social-link\" href=\"https://www.instagram.com/tutorialspoint_/\" rel=\"nofollow\" target=\"_blank\"><i class=\"fa-sharp fa-light fa-brands fa-instagram\"></i></a>\n",
       "</li>\n",
       "<li>\n",
       "<a class=\"accent-nav__social-link\" href=\"https://twitter.com/tutorialspoint\" rel=\"nofollow\" target=\"_blank\"><i class=\"fa-sharp fa-light fa-brands fa-x-twitter\"></i></a>\n",
       "</li>\n",
       "<li>\n",
       "<a class=\"accent-nav__social-link\" href=\"https://www.youtube.com/channel/UCVLbzhxVTiTLiVKeGV7WEBg\" rel=\"nofollow\" target=\"_blank\"><i class=\"fa-sharp fa-light fa-brands fa-youtube\"></i></a>\n",
       "</li>\n",
       "<li>\n",
       "<a class=\"accent-nav__social-link\" href=\"https://www.linkedin.com/company/tutorialspoint/\" rel=\"nofollow\" target=\"_blank\"><i class=\"fa-sharp fa-light fa-brands fa-linkedin\"></i></a>\n",
       "</li>\n",
       "</ul>\n",
       "</nav>\n",
       "</div>\n",
       "<header class=\"header library-header show\">\n",
       "<div class=\"container\">\n",
       "<a href=\"https://www.tutorialspoint.com\" title=\"Tutorialspoint\">\n",
       "<svg class=\"logo-desktop\" fill=\"none\" height=\"42\" viewbox=\"0 0 226 42\" width=\"226\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path class=\"logo-desktop-path\" d=\"M76.2136 13.8408V27.7576H72.3845V26.1045C71.3229 27.3193 69.7701 27.9689 68.0642 27.9689C64.5731 27.9689 62.1172 26.0042 62.1172 21.7103V13.8461H66.1523V21.1135C66.1523 23.4426 67.1874 24.4778 68.9726 24.4778C70.7577 24.4778 72.1785 23.2895 72.1785 20.7279V13.8461H76.2136V13.8408Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M89.1484 20.7959C89.1484 16.6077 92.3807 13.6289 96.8066 13.6289C101.233 13.6289 104.438 16.6024 104.438 20.7959C104.438 24.9894 101.233 27.9629 96.8066 27.9629C92.3807 27.9629 89.1484 24.9894 89.1484 20.7959ZM100.351 20.7959C100.351 18.3928 98.8242 16.9404 96.8066 16.9404C94.7891 16.9404 93.2363 18.3876 93.2363 20.7959C93.2363 23.2043 94.7891 24.6514 96.8066 24.6514C98.8242 24.6514 100.351 23.2043 100.351 20.7959Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M115.28 13.6348V17.3582C114.942 17.3318 114.683 17.3054 114.377 17.3054C112.153 17.3054 110.68 18.5202 110.68 21.1873V27.7575H106.645V13.8407H110.5V15.6787C111.482 14.3319 113.141 13.6348 115.285 13.6348H115.28Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M117.695 13.8408H121.73V27.7576H117.695V13.8408Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M139.119 13.8402V27.757H135.263V26.1514C134.255 27.3661 132.781 27.9629 130.917 27.9629C126.987 27.9629 123.961 25.169 123.961 20.7959C123.961 16.4228 126.987 13.6289 130.917 13.6289C132.623 13.6289 134.07 14.1729 135.079 15.3084V13.8349H139.114L139.119 13.8402ZM135.163 20.7959C135.163 18.3928 133.61 16.9404 131.619 16.9404C129.628 16.9404 128.049 18.3876 128.049 20.7959C128.049 23.2043 129.602 24.6514 131.619 24.6514C133.637 24.6514 135.163 23.2043 135.163 20.7959Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M146.402 8.5625H142.367V27.7555H146.402V8.5625Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M149.141 26.4622L150.487 23.5679C151.729 24.3707 153.619 24.9147 155.325 24.9147C157.19 24.9147 157.887 24.4235 157.887 23.6471C157.887 21.3708 149.479 23.7 149.479 18.1385C149.479 15.4978 151.861 13.6387 155.917 13.6387C157.829 13.6387 159.952 14.077 161.272 14.8534L159.925 17.7266C158.552 16.9502 157.184 16.6914 155.917 16.6914C154.105 16.6914 153.329 17.2618 153.329 17.9854C153.329 20.3673 161.737 18.0646 161.737 23.5468C161.737 26.1347 159.334 27.9674 155.167 27.9674C152.811 27.9674 150.435 27.3231 149.141 26.4675V26.4622Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M178.226 20.9541C178.226 25.0948 175.332 27.8835 171.45 27.8835C169.279 27.8835 167.415 26.9539 166.279 25.1952V32.7742H164.441V14.1515H166.2V16.8398C167.315 15.0283 169.2 14.0459 171.45 14.0459C175.332 14.0459 178.226 16.8398 178.226 20.9541ZM176.388 20.9541C176.388 17.8011 174.191 15.6515 171.318 15.6515C168.445 15.6515 166.248 17.7958 166.248 20.9541C166.248 24.1125 168.418 26.2568 171.318 26.2568C174.218 26.2568 176.388 24.1336 176.388 20.9541Z\" fill=\"var(--clr-text)\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M180.129 20.9541C180.129 16.919 183.076 14.0459 187.058 14.0459C191.041 14.0459 193.966 16.919 193.966 20.9541C193.966 24.9892 191.046 27.8835 187.058 27.8835C183.071 27.8835 180.129 24.9892 180.129 20.9541ZM192.102 20.9541C192.102 17.7747 189.953 15.6515 187.058 15.6515C184.164 15.6515 181.988 17.7747 181.988 20.9541C181.988 24.1336 184.159 26.2568 187.058 26.2568C189.958 26.2568 192.102 24.1336 192.102 20.9541Z\" fill=\"var(--clr-text)\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M196.754 14.1523H198.592V27.7575H196.754V14.1523Z\" fill=\"var(--clr-text)\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M215.288 19.8661V27.7567H213.45V20.051C213.45 17.1778 211.95 15.7043 209.362 15.7043C206.442 15.7043 204.604 17.5159 204.604 20.6161V27.7567H202.766V14.1515H204.524V16.6602C205.507 15.0071 207.345 14.0459 209.695 14.0459C213.006 14.0459 215.283 15.9578 215.283 19.8661H215.288Z\" fill=\"var(--clr-text)\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M59.3346 24.2389C58.8699 24.5769 58.2731 24.7565 57.6815 24.7565C56.5935 24.7565 55.9756 24.1122 55.9756 22.9185V17.2568H59.4139V14.1512H55.9756V10.2852L51.9405 11.2411V14.1512H50.2188V17.2568H51.9405V22.9714C51.9405 26.2829 53.8313 27.9624 57.1375 27.9624C58.3523 27.9624 59.567 27.6772 60.3962 27.0804L59.3346 24.2336V24.2389Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M87.2878 24.2389C86.823 24.5769 86.2262 24.7565 85.6347 24.7565C84.5467 24.7565 83.9287 24.1122 83.9287 22.9185V17.2568H87.367V14.1512H83.9287V10.2852L79.8936 11.2411V14.1512H78.1719V17.2568H79.8936V22.9714C79.8936 26.2829 81.7844 27.9624 85.0907 27.9624C86.3054 27.9624 87.5202 27.6772 88.3494 27.0804L87.2878 24.2336V24.2389Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M119.713 11.8222C120.827 11.8222 121.73 10.9189 121.73 9.80465C121.73 8.69039 120.827 7.78711 119.713 7.78711C118.599 7.78711 117.695 8.69039 117.695 9.80465C117.695 10.9189 118.599 11.8222 119.713 11.8222Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M197.674 11.8222C198.788 11.8222 199.691 10.9189 199.691 9.80465C199.691 8.69039 198.788 7.78711 197.674 7.78711C196.56 7.78711 195.656 8.69039 195.656 9.80465C195.656 10.9189 196.56 11.8222 197.674 11.8222Z\" fill=\"#40A944\"></path>\n",
       "<path class=\"logo-desktop-path\" d=\"M225.15 25.6071C224.633 26.0719 223.909 26.3043 223.133 26.3043C221.606 26.3043 220.803 25.4223 220.803 23.822V15.699H224.918V14.1462H220.803V10.2168L218.965 11.1728V14.1462H217.043V15.699H218.965V23.9223C218.965 26.4311 220.386 27.8782 222.948 27.8782C224.009 27.8782 225.097 27.5666 225.794 26.9222L225.15 25.6019V25.6071Z\" fill=\"var(--clr-text)\"></path>\n",
       "<path d=\"M27.3002 39.5829C33.1626 39.4561 38.4072 35.87 40.8842 30.5568C42.3208 27.4829 43.0444 24.013 42.8542 20.3582C42.2785 9.30395 33.1521 0.394029 22.082 0.0718569C9.95038 -0.282005 0 9.44655 0 21.5043C0 30.7099 5.80439 38.5583 13.9485 41.6004C13.1721 40.7871 12.6017 39.7941 12.2531 38.6217C11.7091 36.8101 11.725 34.6711 12.2954 32.2046L15.2319 19.8881H9.16343L10.1564 15.5837L10.4257 14.4429H16.5259L16.6368 13.9411L18.0628 7.76175L26.9727 6.05582L25.1506 13.9411L23.8408 19.8881L20.8197 33.2609C20.3602 35.2626 20.5398 36.8101 21.3743 37.8928C21.3743 37.8928 22.6207 39.6832 27.3002 39.5829ZM29.4128 13.4605C31.8951 12.9904 34.0288 15.1242 33.5588 17.6065C33.2947 18.9902 32.1803 20.1099 30.7912 20.374C28.3089 20.8441 26.1752 18.7103 26.6453 16.228C26.9093 14.8443 28.0237 13.7246 29.4128 13.4605Z\" fill=\"#40A944\"></path>\n",
       "</svg>\n",
       "<svg class=\"logo-mobile\" fill=\"none\" height=\"42\" viewbox=\"0 0 43 42\" width=\"43\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M27.3002 39.5829C33.1626 39.4561 38.4072 35.87 40.8842 30.5568C42.3208 27.4829 43.0444 24.013 42.8542 20.3582C42.2785 9.30395 33.1521 0.394029 22.082 0.0718569C9.95038 -0.282005 0 9.44655 0 21.5043C0 30.7099 5.80439 38.5583 13.9485 41.6004C13.1721 40.7871 12.6017 39.7941 12.2531 38.6217C11.7091 36.8101 11.725 34.6711 12.2954 32.2046L15.2319 19.8881H9.16343L10.1564 15.5837L10.4257 14.4429H16.5259L16.6368 13.9411L18.0628 7.76175L26.9727 6.05582L25.1506 13.9411L23.8408 19.8881L20.8197 33.2609C20.3602 35.2626 20.5398 36.8101 21.3743 37.8928C21.3743 37.8928 22.6207 39.6832 27.3002 39.5829ZM29.4128 13.4605C31.8951 12.9904 34.0288 15.1242 33.5588 17.6065C33.2947 18.9902 32.1803 20.1099 30.7912 20.374C28.3089 20.8441 26.1752 18.7103 26.6453 16.228C26.9093 14.8443 28.0237 13.7246 29.4128 13.4605Z\" fill=\"#40A944\"></path>\n",
       "</svg>\n",
       "</a>\n",
       "<nav class=\"nav\">\n",
       "<ul class=\"nav__list\">\n",
       "<li class=\"nav__item dropdown\">\n",
       "<button aria-controls=\"category\" aria-expanded=\"false\" class=\"flex-group dropdown__toggle button-reset\" style=\"--gap: .5rem;\"><i class=\"fa-sharp fa-light fa-grid-2\"></i>\n",
       "<span class=\"flex-group\" style=\"--gap: 0.25rem;\">\n",
       "<span>Category</span>\n",
       "<svg class=\"chevron\" fill=\"none\" height=\"16\" viewbox=\"0 0 12 12\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M9.52246 5.06689L6.08496 8.50439L2.64746 5.06689\" stroke=\"var(--clr-text)\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path>\n",
       "</svg>\n",
       "</span>\n",
       "</button>\n",
       "<div class=\"dropdown__list-wrapper\" id=\"categories\">\n",
       "<div class=\"categories-menu\">\n",
       "<div class=\"\">\n",
       "<ul>\n",
       "<li aria-selected=\"true\" class=\"category-button\" role=\"tab\">AI, ML, and Data Science<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"category-button\" role=\"tab\">Programming Languages<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"category-button\" role=\"tab\">Web Development Languages<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"category-button\" role=\"tab\">DevOps<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"category-button\" role=\"tab\">Databases<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"category-button\" role=\"tab\">Computer Science Subjects<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"category-button\" role=\"tab\">Python Technologies<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"category-button\" role=\"tab\">Software Testing<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"category-button\" role=\"tab\">Cyber Security<i class=\"fa-sharp fa-light fa-angle-right\"></i></li>\n",
       "<li class=\"\"><a class=\"button w100 mt-2\" href=\"/top-categories.htm\" title=\"All Categories\"><i class=\"fa-sharp fa-light fa-cubes\"></i> All Categories </a></li>\n",
       "</ul>\n",
       "<div class=\"categories-menu-content\">\n",
       "<div class=\"categories-menu-sections-wrapper\">\n",
       "<!-- AI, ML Data Science -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a href=\"/artificial_intelligence/index.htm\">Artificial Intelligence</a></li>\n",
       "<li><a href=\"/machine_learning/index.htm\">Machine Learning</a></li>\n",
       "<li><a href=\"/machine_learning_with_python/index.htm\">ML With Python</a></li>\n",
       "<li><a href=\"/data_science/index.htm\">Data Science</a></li>\n",
       "<li><a href=\"/statistics/index.htm\">Statistics</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/natural_language_processing/index.htm\">NLP</a></li>\n",
       "<li><a href=\"/artificial_neural_network/index.htm\">Neural Networks</a></li>\n",
       "<li><a href=\"/tensorflow/index.htm\">TensorFlow</a></li>\n",
       "<li><a href=\"/pytorch/index.htm\">PyTorch</a></li>\n",
       "<li><a href=\"/matplotlib/index.htm\">Matplotlib</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/numpy/index.htm\">NumPy</a></li>\n",
       "<li><a href=\"/python_pandas/index.htm\">Pandas</a></li>\n",
       "<li><a href=\"/scipy/index.htm\">SciPy</a></li>\n",
       "<li><a href=\"/big_data_analytics/index.htm\">Big Data Analytics</a></li>\n",
       "<li><a class=\"w100\" href=\"/machine_learning_tutorials.htm\">See all</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<!-- Programming Languages -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a href=\"/python/index.htm\">Python</a></li>\n",
       "<li><a href=\"/java/index.htm\">Java</a></li>\n",
       "<li><a href=\"/cplusplus/index.htm\">C++</a></li>\n",
       "<li><a href=\"/cprogramming/index.htm\">C</a></li>\n",
       "<li><a href=\"/php/index.htm\">PHP</a></li>\n",
       "<li><a href=\"/go/index.htm\">Go</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/kotlin/index.htm\">Kotlin</a></li>\n",
       "<li><a href=\"/r/index.htm\">R</a></li>\n",
       "<li><a href=\"/asp.net/index.htm\">ASP.Net</a></li>\n",
       "<li><a href=\"/csharp/index.htm\">C#.Net</a></li>\n",
       "<li><a href=\"/vb.net/index.htm\">VB.Net</a></li>\n",
       "<li><a href=\"/scala/index.htm\">Scala</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/swift/index.htm\">Swift</a></li>\n",
       "<li><a href=\"/perl/index.htm\">Perl</a></li>\n",
       "<li><a href=\"/ruby/index.htm\">Ruby</a></li>\n",
       "<li><a href=\"/rust/index.htm\">Rust</a></li>\n",
       "<li><a href=\"/lua/index.htm\">Lua</a></li>\n",
       "<li><a class=\"w100\" href=\"/computer_programming_tutorials.htm\">See all</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<!-- Web Development Languages -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a href=\"/html/index.htm\">HTML</a></li>\n",
       "<li><a href=\"/css/index.htm\">CSS</a></li>\n",
       "<li><a href=\"/javascript/index.htm\">JavaScript</a></li>\n",
       "<li><a href=\"/jquery/index.htm\">jQuery</a></li>\n",
       "<li><a href=\"/reactjs/index.htm\">ReactJs</a></li>\n",
       "<li><a href=\"/nodejs/index.htm\">NodeJs</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/wordpress/index.htm\">Wordpress</a></li>\n",
       "<li><a href=\"/angularjs/index.htm\">AngularJs</a></li>\n",
       "<li><a href=\"/php/index.htm\">PHP</a></li>\n",
       "<li><a href=\"/django/index.htm\">Django</a></li>\n",
       "<li><a href=\"/json/index.htm\">JSON</a></li>\n",
       "<li><a href=\"/codeigniter/index.htm\">Codeigniter</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/typescript/index.htm\">TypeScript</a></li>\n",
       "<li><a href=\"/ajax/index.htm\">Ajax</a></li>\n",
       "<li><a href=\"/bootstrap/index.htm\">Bootstrap</a></li>\n",
       "<li><a href=\"/sass/index.htm\">Sass</a></li>\n",
       "<li><a href=\"/appml/index.htm\">AppML</a></li>\n",
       "<li><a class=\"w100\" href=\"/web_development_tutorials.htm\">See all</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<!-- DevOPS -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a href=\"/git/index.htm\">GIT</a></li>\n",
       "<li><a href=\"/amazon_web_services/index.htm\">AWS</a></li>\n",
       "<li><a href=\"/docker/index.htm\">Docker</a></li>\n",
       "<li><a href=\"/kubernetes/index.htm\">Kubernetes</a></li>\n",
       "<li><a href=\"/microsoft_azure/index.htm\">Azure</a></li>\n",
       "<li><a href=\"/gitlab/index.htm\">Gitlab</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/jira/index.htm\">Jira</a></li>\n",
       "<li><a href=\"/gerrit/index.htm\">Gerrit</a></li>\n",
       "<li><a href=\"/ansible/index.htm\">Ansible</a></li>\n",
       "<li><a href=\"/bugzilla/index.htm\">Bugzilla</a></li>\n",
       "<li><a href=\"/chef/index.htm\">Chef</a></li>\n",
       "<li><a href=\"/saltstack/index.htm\">SaltStack</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/openshift/index.htm\">OpenShift <i class=\"fa-sharp fa-light fa-angle-right\"></i></a> </li>\n",
       "<li><a href=\"/puppet/index.htm\">Puppet</a></li>\n",
       "<li><a href=\"/unix/index.htm\">UNIX</a></li>\n",
       "<li><a href=\"/linux_admin/index.htm\">Linux Admin</a></li>\n",
       "<li><a href=\"/ubuntu/index.htm\">Ubuntu</a></li>\n",
       "<li><a class=\"w100\" href=\"/devops_tutorials.htm\">See all</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<!-- Databases -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a href=\"/dbms/index.htm\">DBMS</a></li>\n",
       "<li><a href=\"/sql/index.htm\">SQL</a></li>\n",
       "<li><a href=\"/plsql/index.htm\">PL/SQL</a></li>\n",
       "<li><a href=\"/mysql/index.htm\">MySQL</a></li>\n",
       "<li><a href=\"/tinydb/index.htm\">TinyDB</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/ms_sql_server/index.htm\">SQL Server</a></li>\n",
       "<li><a href=\"/mongodb/index.htm\">MongoDB</a></li>\n",
       "<li><a href=\"/postgresql/index.htm\">PostgreSQL</a></li>\n",
       "<li><a href=\"/sqlite/index.htm\">SQLite</a></li>\n",
       "<li><a href=\"/redis/index.htm\">Redis</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/phpmyadmin/index.htm\">PHP MyAdmin</a></li>\n",
       "<li><a href=\"/mariadb/index.htm\">MariaDB</a></li>\n",
       "<li><a href=\"/couchdb/index.htm\">CouchDB</a></li>\n",
       "<li><a href=\"/db2/index.htm\">DB2</a></li>\n",
       "<li><a class=\"w100\" href=\"/database_tutorials.htm\">See all </a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<!-- Computer Science Subjects -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a class=\"h60\" href=\"/computer_fundamentals/index.htm\">Computer Fundamentals</a></li>\n",
       "<li><a class=\"h60\" href=\"/operating_system/index.htm\">Operating System</a></li>\n",
       "<li><a class=\"h60\" href=\"/dbms/index.htm\">DBMS</a></li>\n",
       "<li><a class=\"h60\" href=\"/data_structures_algorithms/index.htm\">DSA</a></li>\n",
       "<li><a class=\"h60\" href=\"/data_communication_computer_network/index.htm\">Computer Networks</a></li>\n",
       "<li><a class=\"h60\" href=\"/software_engineering/index.htm\">Software Engineering</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a class=\"h60\" href=\"/computer_graphics/index.htm\">Computer Graphics</a></li>\n",
       "<li><a class=\"h60\" href=\"/data_mining/index.htm\">Data Mining</a></li>\n",
       "<li><a class=\"h60\" href=\"/digital_marketing/index.htm\">Digital Marketing</a></li>\n",
       "<li><a class=\"h60\" href=\"/seo/index.htm\">SEO</a></li>\n",
       "<li><a class=\"h60\" href=\"/digital_circuits/index.htm\">Digital Circuits</a></li>\n",
       "<li><a class=\"h60\" href=\"/discrete_mathematics/index.htm\">Discrete Mathematics</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a class=\"h60\" href=\"/cryptography/index.htm\">Cryptography</a></li>\n",
       "<li><a class=\"h60\" href=\"/cloud_computing/index.htm\">Cloud Computing</a></li>\n",
       "<li><a class=\"h60\" href=\"/compiler_design/index.htm\">Compiler Design</a></li>\n",
       "<li><a class=\"h60\" href=\"/embedded_systems/index.htm\">Embedded Systems</a></li>\n",
       "<li><a class=\"h60\" href=\"/microprocessor/index.htm\">Microprocessors</a></li>\n",
       "<li><a class=\"w100\" href=\"/computer_science_tutorials.htm\" style=\"line-height:36px;\">See all </a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<!-- Python Technologies -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a href=\"/python/index.htm\">Python</a></li>\n",
       "<li><a href=\"/numpy/index.htm\">NumPy</a></li>\n",
       "<li><a href=\"/python_pandas/index.htm\">Pandas</a></li>\n",
       "<li><a href=\"/matplotlib/index.htm\">Matplotlib</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/django/index.htm\">Django</a></li>\n",
       "<li><a href=\"/pyqt/index.htm\">PyQt</a></li>\n",
       "<li><a href=\"/pycharm/index.htm\">PyCharm</a></li>\n",
       "<li><a href=\"/python_pillow/index.htm\">Pillow</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/opencv/index.htm\">OpenCV</a></li>\n",
       "<li><a href=\"/seaborn/index.htm\">Seaborn</a></li>\n",
       "<li><a href=\"/machine_learning_with_python/index.htm\">ML with Python</a></li>\n",
       "<li><a href=\"/scipy/index.htm\">SciPy</a></li>\n",
       "<li><a class=\"w100\" href=\"/python_technologies_tutorials.htm\">See all </a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<!-- Software Testing -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a href=\"/software_testing/index.htm\" title=\"Software Testing\">Software Testing</a></li>\n",
       "<li><a href=\"/jira/index.htm\" title=\"Jira\">Jira</a></li>\n",
       "<li><a href=\"/selenium/index.htm\" title=\"Selenium\">Selenium</a></li>\n",
       "<li><a href=\"/testrail/index.htm\">TestRail</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/postman/index.htm\" title=\"Postman\">Postman</a></li>\n",
       "<li><a href=\"/cucumber/index.htm\">Cucumber</a></li>\n",
       "<li><a href=\"/cypress/index.htm\">Cypress</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/watir/index.htm\">Watir</a></li>\n",
       "<li><a href=\"/agile/index.htm\" title=\"Agile\">Agile</a></li>\n",
       "<li><a href=\"/jmeter/index.htm\" title=\"jMeter\">jMeter</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<!-- Cyber Security -->\n",
       "<div class=\"categories-menu-section\">\n",
       "<button class=\"button button--neutral categories-menu-section__back-button\">\n",
       "<i class=\"fa-sharp fa-light fa-angle-right\"></i> Back\n",
       "      </button>\n",
       "<ul>\n",
       "<li><a href=\"/blockchain/index.htm\" title=\"Blockchain\">Blockchain</a></li>\n",
       "<li><a href=\"/information_security_cyber_law/index.htm\" title=\"Information Security\">Information Security</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/computer_security/index.htm\" title=\"Computer Security\">Computer Security</a></li>\n",
       "<li><a href=\"/internet_security/index.htm\" title=\"Internet Security\">Internet Security</a></li>\n",
       "</ul>\n",
       "<ul>\n",
       "<li><a href=\"/network_security/index.htm\" title=\"Network Security\">Network Security</a></li>\n",
       "<li><a href=\"/wireless_security/index.htm\" title=\"Wireless Security\">Wireless Security</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</li>\n",
       "<li class=\"nav__search-wrapper\">\n",
       "<input aria-label=\"Search\" autocomplete=\"off\" class=\"nav__item nav__search gradient-input\" data-result=\"search-results\" id=\"search-strings\" name=\"key\" placeholder=\"Search tutorials, courses and ebooks...\" type=\"text\"/>\n",
       "<button class=\"btn bg-transparent px-2 py-0 position-absolute top-50 end-0 translate-middle-y\" id=\"btnSearch\" title=\"Search Tutorials\" type=\"button\"><svg fill=\"rgb(44, 157, 48)\" height=\"1em\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M508.5 481.6l-129-129c-2.3-2.3-5.3-3.5-8.5-3.5h-10.3C395 312 416 262.5 416 208 416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c54.5 0 104-21 141.1-55.2V371c0 3.2 1.3 6.2 3.5 8.5l129 129c4.7 4.7 12.3 4.7 17 0l9.9-9.9c4.7-4.7 4.7-12.3 0-17zM208 384c-97.3 0-176-78.7-176-176S110.7 32 208 32s176 78.7 176 176-78.7 176-176 176z\"></path></svg></button>\n",
       "<div class=\"search-box search-box-inn\" id=\"search-results\"></div>\n",
       "<div class=\"clear\"></div>\n",
       "</li>\n",
       "<li class=\"nav__item nav__item--left menuBlock\"><a class=\"nav__link\" href=\"/tutorialslibrary.htm\">Library</a></li>\n",
       "<li class=\"nav__item menuBlock\"><a class=\"nav__link\" href=\"https://www.tutorialspoint.com/market/index.asp\">Courses</a></li>\n",
       "<li class=\"nav__item menuBlock\"><a class=\"nav__link\" href=\"https://www.tutorialspoint.com/latest/certifications\">Certifications</a></li>\n",
       "<li class=\"nav__item nav__item--button menuBlock\"><a class=\"button nav__signup-link fw-600\" href=\"https://www.tutorialspoint.com/market/login.jsp\">Login</a></li>\n",
       "</ul>\n",
       "</nav>\n",
       "<button aria-expanded=\"false\" class=\"tutorial-toc-toggle\">\n",
       "<span class=\"sr-only\">Menu</span>\n",
       "</button>\n",
       "<div class=\"flex-group header__buttons\" style=\"--gap: min(3vw, 1rem)\">\n",
       "<div class=\"nav__search-wrapper nav__search-wrapper--mobile\">\n",
       "<input aria-label=\"Search\" autocomplete=\"off\" class=\"nav__item nav__search nav__search--mobile gradient-input\" data-result=\"search-results\" id=\"mobile-search-strings\" name=\"key\" placeholder=\"Search tutorials, courses and ebooks...\" type=\"text\"/>\n",
       "</div>\n",
       "<button aria-expanded=\"false\" class=\"button-reset mobile-search-button header__search-button search-button\">\n",
       "<span class=\"sr-only\">Show search</span>\n",
       "</button>\n",
       "</div>\n",
       "</div>\n",
       "</header>\n",
       "<nav class=\"library-nav\">\n",
       "<div class=\"library-nav__container\">\n",
       "<button class=\"library-nav__prev-button library-nav__button button-reset\" id=\"scroll_left_btn\" onmousedown=\"initScroll(-1)\" onmouseout=\"stopScrolling()\" onmouseup=\"stopScrolling()\" style=\"display: block;\"><svg fill=\"none\" height=\"15\" viewbox=\"0 0 10 17\" width=\"10\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M8.17969 15.459L0.963867 8.24316L8.17969 1.02734\" stroke=\"white\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.79664\"></path></svg></button>\n",
       "<div class=\"library-nav__slider\">\n",
       "<ul id=\"library-nav\">\n",
       "<li><a class=\"\" href=\"/sql/index.htm\" title=\"SQL Tutorial\">SQL</a></li>\n",
       "<li><a class=\"\" href=\"/html/index.htm\" title=\"HTML Tutorial\">HTML</a></li>\n",
       "<li><a class=\"\" href=\"/css/index.htm\" title=\"CSS Tutorial\">CSS</a></li>\n",
       "<li><a class=\"\" href=\"/javascript/index.htm\" title=\"JavaScript Tutorial\">Javascript</a></li>\n",
       "<li><a class=\"\" href=\"/python/index.htm\" title=\"Python Tutorial\">Python</a></li>\n",
       "<li><a class=\"\" href=\"/java/index.htm\" title=\"Java Tutorial\">Java</a></li>\n",
       "<li><a class=\"\" href=\"/cprogramming/index.htm\" title=\"C Tutorial\">C</a></li>\n",
       "<li><a class=\"\" href=\"/cplusplus/index.htm\" title=\"C++ Tutorial\">C++</a></li>\n",
       "<li><a class=\"\" href=\"/php/index.htm\" title=\"PHP Tutorial\">PHP</a></li>\n",
       "<li><a class=\"\" href=\"/scala/index.htm\" title=\"Scala Tutorial\">Scala</a></li>\n",
       "<li><a class=\"\" href=\"/csharp/index.htm\" title=\"C# Tutorial\">C#</a></li>\n",
       "<li><a class=\"\" href=\"/tailwind_css/index.htm\" title=\"Tailwind CSS Tutorial\">Tailwind CSS</a></li>\n",
       "<li><a class=\"\" href=\"/nodejs/index.htm\" title=\"Node.js Tutorial\">Node.js</a></li>\n",
       "<li><a class=\"\" href=\"/mysql/index.htm\" title=\"MySQL\">MySQL</a></li>\n",
       "<li><a class=\"\" href=\"/mongodb/index.htm\" title=\"MongoDB Tutorial\">MongoDB</a></li>\n",
       "<li><a class=\"\" href=\"/plsql/index.htm\" title=\"PL/SQL Tutorial\">PL/SQL</a></li>\n",
       "<li><a class=\"\" href=\"/swift/index.htm\" title=\"Swift Tutorial\">Swift</a></li>\n",
       "<li><a class=\"\" href=\"/bootstrap/index.htm\" title=\"Bootstrap Tutorial\">Bootstrap</a></li>\n",
       "<li><a class=\"\" href=\"/r/index.htm\" title=\"R Programming\">R</a></li>\n",
       "<li><a class=\"\" href=\"/machine_learning/index.htm\" title=\"Machine Learning\">Machine Learning</a></li>\n",
       "<li><a class=\"\" href=\"/blockchain/index.htm\" title=\"Blockchain Tutorial\">Blockchain</a></li>\n",
       "<li><a class=\"\" href=\"/angular4/index.htm\" title=\"Angular Tutorial\">Angular</a></li>\n",
       "<li><a class=\"\" href=\"/react_native/index.htm\" title=\"React Native Tutorial\">React Native</a></li>\n",
       "<li><a class=\"\" href=\"/computer_fundamentals/index.htm\" title=\"Computer Fundamentals Tutorial\">Computer Fundamentals</a></li>\n",
       "<li><a class=\"\" href=\"/compiler_design/index.htm\" title=\"Compiler Design Tutorial\">Compiler Design</a></li>\n",
       "<li><a class=\"\" href=\"/operating_system/index.htm\" title=\"Operating System Tutorial\">Operating System</a></li>\n",
       "<li><a class=\"\" href=\"/data_structures_algorithms/index.htm\" title=\"Data Structure and Algorithms Tutorial\">Data Structure and Algorithms</a></li>\n",
       "<li><a class=\"\" href=\"/data_communication_computer_network/index.htm\" title=\"Computer Network Tutorial\">Computer Network</a></li>\n",
       "<li><a class=\"\" href=\"/dbms/index.htm\" title=\"DBMS Tutorial\">DBMS</a></li>\n",
       "<li><a class=\"\" href=\"/excel/index.htm\" title=\"Excel Tutorial\">Excel</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<button class=\"library-nav__next-button library-nav__button button-reset\" id=\"scroll_right_btn\" onmousedown=\"initScroll(1)\" onmouseout=\"stopScrolling()\" onmouseup=\"stopScrolling()\"><svg fill=\"none\" height=\"15\" viewbox=\"0 0 10 17\" width=\"10\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M1.27734 15.459L8.49316 8.24316L1.27734 1.02734\" stroke=\"white\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.79664\"></path></svg></button>\n",
       "</div>\n",
       "</nav>\n",
       "<main class=\"bg-light\" style=\"overflow: unset;\">\n",
       "<div class=\"container-fluid\">\n",
       "<div class=\"row\">\n",
       "<div class=\"tutorial-toc\">\n",
       "<div class=\"toc-nav\">\n",
       "<div class=\"mini-logo\">\n",
       "<img alt=\"Beautiful Soup Tutorial\" src=\"/beautiful_soup/images/beautifulsoup-mini-logo.jpg\"/>\n",
       "</div>\n",
       "<div id=\"ezoic-pub-ad-placeholder-146\" style=\"max-height:100px;\"></div>\n",
       "<script>\n",
       "    ezstandalone.cmd.push(function() {\n",
       "        ezstandalone.showAds([{id: 146, required: true}]);\n",
       "    });\n",
       "</script>\n",
       "<ul class=\"toc chapters\">\n",
       "<li class=\"heading\">Beautiful Soup Tutorial</li>\n",
       "<li><a href=\"/beautiful_soup/index.htm\">Beautiful Soup - Home</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_overview.htm\">Beautiful Soup - Overview</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_web_scraping.htm\">Beautiful Soup - Web Scraping</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_installation.htm\">Beautiful Soup - Installation</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_souping_the_page.htm\">Beautiful Soup - Souping the Page</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_kinds_of_objects.htm\">Beautiful Soup - Kinds of objects</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_inspect_data_source.htm\">Beautiful Soup - Inspect Data Source</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_scrape_html_content.htm\">Beautiful Soup - Scrape HTML Content</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_navigating_by_tags.htm\">Beautiful Soup - Navigating by Tags</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_elements_by_id.htm\">Beautiful Soup - Find Elements by ID</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_elements_by_class.htm\">Beautiful Soup - Find Elements by Class</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_elements_by_attribute.htm\">Beautiful Soup - Find Elements by Attribute</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_searching_the_tree.htm\">Beautiful Soup - Searching the Tree</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_modifying_the_tree.htm\">Beautiful Soup - Modifying the Tree</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_parsing_a_section_of_a_document.htm\">Beautiful Soup - Parsing a Section of a Document</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_all_children_of_an_element.htm\">Beautiful Soup - Find all Children of an Element</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_element_using_css_selectors.htm\">Beautiful Soup - Find Element using CSS Selectors</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_all_comments.htm\">Beautiful Soup - Find all Comments</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_scraping_list_from_html.htm\">Beautiful Soup - Scraping List from HTML</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_scraping_paragraphs_from_html.htm\">Beautiful Soup - Scraping Paragraphs from HTML</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_scraping_link_from_html.htm\">BeautifulSoup - Scraping Link from HTML</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_get_all_html_tags.htm\">Beautiful Soup - Get all HTML Tags</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_get_text_inside_tag.htm\">Beautiful Soup - Get Text Inside Tag</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_all_headings.htm\">Beautiful Soup - Find all Headings</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_extract_title_tag.htm\">Beautiful Soup - Extract Title Tag</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_extract_email_ids.htm\">Beautiful Soup - Extract Email IDs</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_scrape_nested_tags.htm\">Beautiful Soup - Scrape Nested Tags</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_parsing_tables.htm\">Beautiful Soup - Parsing Tables</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_selecting_nth_child.htm\">Beautiful Soup - Selecting nth Child</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_search_by_text_inside_a_tag.htm\">Beautiful Soup - Search by text inside a Tag</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_remove_html_tags.htm\">Beautiful Soup - Remove HTML Tags</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_remove_all_styles.htm\">Beautiful Soup - Remove all Styles</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_remove_all_scripts.htm\">Beautiful Soup - Remove all Scripts</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_remove_empty_tags.htm\">Beautiful Soup - Remove Empty Tags</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_remove_child_elements.htm\">Beautiful Soup - Remove Child Elements</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_vs_find_all.htm\">Beautiful Soup -  find vs find_all</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_specifying_the_parser.htm\">Beautiful Soup - Specifying the Parser</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_comparing_objects.htm\">Beautiful Soup - Comparing Objects</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_copying_objects.htm\">Beautiful Soup - Copying Objects</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_get_tag_position.htm\">Beautiful Soup - Get Tag Position</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_encoding.htm\">Beautiful Soup - Encoding</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_output_formatting.htm\">Beautiful Soup - Output Formatting</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_pretty_printing.htm\">Beautiful Soup - Pretty Printing</a></li>\n",
       "<!--<li><a href=\"/beautiful_soup/beautiful_soup_beautiful_objects.htm\">Beautiful Soup - Beautiful Objects</a></li>-->\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_navigablestring_class.htm\">Beautiful Soup - NavigableString Class</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_convert_object_to_string.htm\">Beautiful Soup - Convert Object to String</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_convert_html_to_text.htm\">Beautiful Soup - Convert HTML to Text</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_parsing_xml.htm\">Beautiful Soup - Parsing XML</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_error_handling.htm\">Beautiful Soup - Error Handling</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_trouble_shooting.htm\">Beautiful Soup - Trouble Shooting</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_porting_old_code.htm\">Beautiful Soup - Porting Old Code</a></li>\n",
       "<li class=\"heading\">Beautiful Soup - Functions Reference</li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_contents_property.htm\">Beautiful Soup - contents Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_children_property.htm\">Beautiful Soup - children Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_string_property.htm\">Beautiful Soup - string Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_strings_property.htm\">Beautiful Soup - strings Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_stripped_strings_property.htm\">Beautiful Soup - stripped_strings Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_descendants_property.htm\">Beautiful Soup - descendants Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_parent_property.htm\">Beautiful Soup - parent Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_parents_property.htm\">Beautiful Soup - parents Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_next_sibling_property.htm\">Beautiful Soup - next_sibling Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_previous_sibling_property.htm\">Beautiful Soup - previous_sibling Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_next_siblings_property.htm\">Beautiful Soup - next_siblings Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_previous_siblings_property.htm\">Beautiful Soup - previous_siblings Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_next_element_property.htm\">Beautiful Soup - next_element Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_previous_element_property.htm\">Beautiful Soup - previous_element Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_next_elements_property.htm\">Beautiful Soup - next_elements Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_previous_elements_property.htm\">Beautiful Soup - previous_elements Property</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_method.htm\">Beautiful Soup - find Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_all_method.htm\">Beautiful Soup - find_all Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_parents_method.htm\">Beautiful Soup - find_parents Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_parent_method.htm\">Beautiful Soup - find_parent Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_next_siblings_method.htm\">Beautiful Soup - find_next_siblings Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_next_sibling_method.htm\">Beautiful Soup - find_next_sibling Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_previous_siblings_method.htm\">Beautiful Soup - find_previous_siblings Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_previous_sibling_method.htm\">Beautiful Soup - find_previous_sibling Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_all_next_method.htm\">Beautiful Soup - find_all_next Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_next_method.htm\">Beautiful Soup - find_next Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_all_previous_method.htm\">Beautiful Soup - find_all_previous Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_find_previous_method.htm\">Beautiful Soup - find_previous Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_select_method.htm\">Beautiful Soup - select Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_append_method.htm\">Beautiful Soup - append Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_extend_method.htm\">Beautiful Soup - extend Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_navigablestring_method.htm\">Beautiful Soup - NavigableString Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_new_tag_method.htm\">Beautiful Soup - new_tag Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_insert_method.htm\">Beautiful Soup - insert Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_insert_before_method.htm\">Beautiful Soup - insert_before Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_insert_after_method.htm\">Beautiful Soup - insert_after Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_clear_method.htm\">Beautiful Soup - clear Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_extract_method.htm\">Beautiful Soup - extract Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_decompose_method.htm\">Beautiful Soup - decompose Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_replace_with_method.htm\">Beautiful Soup - replace_with Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_wrap_method.htm\">Beautiful Soup - wrap Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_unwrap_method.htm\">Beautiful Soup - unwrap Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_smooth_method.htm\">Beautiful Soup - smooth Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_prettify_method.htm\">Beautiful Soup - prettify Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_encode_method.htm\">Beautiful Soup - encode Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_decode_method.htm\">Beautiful Soup - decode Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_get_text_method.htm\">Beautiful Soup - get_text Method</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_diagnose_method.htm\">Beautiful Soup - diagnose Method</a></li>\n",
       "<li class=\"heading\">Beautiful Soup Useful Resources</li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_quick_guide.htm\">Beautiful Soup - Quick Guide</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_useful_resources.htm\">Beautiful Soup - Useful Resources</a></li>\n",
       "<li><a href=\"/beautiful_soup/beautiful_soup_discussion.htm\">Beautiful Soup - Discussion</a></li>\n",
       "</ul>\n",
       "<ul class=\"toc reading\">\n",
       "<li class=\"sreading\">Selected Reading</li>\n",
       "<li><a href=\"/upsc_ias_exams.htm\" target=\"_blank\">UPSC IAS Exams Notes</a></li>\n",
       "<li><a href=\"/developers_best_practices/index.htm\" target=\"_blank\">Developer's Best Practices</a></li>\n",
       "<li><a href=\"/questions_and_answers.htm\" target=\"_blank\">Questions and Answers</a></li>\n",
       "<li><a href=\"/effective_resume_writing.htm\" target=\"_blank\">Effective Resume Writing</a></li>\n",
       "<li><a href=\"/hr_interview_questions/index.htm\" target=\"_blank\">HR Interview Questions</a></li>\n",
       "<li><a href=\"/computer_glossary.htm\" target=\"_blank\">Computer Glossary</a></li>\n",
       "<li><a href=\"/computer_whoiswho.htm\" target=\"_blank\">Who is Who</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"d-none d-sm-block\" id=\"stickyparent\">\n",
       "<div id=\"sticky-ad\" style=\"height:0px;width:300px;\">\n",
       "<!-- Placeholder for an advertisement -->\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<!-- Tutorial ToC Ends Here -->\n",
       "<!-- Tutorial Content Starts Here -->\n",
       "<div class=\"tutorial-content\" id=\"mainContent\">\n",
       "<h1>Beautiful Soup - Quick Guide</h1>\n",
       "<hr/>\n",
       "<!-- TAGNAME: 728x90_Top -->\n",
       "<div class=\"clsEzoicAdv\" id=\"ezoic-pub-ad-placeholder-132\" style=\"text-align:center !important;overflow: hidden; max-height:99px;min-height:99px\"></div>\n",
       "<script>\n",
       "   ezstandalone.cmd.push(function() {\n",
       "   ezstandalone.showAds(132);\n",
       "});\n",
       "</script>\n",
       "<hr/>\n",
       "<div class=\"library-page-top-nav\">\n",
       "<a href=\"/beautiful_soup/beautiful_soup_diagnose_method.htm\">\n",
       "<div class=\"button button--neutral\">\n",
       "<svg fill=\"none\" height=\"16\" viewbox=\"0 0 10 16\" width=\"10\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M1.03117 8.48836C0.64065 8.09783 0.64065 7.46467 1.03117 7.07414L7.39514 0.710183C7.78566 0.319658 8.41883 0.319658 8.80935 0.710183C9.19987 1.10071 9.19987 1.73387 8.80935 2.1244L3.15249 7.78125L8.80935 13.4381C9.19987 13.8286 9.19987 14.4618 8.80935 14.8523C8.41882 15.2428 7.78566 15.2428 7.39513 14.8523L1.03117 8.48836ZM3.12109 8.78125L1.73828 8.78125L1.73828 6.78125L3.12109 6.78125L3.12109 8.78125Z\" fill=\"black\"></path></svg>\n",
       "      Previous\n",
       "   </div>\n",
       "</a>\n",
       "<div class=\"flex-group\">\n",
       "<a href=\"/beautiful_soup/beautiful_soup_useful_resources.htm\">\n",
       "<div class=\"button\">Next\n",
       "   <svg fill=\"none\" height=\"16\" viewbox=\"0 0 10 16\" width=\"10\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M8.87117 8.48836C9.26169 8.09783 9.26169 7.46467 8.87117 7.07414L2.50721 0.710183C2.11668 0.319658 1.48352 0.319658 1.09299 0.710183C0.70247 1.10071 0.70247 1.73387 1.09299 2.1244L6.74985 7.78125L1.093 13.4381C0.702471 13.8286 0.702471 14.4618 1.093 14.8523C1.48352 15.2428 2.11668 15.2428 2.50721 14.8523L8.87117 8.48836ZM6.78125 8.78125L8.16406 8.78125L8.16406 6.78125L6.78125 6.78125L6.78125 8.78125Z\" fill=\"white\"></path></svg>\n",
       "</div>\n",
       "</a>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"clearer\"></div>\n",
       "<h1>Beautiful Soup - Overview</h1>\n",
       "<p>In today's world, we have tons of unstructured data/information (mostly web data) available freely. Sometimes the freely available data is easy to read and sometimes not. No matter how your data is available, web scraping is very useful tool to transform unstructured data into structured data that is easier to read and analyze. In other words, web scraping is a way to collect, organize and analyze this enormous amount of data. So let us first understand what is web-scraping.</p>\n",
       "<h2>Introduction to Beautiful Soup</h2>\n",
       "<p>The Beautiful Soup is a python library which is named after a Lewis Carroll poem of the same name in \"Alice's Adventures in the Wonderland\". Beautiful Soup is a python package and as the name suggests, parses the unwanted data and helps to organize and format the messy web data by fixing bad HTML and present to us in an easily-traversable XML structures.</p>\n",
       "<p>In short, Beautiful Soup is a python package which allows us to pull data out of HTML and XML documents.</p>\n",
       "<h2>HTML tree Structure</h2>\n",
       "<p>Before we look into the functionality provided by Beautiful Soup, let us first understand the HTML tree structure.</p>\n",
       "<img alt=\"HTML tree structure\" src=\"/beautiful_soup/images/html_tree_structure.jpg\"/>\n",
       "<p>The root element in the document tree is the html, which can have parents, children and siblings and this determines by its position in the tree structure. To move among HTML elements, attributes and text, you have to move among nodes in your tree structure.</p>\n",
       "<p>Let us suppose the webpage is as shown below </p>\n",
       "<img alt=\"webpage\" src=\"/beautiful_soup/images/webpage.jpg\"/>\n",
       "<p>Which translates to an html document as follows </p>\n",
       "<pre class=\"demo-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h1&gt;Tutorialspoint Online Library&lt;/h1&gt;\n",
       "      &lt;p&gt;&lt;b&gt;It's all Free&lt;/b&gt;&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Which simply means, for above html document, we have a html tree structure as follows </p>\n",
       "<img alt=\"Html Tree Structure\" src=\"/beautiful_soup/images/html_tree_structure_document.jpg\"/>\n",
       "<h1>Beautiful Soup - web-scraping</h1>\n",
       "<p>Scraping is simply a process of extracting (from various means), copying and screening of data.</p>\n",
       "<p>When we scrape or extract data or feeds from the web (like from web-pages or websites), it is termed as web-scraping.</p>\n",
       "<p>So, web scraping (which is also known as web data extraction or web harvesting) is the extraction of data from web. In short, web scraping provides a way to the developers to collect and analyze data from the internet.</p>\n",
       "<h3>Why Web-scraping?</h3>\n",
       "<p>Web-scraping provides one of the great tools to automate most of the things a human does while browsing. Web-scraping is used in an enterprise in a variety of ways </p>\n",
       "<h3>Data for Research</h3>\n",
       "<p>Smart analyst (like researcher or journalist) uses web scrapper instead of manually collecting and cleaning data from the websites.</p>\n",
       "<h3>Products, prices &amp; popularity comparison</h3>\n",
       "<p>Currently there are couple of services which use web scrappers to collect data from numerous online sites and use it to compare products popularity and prices.</p>\n",
       "<h3>SEO Monitoring</h3>\n",
       "<p>There are numerous SEO tools such as Ahrefs, Seobility, SEMrush, etc., which are used for competitive analysis and for pulling data from your client's websites.</p>\n",
       "<h3>Search engines</h3>\n",
       "<p>There are some big IT companies whose business solely depends on web scraping.</p>\n",
       "<h3>Sales and Marketing</h3>\n",
       "<p>The data gathered through web scraping can be used by marketers to analyze different niches and competitors or by the sales specialist for selling content marketing or social media promotion services.</p>\n",
       "<h2>Why Python for Web Scraping?</h2>\n",
       "<p>Python is one of the most popular languages for web scraping as it can handle most of the web crawling related tasks very easily. </p>\n",
       "<p>Below are some of the points on why to choose python for web scraping </p>\n",
       "<h3>Ease of Use</h3>\n",
       "<p>As most of the developers agree that python is very easy to code. We don't have to use any curly braces \"{ }\" or semi-colons \";\" anywhere, which makes it more readable and easy-to-use while developing web scrapers.</p>\n",
       "<h3>Huge Library Support</h3>\n",
       "<p>Python provides huge set of libraries for different requirements, so it is appropriate for web scraping as well as for data visualization, machine learning, etc.</p>\n",
       "<h3>Easily Explicable Syntax</h3>\n",
       "<p>Python is a very readable programming language as python syntax are easy to understand. Python is very expressive and code indentation helps the users to differentiate different blocks or scopes in the code.</p>\n",
       "<h3>Dynamically-typed language</h3>\n",
       "<p>Python is a dynamically-typed language, which means the data assigned to a variable tells, what type of variable it is. It saves lot of time and makes work faster.</p>\n",
       "<h3>Huge Community</h3>\n",
       "<p>Python community is huge which helps you wherever you stuck while writing code.</p>\n",
       "<h1>Beautiful Soup - Installation</h1>\n",
       "<p>Beautiful Soup is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.</p>\n",
       "<p>BeautifulSoup package is not a part of Python's standard library, hence it must be installed. Before installing the latest version, let us create a virtual environment, as per Python's recommended method.</p>\n",
       "<p>A virtual environment allows us to create an isolated working copy of python for a specific project without affecting the outside setup.</p>\n",
       "<p>We shall use venv module in Python's standard library to create virtual environment. PIP is included by default in Python version 3.4 or later.</p>\n",
       "<p>Use the following command to create virtual environment in Windows</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "C:\\uses\\user\\&gt;python -m venv myenv\n",
       "</pre>\n",
       "<p>On Ubuntu Linux, update the APT repo and install venv if required before creating virtual environment</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "mvl@GNVBGL3:~ $ sudo apt update &amp;&amp; sudo apt upgrade -y\n",
       "mvl@GNVBGL3:~ $ sudo apt install python3-venv\n",
       "</pre>\n",
       "<p>Then use the following command to create a virtual environment</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "mvl@GNVBGL3:~ $ sudo python3 -m venv myenv\n",
       "</pre>\n",
       "<p>You need to activate the virtual environment. On Windows use the command</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "C:\\uses\\user\\&gt;cd myenv\n",
       "C:\\uses\\user\\myenv&gt;scripts\\activate\n",
       "(myenv) C:\\Users\\users\\user\\myenv&gt;\n",
       "</pre>\n",
       "<p>On Ubuntu Linux, use following command to activate the virtual environment</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "mvl@GNVBGL3:~$ cd myenv\n",
       "mvl@GNVBGL3:~/myenv$ source bin/activate\n",
       "(myenv) mvl@GNVBGL3:~/myenv$\n",
       "</pre>\n",
       "<p>Name of the virtual environment appears in the parenthesis. Now that it is activated, we can now install BeautifulSoup in it.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "(myenv) mvl@GNVBGL3:~/myenv$ pip3 install beautifulsoup4\n",
       "Collecting beautifulsoup4\n",
       "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
       "      \n",
       "143.0/143.0 KB 325.2 kB/s eta 0:00:00\n",
       "Collecting soupsieve&gt;1.2\n",
       "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
       "Installing collected packages: soupsieve, beautifulsoup4\n",
       "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1 \n",
       "</pre>\n",
       "<p>Note that the latest version of Beautifulsoup4 is 4.12.2 and requires Python 3.8 or later.</p>\n",
       "<p>If you don't have easy_install or pip installed, you can download the Beautiful Soup 4 source tarball and install it with setup.py.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "(myenv) mvl@GNVBGL3:~/myenv$ python setup.py install \n",
       "</pre>\n",
       "<p>To check if Beautifulsoup is properly install, enter following commands in Python terminal </p>\n",
       "<pre class=\"result notranslate\">\n",
       "&gt;&gt;&gt; import bs4\n",
       "&gt;&gt;&gt; bs4.__version__\n",
       "'4.12.2'\n",
       "</pre>\n",
       "<p>If the installation hasn't been successful, you will get ModuleNotFoundError.</p>\n",
       "<p>You will also need to install requests library. It is a HTTP library for Python.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "pip3 install requests\n",
       "</pre>\n",
       "<h3>Installing a Parser</h3>\n",
       "<p>By default, Beautiful Soup supports the HTML parser included in Python's standard library, however it also supports many external third party python parsers like lxml parser or html5lib parser. </p>\n",
       "<p>To install lxml or html5lib parser, use the command:</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "pip3 install lxml\n",
       "pip3 install html5lib\n",
       "</pre>\n",
       "<p>These parsers have their advantages and disadvantages as shown below </p>\n",
       "<h3>Parser: Python's html.parser</h3>\n",
       "<p><b>Usage</b>  BeautifulSoup(markup, \"html.parser\")</p>\n",
       "<p><b>Advantages</b></p>\n",
       "<ul class=\"list\">\n",
       "<li>Batteries included</li>\n",
       "<li>Decent speed</li>\n",
       "<li>Lenient (As of Python 3.2)</li>\n",
       "</ul>\n",
       "<p><b>Disadvantages</b></p>\n",
       "<ul class=\"list\">\n",
       "<li>Not as fast as lxml, less lenient than html5lib.</li>\n",
       "</ul>\n",
       "<h3>Parser: lxml's HTML parser</h3>\n",
       "<p><b>Usage</b>  BeautifulSoup(markup, \"lxml\")</p>\n",
       "<p><b>Advantages</b></p>\n",
       "<ul class=\"list\">\n",
       "<li>Very fast</li>\n",
       "<li>Lenient</li>\n",
       "</ul>\n",
       "<p><b>Disadvantages</b></p>\n",
       "<ul class=\"list\">\n",
       "<li></li>External C dependency\n",
       "</ul>\n",
       "<h3>Parser: lxml's XML parser</h3>\n",
       "<p><b>Usage</b>  BeautifulSoup(markup, \"lxml-xml\") </p><p>Or BeautifulSoup(markup, \"xml\")</p>\n",
       "<p><b>Advantages</b></p>\n",
       "<ul class=\"list\">\n",
       "<li>Very fast</li>\n",
       "<li>The only currently supported XML parser</li>\n",
       "</ul>\n",
       "<p><b>Disadvantages</b></p>\n",
       "<ul class=\"list\">\n",
       "<li>External C dependency</li>\n",
       "</ul>\n",
       "<h3>Parser: html5lib</h3>\n",
       "<p><b>Usage</b>  BeautifulSoup(markup, \"html5lib\")</p>\n",
       "<p><b>Advantages</b></p>\n",
       "<ul class=\"list\">\n",
       "<li>Extremely lenient</li>\n",
       "<li>Parses pages the same way a web browser does</li>\n",
       "<li>Creates valid HTML5</li>\n",
       "</ul>\n",
       "<p><b>Disadvantages</b></p>\n",
       "<ul class=\"list\">\n",
       "<li>Very slow</li>\n",
       "<li>External Python dependency</li>\n",
       "</ul>\n",
       "<h1>Beautiful Soup - Souping the Page</h1>\n",
       "<p>It is time to test our Beautiful Soup package in one of the html pages (taking web page - <a href=\"https://www.tutorialspoint.com/index.htm\" target=\"_blank\">https://www.tutorialspoint.com/index.htm</a>, you can choose any-other web page you want) and extract some information from it.</p>\n",
       "<p>In the below code, we are trying to extract the title from the webpage </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "import requests\n",
       "\n",
       "\n",
       "url = \"https://www.tutorialspoint.com/index.htm\"\n",
       "req = requests.get(url)\n",
       "\n",
       "soup = BeautifulSoup(req.content, \"html.parser\")\n",
       "\n",
       "print(soup.title)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;title&gt;Online Courses and eBooks Library&lt;title&gt;\n",
       "</pre>\n",
       "<p>One common task is to extract all the URLs within a webpage. For that we just need to add the below line of code </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "for link in soup.find_all('a'):\n",
       "   print(link.get('href'))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<p>Shown below is the partial output of the above loop </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "https://www.tutorialspoint.com/index.htm\n",
       "https://www.tutorialspoint.com/codingground.htm\n",
       "https://www.tutorialspoint.com/about/about_careers.htm\n",
       "https://www.tutorialspoint.com/whiteboard.htm\n",
       "https://www.tutorialspoint.com/online_dev_tools.htm\n",
       "https://www.tutorialspoint.com/business/index.asp\n",
       "https://www.tutorialspoint.com/market/teach_with_us.jsp\n",
       "https://www.facebook.com/tutorialspointindia\n",
       "https://www.instagram.com/tutorialspoint_/\n",
       "https://twitter.com/tutorialspoint\n",
       "https://www.youtube.com/channel/UCVLbzhxVTiTLiVKeGV7WEBg\n",
       "https://www.tutorialspoint.com/categories/development\n",
       "https://www.tutorialspoint.com/categories/it_and_software\n",
       "https://www.tutorialspoint.com/categories/data_science_and_ai_ml\n",
       "https://www.tutorialspoint.com/categories/cyber_security\n",
       "https://www.tutorialspoint.com/categories/marketing\n",
       "https://www.tutorialspoint.com/categories/office_productivity\n",
       "https://www.tutorialspoint.com/categories/business\n",
       "https://www.tutorialspoint.com/categories/lifestyle\n",
       "https://www.tutorialspoint.com/latest/prime-packs\n",
       "https://www.tutorialspoint.com/market/index.asp\n",
       "https://www.tutorialspoint.com/latest/ebooks\n",
       "\n",
       "\n",
       "</pre>\n",
       "<p>To parse a web page stored locally in the current working directory, obtain the file object pointing to the html file, and use it as argument to the BeautifulSoup() constructor.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "with open(\"index.html\") as fp:\n",
       "    soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "print(soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "&lt;title&gt;Hello World&lt;/title&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "&lt;h1 style=\"text-align:center;\"&gt;Hello World&lt;/h1&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>You can also use a string that contains HTML script as constructor's argument as follows </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;Hello World&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h1 style=\"text-align:center;\"&gt;Hello World&lt;/h1&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "print(soup)\n",
       "</pre>\n",
       "<p>Beautiful Soup uses the best available parser to parse the document. It will use an HTML parser unless specified otherwise.</p>\n",
       "<h1>Beautiful Soup - Kinds of objects</h1>\n",
       "<p>When we pass a html document or string to a beautifulsoup constructor, beautifulsoup basically converts a complex html page into different python objects. Below we are going to discuss four major kinds of objects defined in bs4 package.</p>\n",
       "<ul class=\"list\">\n",
       "<li>Tag</li>\n",
       "<li>NavigableString</li>\n",
       "<li>BeautifulSoup</li>\n",
       "<li>Comments</li>\n",
       "</ul>\n",
       "<h2>Tag Object</h2>\n",
       "<p>A HTML tag is used to define various types of content. A tag object in BeautifulSoup corresponds to an HTML or XML tag in the actual page or document.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup('&lt;b class=\"boldest\"&gt;TutorialsPoint&lt;/b&gt;', 'lxml')\n",
       "tag = soup.html\n",
       "print (type(tag))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;class 'bs4.element.Tag'&gt;\n",
       "</pre>\n",
       "<p>Tags contain lot of attributes and methods and two important features of a tag are its name and attributes.</p>\n",
       "<h3>Name (tag.name)</h3>\n",
       "<p>Every tag contains a name and can be accessed through '.name' as suffix. tag.name will return the type of tag it is.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup('&lt;b class=\"boldest\"&gt;TutorialsPoint&lt;/b&gt;', 'lxml')\n",
       "tag = soup.html\n",
       "print (tag.name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "html\n",
       "</pre>\n",
       "<p>However, if we change the tag name, same will be reflected in the HTML markup generated by the BeautifulSoup.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup('&lt;b class=\"boldest\"&gt;TutorialsPoint&lt;/b&gt;', 'lxml')\n",
       "tag = soup.html\n",
       "tag.name = \"strong\"\n",
       "print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;strong&gt;&lt;body&gt;&lt;b class=\"boldest\"&gt;TutorialsPoint&lt;/b&gt;&lt;/body&gt;&lt;/strong&gt;\n",
       "</pre>\n",
       "<h3>Attributes (tag.attrs)</h3>\n",
       "<p>A tag object can have any number of attributes. In the above example, the tag &lt;b class=\"boldest\"&gt; has an attribute 'class' whose value is \"boldest\". Anything that is NOT tag, is basically an attribute and must contain a value. A dictionary of attributes and their values is returned by \"attrs\". You can access the attributes either through accessing the keys too.</p>\n",
       "<p>In the example below, the string argument for Beautifulsoup() constructor contains HTML input tag. The attributes of input tag are returned by \"attr\".</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup('&lt;input type=\"text\" name=\"name\" value=\"Raju\"&gt;', 'lxml')\n",
       "tag = soup.input\n",
       "\n",
       "print (tag.attrs)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "{'type': 'text', 'name': 'name', 'value': 'Raju'}\n",
       "</pre>\n",
       "<p>We can do all kind of modifications to our tag's attributes (add/remove/modify), using dictionary operators or methods.</p>\n",
       "<p>In the following example, the value tag is updated. The updated HTML string shows changes.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup('&lt;input type=\"text\" name=\"name\" value=\"Raju\"&gt;', 'lxml')\n",
       "tag = soup.input\n",
       "\n",
       "print (tag.attrs)\n",
       "tag['value']='Ravi'\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;&lt;body&gt;&lt;input name=\"name\" type=\"text\" value=\"Ravi\"/&gt;&lt;/body&gt;&lt;/html&gt;\n",
       "</pre>\n",
       "<p>We add a new id tag, and delete the value tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup('&lt;input type=\"text\" name=\"name\" value=\"Raju\"&gt;', 'lxml')\n",
       "tag = soup.input\n",
       "\n",
       "tag['id']='nm'\n",
       "del tag['value']\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;&lt;body&gt;&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;&lt;/body&gt;&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Multi-valued attributes</h3>\n",
       "<p>Some of the HTML5 attributes can have multiple values. Most commonly used is the class-attribute which can have multiple CSS-values. Others include 'rel', 'rev', 'headers', 'accesskey' and 'accept-charset'. The multi-valued attributes in beautiful soup are shown as list.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "css_soup = BeautifulSoup('&lt;p class=\"body\"&gt;&lt;/p&gt;', 'lxml')\n",
       "print (\"css_soup.p['class']:\", css_soup.p['class'])\n",
       "\n",
       "css_soup = BeautifulSoup('&lt;p class=\"body bold\"&gt;&lt;/p&gt;', 'lxml')\n",
       "print (\"css_soup.p['class']:\", css_soup.p['class'])\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "css_soup.p['class']: ['body']\n",
       "css_soup.p['class']: ['body', 'bold']\n",
       "</pre>\n",
       "<p>However, if any attribute contains more than one value but it is not multi-valued attributes by any-version of HTML standard, beautiful soup will leave the attribute alone </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "id_soup = BeautifulSoup('&lt;p id=\"body bold\"&gt;&lt;/p&gt;', 'lxml')\n",
       "print (\"id_soup.p['id']:\", id_soup.p['id'])\n",
       "print (\"type(id_soup.p['id']):\", type(id_soup.p['id']))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "id_soup.p['id']: body bold\n",
       "type(id_soup.p['id']): &lt;class 'str'&gt;\n",
       "</pre>\n",
       "<h2>NavigableString object</h2>\n",
       "<p>Usually, a certain string is placed in opening and closing tag of a certain type. The HTML engine of the browser applies the intended effect on the string while rendering the element. For example , in &lt;b&gt;Hello World&lt;/b&gt;, you find a string in the middle of &lt;b&gt; and &lt;/b&gt; tags so that it is rendered in bold.</p>\n",
       "<p>The NavigableString object represents the contents of a tag. It is an object of bs4.element.NavigableString class. To access the contents, use \".string\" with tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(\"&lt;h2 id='message'&gt;Hello, Tutorialspoint!&lt;/h2&gt;\", 'html.parser')\n",
       "\n",
       "print (soup.string)\n",
       "\n",
       "print (type(soup.string))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Hello, Tutorialspoint!\n",
       "&lt;class 'bs4.element.NavigableString'&gt;\n",
       "</pre>\n",
       "<p>A NavigableString object is similar to a Python Unicode string. some of its features support Navigating the tree and Searching the tree. A NavigableString can be converted to a  Unicode string with str() function.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(\"&lt;h2 id='message'&gt;Hello, Tutorialspoint!&lt;/h2&gt;\",'html.parser')\n",
       "\n",
       "tag = soup.h2\n",
       "string = str(tag.string)\n",
       "print (string)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Hello, Tutorialspoint!\n",
       "</pre>\n",
       "<p>Just as a Python string, which is immutable, the NavigableString also can't be modified in place. However, use replace_with() to replace the inner string of a tag with another.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(\"&lt;h2 id='message'&gt;Hello, Tutorialspoint!&lt;/h2&gt;\",'html.parser')\n",
       "\n",
       "tag = soup.h2\n",
       "tag.string.replace_with(\"OnLine Tutorials Library\")\n",
       "print (tag.string)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "OnLine Tutorials Library\n",
       "</pre>\n",
       "<h2>BeautifulSoup object</h2>\n",
       "<p>The BeautifulSoup object represents the entire parsed object. However, it can be considered to be similar to Tag object. It is the object created when we try to scrape a web resource. Because it is similar to a Tag object, it supports the functionality required to parse and search the document tree.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "print (soup)\n",
       "print (soup.name)\n",
       "print ('type:',type(soup))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "&lt;h2&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "&lt;ul&gt;\n",
       "&lt;li&gt;Accounts&lt;/li&gt;\n",
       "&lt;ul&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;li&gt;HR&lt;/li&gt;\n",
       "&lt;ul&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "[document]\n",
       "type: &lt;class 'bs4.BeautifulSoup'&gt;\n",
       "</pre>\n",
       "<p>The name property of BeautifulSoup object always returns [document].</p>\n",
       "<p>Two parsed documents can be combined if you pass a BeautifulSoup object as an argument to a certain function such as replace_with().</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "obj1 = BeautifulSoup(\"&lt;book&gt;&lt;title&gt;Python&lt;/title&gt;&lt;/book&gt;\", features=\"xml\")\n",
       "obj2 = BeautifulSoup(\"&lt;b&gt;Beautiful Soup parser&lt;/b&gt;\", \"lxml\")\n",
       "\n",
       "obj2.find('b').replace_with(obj1)\n",
       "print (obj2)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;&lt;body&gt;&lt;book&gt;&lt;title&gt;Python&lt;/title&gt;&lt;/book&gt;&lt;/body&gt;&lt;/html&gt;\n",
       "</pre>\n",
       "<h2>Comment object</h2>\n",
       "<p>Any text written between &lt;!-- and --&gt; in HTML as well as XML document is treated as comment. BeautifulSoup can detect such commented text as a Comment object.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "markup = \"&lt;b&gt;&lt;!--This is a comment text in HTML--&gt;&lt;/b&gt;\"\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "comment = soup.b.string\n",
       "print (comment, type(comment))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "This is a comment text in HTML &lt;class 'bs4.element.Comment'&gt;\n",
       "</pre>\n",
       "<p>The Comment object is a special type of NavigableString object. The prettify() method displays the comment text with special formatting </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "print (soup.b.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   &lt;!--This is a comment text in HTML--&gt;\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Inspect Data Source</h1>\n",
       "<p>In order to scrape a web page with BeautifulSoup and Python, your first step for any web scraping project should be to explore the website that you want to scrape. So, first visit the website to understand the site structure before you start extracting the information that's relevant for you.</p>\n",
       "<p>Let us visit TutorialsPoint's Python Tutorial home page. Open  <a href=\"https://www.tutorialspoint.com/python3/index.htm\" target=\"_blank\">https://www.tutorialspoint.com/python3/index.htm</a> in your browser.</p>\n",
       "<p>Use Developer tools can help you understand the structure of a website. All modern browsers come with developer tools installed. </p>\n",
       "<p>If using Chrome browser, open the Developer Tools from the top-right menu button () and selecting More Tools  Developer Tools.</p>\n",
       "<img alt=\"Developer Tools\" src=\"/beautiful_soup/images/developer_tools.jpg\"/>\n",
       "<p>With Developer tools, you can explore the site's document object model (DOM) to better understand your source. Select the Elements tab in developer tools. You'll see a structure with clickable HTML elements.</p>\n",
       "<p>The Tutorial page shows the table of contents in the left sidebar. Right click on any chapter and choose Inspect option.</p>\n",
       "<img alt=\"tutorial_page\" src=\"/beautiful_soup/images/tutorial_page.jpg\"/>\n",
       "<p>For the Elements tab, locate the tag that corresponds to the TOC list, as shown in the figure below </p>\n",
       "<img alt=\"TOC_list\" src=\"/beautiful_soup/images/TOC_list.jpg\"/>\n",
       "<p>Right click on the HTML element, copy the HTML element, and paste it in any editor.</p>\n",
       "<img alt=\"html element\" src=\"/beautiful_soup/images/html_element.jpg\"/>\n",
       "<p>The HTML script of the &lt;ul&gt;..&lt;/ul&gt; element is now obtained.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "&lt;ul class=\"toc chapters\"&gt;\n",
       "   &lt;li class=\"heading\"&gt;Python 3 Basic Tutorial&lt;/li&gt;\n",
       "   &lt;li class=\"current-chapter\"&gt;&lt;a href=\"/python3/index.htm\"&gt;Python 3 - Home&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python3_whatisnew.htm\"&gt;What is New in Python 3&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_overview.htm\"&gt;Python 3 - Overview&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_environment.htm\"&gt;Python 3 - Environment Setup&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_basic_syntax.htm\"&gt;Python 3 - Basic Syntax&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_variable_types.htm\"&gt;Python 3 - Variable Types&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_basic_operators.htm\"&gt;Python 3 - Basic Operators&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_decision_making.htm\"&gt;Python 3 - Decision Making&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_loops.htm\"&gt;Python 3 - Loops&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_numbers.htm\"&gt;Python 3 - Numbers&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_strings.htm\"&gt;Python 3 - Strings&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_lists.htm\"&gt;Python 3 - Lists&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_tuples.htm\"&gt;Python 3 - Tuples&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_dictionary.htm\"&gt;Python 3 - Dictionary&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_date_time.htm\"&gt;Python 3 - Date &amp; Time&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_functions.htm\"&gt;Python 3 - Functions&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_modules.htm\"&gt;Python 3 - Modules&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_files_io.htm\"&gt;Python 3 - Files I/O&lt;/a&gt;&lt;/li&gt;\n",
       "   &lt;li&gt;&lt;a href=\"/python3/python_exceptions.htm\"&gt;Python 3 - Exceptions&lt;/a&gt;&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "</pre>\n",
       "<p>We can now load this script in a BeautifulSoup object to parse the document tree.</p>\n",
       "<h1>Beautiful Soup - Scrape HTML Content</h1>\n",
       "<p>The process of extracting data from websites is called Web scraping. A web page may have urls, Email addresses, images or any other content, which we can be stored in a file or database. Searching a website manually is cumbersome process. There are different web scaping tools that automate the process. </p>\n",
       "<p>Web scraping is is sometimes prohibited by the use of 'robots.txt' file. Some popular sites provide APIs to access their data in a structured way. Unethical web scraping may result in getting your IP blocked.</p>\n",
       "<p>Python is widely used for web scraping. Python standard library has urllib package, which can be used to extract data from HTML pages. Since urllib module is bundled with the standard library, it need not be installed.</p>\n",
       "<p>The urllib package is an HTTP client for python programming language. The urllib.request module is usefule when we want to open and read URLs. Other module in urllib package are </p>\n",
       "<ul class=\"list\">\n",
       "<li><p>urllib.error defines the exceptions and errors raised by the urllib.request command.</p></li>\n",
       "<li><p>urllib.parse is used for parsing URLs.</p></li>\n",
       "<li><p>urllib.robotparser is used for parsing robots.txt files.</p></li>\n",
       "</ul>\n",
       "<p>Use the urlopen() function in urllib module to read the content of a web page from a website.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "import urllib.request\n",
       "response =  urllib.request.urlopen('http://python.org/') \n",
       "html = response.read()\n",
       "</pre>\n",
       "<p>You can also use the requests library for this purpose. You need to install it before using.</p>\n",
       "<p>pip3 install requests</p>\n",
       "<p>In the below code, the homepage of <a href=\"http://www.tutorialspoint.com\" target=\"_blank\">http://www.tutorialspoint.com</a> is scraped </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "import requests\n",
       "\n",
       "\n",
       "url = \"https://www.tutorialspoint.com/index.htm\"\n",
       "req = requests.get(url)\n",
       "</pre>\n",
       "<p>The content obtained by either of the above two methods are then parsed with Beautiful Soup.</p>\n",
       "<h1>Beautiful Soup - Navigating by Tags</h1>\n",
       "<p>One of the important pieces of element in any piece of HTML document are tags, which may contain other tags/strings (tag's children). Beautiful Soup provides different ways to navigate and iterate over's tag's children.</p>\n",
       "<p>Easiest way to search a parse tree is to search the tag by its name.</p>\n",
       "<h2>soup.head</h2>\n",
       "<p>The soup.head function returns the contents put inside the &lt;head&gt; .. &lt;/head&gt; element of a HTML page.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "Consider the following HTML page to be scraped:\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "      &lt;script&gt;\n",
       "         document.write(\"Welcome to TutorialsPoint\");\n",
       "      &lt;/script&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h1&gt;Tutorialspoint Online Library&lt;/h1&gt;\n",
       "      &lt;p&gt;&lt;b&gt;It's all Free&lt;/b&gt;&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Following code extracts the contents of &lt;head&gt; element</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "with open(\"index.html\") as fp:\n",
       "   soup = BeautifulSoup(fp, 'html.parser')\n",
       "print(soup.head)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;head&gt;\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "&lt;script&gt;\n",
       "document.write(\"Welcome to TutorialsPoint\");\n",
       "&lt;/script&gt;\n",
       "&lt;/head&gt;\n",
       "</pre>\n",
       "<h2>soup.body</h2>\n",
       "<p>Similarly, to return the contents of body part of HTML page, use soup.body</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "with open(\"index.html\") as fp:\n",
       "   soup = BeautifulSoup(fp, 'html.parser')\n",
       "print (soup.body)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;body&gt;\n",
       "&lt;h1&gt;Tutorialspoint Online Library&lt;/h1&gt;\n",
       "&lt;p&gt;&lt;b&gt;It's all Free&lt;/b&gt;&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "</pre>\n",
       "<p>You can also extract specific tag (like first &lt;h1&gt; tag) in the &lt;body&gt; tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "with open(\"index.html\") as fp:\n",
       "   soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "print(soup.body.h1)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;h1&gt;Tutorialspoint Online Library&lt;/h1&gt;\n",
       "</pre>\n",
       "<h2>soup.p</h2>\n",
       "<p>Our HTML file contains a &lt;p&gt; tag. We can extract the contents of this tag</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "with open(\"index.html\") as fp:\n",
       "   soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "print(soup.p)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;&lt;b&gt;It's all Free&lt;/b&gt;&lt;/p&gt;\n",
       "</pre>\n",
       "<h2>Tag.contents</h2>\n",
       "<p>A Tag object may have one or more PageElements. The Tag object's contents property returns a list of all elements included in it.</p>\n",
       "<p>Let us find the elements in &lt;head&gt; tag of our index.html file.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "with open(\"index.html\") as fp:\n",
       "   soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.head\n",
       "print (tag.contents)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['\\n',\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;,\n",
       "'\\n',\n",
       "&lt;script&gt;\n",
       "document.write(\"Welcome to TutorialsPoint\");\n",
       "&lt;/script&gt;,\n",
       "'\\n']\n",
       "</pre>\n",
       "<h2>Tag.children</h2>\n",
       "<p>The structure of tags in a HTML script is hierarchical. The elements are nested one inside the other. For example, the top level &lt;HTML&gt; tag includes &lt;HEAD&gt; and &lt;BODY&gt; tags, each may have other tags in it.</p>\n",
       "<p>The Tag object has a children property that returns a list iterator object containing the enclosed PageElements.</p>\n",
       "<p>To demonstrate the children property, we shall use the following HTML script (index.html). In the &lt;body&gt; section, there are two &lt;ul&gt; list elements, one nested in another. In other words, the body tag has top level list elements, and each list element has another list under it.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "      &lt;ul&gt;\n",
       "      &lt;li&gt;Accounts&lt;/li&gt;\n",
       "         &lt;ul&gt;\n",
       "         &lt;li&gt;Anand&lt;/li&gt;\n",
       "         &lt;li&gt;Mahesh&lt;/li&gt;\n",
       "         &lt;/ul&gt;\n",
       "      &lt;li&gt;HR&lt;/li&gt;\n",
       "         &lt;ul&gt;\n",
       "         &lt;li&gt;Rani&lt;/li&gt;\n",
       "         &lt;li&gt;Ankita&lt;/li&gt;\n",
       "         &lt;/ul&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The following Python code gives a list of all the children elements of top level &lt;ul&gt; tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "with open(\"index.html\") as fp:\n",
       "   soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.ul\n",
       "print (list(tag.children))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['\\n', &lt;li&gt;Accounts&lt;/li&gt;, '\\n', &lt;ul&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;, '\\n', &lt;li&gt;HR&lt;/li&gt;, '\\n', &lt;ul&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ul&gt;, '\\n']\n",
       "</pre>\n",
       "<p>Since the .children property returns a list_iterator, we can use a for loop to traverse the hierarchy.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "for child in tag.children:\n",
       "   print (child)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;li&gt;Accounts&lt;/li&gt;\n",
       "\n",
       "&lt;ul&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "\n",
       "&lt;li&gt;HR&lt;/li&gt;\n",
       "\n",
       "&lt;ul&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "</pre>\n",
       "<h2>Tag.find_all()</h2>\n",
       "<p>This method returns a result set of contents of all the tags matching with the argument tag provided.</p>\n",
       "<p>Let us consider the following HTML page(index.html) for this </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h1&gt;Tutorialspoint Online Library&lt;/h1&gt;\n",
       "      &lt;p&gt;&lt;b&gt;It's all Free&lt;/b&gt;&lt;/p&gt;\n",
       "      &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/java/java_overview.htm\" id=\"link1\"&gt;Java&lt;/a&gt;\n",
       "      &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/cprogramming/index.htm\" id=\"link2\"&gt;C&lt;/a&gt;\n",
       "      &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/python/index.htm\" id=\"link3\"&gt;Python&lt;/a&gt;\n",
       "      &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/javascript/javascript_overview.htm\" id=\"link4\"&gt;JavaScript&lt;/a&gt;\n",
       "      &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/ruby/index.htm\" id=\"link5\"&gt;C&lt;/a&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The following code lists all the elements with &lt;a&gt; tag</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "with open(\"index.html\") as fp:\n",
       "   soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "result = soup.find_all(\"a\")\n",
       "print (result)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[\n",
       "   &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/java/java_overview.htm\" id=\"link1\"&gt;Java&lt;/a&gt;,\n",
       "   &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/cprogramming/index.htm\" id=\"link2\"&gt;C&lt;/a&gt;,\n",
       "   &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/python/index.htm\" id=\"link3\"&gt;Python&lt;/a&gt;,\n",
       "   &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/javascript/javascript_overview.htm\" id=\"link4\"&gt;JavaScript&lt;/a&gt;,\n",
       "   &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/ruby/index.htm\" id=\"link5\"&gt;C&lt;/a&gt;\n",
       "]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Find Elements by ID</h1>\n",
       "<p>In an HTML document, usually each element is assigned a unique ID. This enables the value of an element to be extracted by a front-end code such as JavaScript function.</p>\n",
       "<p>With BeautifulSoup, you can find the contents of a given element by its ID. There are two methods by which this can be achieved - find() as well as find_all(), and select()</p>\n",
       "<h2>Using find() method</h2>\n",
       "<p>The find() method of BeautifulSoup object searches for first element that satisfies the given criteria as an argument.</p>\n",
       "<p>Let us use the following HTML script (as index.html) for the purpose</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;form&gt;\n",
       "         &lt;input type = 'text' id = 'nm' name = 'name'&gt;\n",
       "         &lt;input type = 'text' id = 'age' name = 'age'&gt;\n",
       "         &lt;input type = 'text' id = 'marks' name = 'marks'&gt;\n",
       "      &lt;/form&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The following Python code finds the element with its id as nm</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.find(id = 'nm')\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h2>Using find_all()</h2>\n",
       "<p>The find_all() method also accepts a filter argument. It returns a list of all the elements with the given id. In a certain HTML document, usually a single element with a particular id. Hence, using find() instead of find_all() is preferrable to search for a given id.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.find_all(id = 'nm')\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<p>Note that the find_all() method returns a list. The find_all() method also has a limit parameter. Setting limit=1 to find_all() is equivalent to find()</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj = soup.find_all(id = 'nm', limit=1)\n",
       "</pre>\n",
       "<h2>Using select() method</h2>\n",
       "<p>The select() method in BeautifulSoup class accepts CSS selector as an argument. The # symbol is the CSS selector for id. It followed by the value of required id is passed to select() method. It works as the find_all() method.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.select(\"#nm\")\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h2>Using select_one()</h2>\n",
       "<p>Like the find_all() method, the select() method also returns a list. There is also a select_one() method to return the first tag of the given argument.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.select_one(\"#nm\")\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Find Elements by Class</h1>\n",
       "<p>CSS (cascaded Style sheets) is a tool for designing the appearance of HTML elements. CSS rules control the different aspects of HTML element such as size, color, alignment etc.. Applying styles is more effective than defining HTML element attributes. You can apply styling rules to each HTML element. Instead of applying style to each element individually, CSS classes are used to apply similar styling to groups of HTML elements to achieve uniform web page appearance. In BeautifulSoup, it is possible to find tags styled with CSS class. In this chapter, we shall use the following methods to search for elements for a specified CSS class </p>\n",
       "<ul class=\"list\">\n",
       "<li>find_all() and find() methods</li>\n",
       "<li>select() and select_one() methods</li>\n",
       "</ul>\n",
       "<h2>Class in CSS</h2>\n",
       "<p>A class in CSS is a collection of attributes specifying the different features related to appearance, such as font type, size and color, background color, alignment etc. Name of the class is prefixed with a dot (.) while declaring it.</p>\n",
       "<pre class=\"just-code notranslate language-css\" data-lang=\"css\">\n",
       ".class {  \n",
       "   css declarations;  \n",
       "}\n",
       "</pre>\n",
       "<p>A CSS class may be defined inline, or in a separate css file which needs to be included in the HTML script. A typical example of a CSS class could be as follows </p>\n",
       "<pre class=\"just-code notranslate language-css\" data-lang=\"css\">\n",
       ".blue-text {\n",
       "   color: blue;\n",
       "   font-weight: bold;\n",
       "}\n",
       "</pre>\n",
       "<p>You can search for HTML elements defined with a certain class style with the help of following BeautifulSoup methods.</p>\n",
       "<p>For the purpose of this chapter, we shall use the following HTML page </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2 class=\"heading\"&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "      &lt;ul&gt;\n",
       "         &lt;li class=\"mainmenu\"&gt;Accounts&lt;/li&gt;\n",
       "         &lt;ul&gt;\n",
       "            &lt;li class=\"submenu\"&gt;Anand&lt;/li&gt;\n",
       "            &lt;li class=\"submenu\"&gt;Mahesh&lt;/li&gt;\n",
       "         &lt;/ul&gt;\n",
       "         &lt;li class=\"mainmenu\"&gt;HR&lt;/li&gt;\n",
       "         &lt;ul&gt;\n",
       "            &lt;li class=\"submenu\"&gt;Rani&lt;/li&gt;\n",
       "            &lt;li class=\"submenu\"&gt;Ankita&lt;/li&gt;\n",
       "         &lt;/ul&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h2>Using find() and find_all()</h2>\n",
       "<p>To search for elements with a certain CSS class used in a tag, use <b>attrs</b> property of Tag object as follows </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.find_all(attrs={\"class\": \"mainmenu\"})\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;li class=\"mainmenu\"&gt;Accounts&lt;/li&gt;, &lt;li class=\"mainmenu\"&gt;HR&lt;/li&gt;]\n",
       "</pre>\n",
       "<p>The result is a list of all the elements with mainmenu class</p>\n",
       "<p>To fetch the list of elements with any of the CSS classes mentioned in in attrs property, change the find_all() statement to </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj = soup.find_all(attrs={\"class\": [\"mainmenu\", \"submenu\"]})\n",
       "</pre>\n",
       "<p>This results into a list of all the elements with any of CSS classes used above.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "[\n",
       "   &lt;li class=\"mainmenu\"&gt;Accounts&lt;/li&gt;, \n",
       "   &lt;li class=\"submenu\"&gt;Anand&lt;/li&gt;, \n",
       "   &lt;li class=\"submenu\"&gt;Mahesh&lt;/li&gt;, \n",
       "   &lt;li class=\"mainmenu\"&gt;HR&lt;/li&gt;, \n",
       "   &lt;li class=\"submenu\"&gt;Rani&lt;/li&gt;, \n",
       "   &lt;li class=\"submenu\"&gt;Ankita&lt;/li&gt;\n",
       "] \n",
       "</pre>\n",
       "<h2>Using select() and select_one()</h2>\n",
       "<p>You can also use select() method with the CSS selector as the argument. The (.) symbol followed by the name of the class is used as the CSS selector.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.select(\".heading\")\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;h2 class=\"heading\"&gt;Departmentwise Employees&lt;/h2&gt;]\n",
       "</pre>\n",
       "<p>The select_one() method returns the first element found with the given class.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj = soup.select_one(\".submenu\")\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Find Elements by Attribute</h1>\n",
       "<p>Both find() and find_all() methods are meant to find one or all the tags in the document as per the arguments passed to these methods. You can pass attrs parameter to these functions. The value of attrs must be a dictionary with one or more tag attributes and their values.</p>\n",
       "<p>For the purpose of checking the behaviour of these methods, we shall use the following HTML document (index.html)</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;form&gt;\n",
       "         &lt;input type = 'text' id = 'nm' name = 'name'&gt;\n",
       "         &lt;input type = 'text' id = 'age' name = 'age'&gt;\n",
       "         &lt;input type = 'text' id = 'marks' name = 'marks'&gt;\n",
       "      &lt;/form&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h2>Using find_all()</h2>\n",
       "<p>The following program returns a list of all the tags having input type=\"text\" attribute.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.find_all(attrs={\"type\":'text'})\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;, &lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;, &lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h2>Using find()</h2>\n",
       "<p>The find() method returns the first tag in the parsed document that has the given attributes.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj = soup.find(attrs={\"name\":'marks'})\n",
       "</pre>\n",
       "<h2>Using select()</h2>\n",
       "<p>The select() method can be called by passing the attributes to be compared against. The attributes must be put in a list object. It returns a list of all tags that have the given attribute.</p>\n",
       "<p>In the following code, the select() method returns all the tags with type attribute.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.select(\"[type]\")\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;, &lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;, &lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h2>Using select_one()</h2>\n",
       "<p>The select_one() is method is similar, except that it returns the first tag satisfying the given filter.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj = soup.select_one(\"[name='marks']\")\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Searching the Tree</h1>\n",
       "<p>In this chapter, we shall discuss different methods in Beautiful Soup for navigating the HTML document tree in different directions - going up and down, sideways, and back and forth.</p>\n",
       "<p>We shall use the following HTML string in all the examples in this chapter </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "html = \"\"\"\n",
       "&lt;html&gt;&lt;head&gt;&lt;title&gt;TutorialsPoint&lt;/title&gt;&lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p class=\"title\"&gt;&lt;b&gt;Online Tutorials Library&lt;/b&gt;&lt;/p&gt;\n",
       "\n",
       "      &lt;p class=\"story\"&gt;TutorialsPoint has an excellent collection of tutorials on:\n",
       "      &lt;a href=\"https://tutorialspoint.com/Python\" class=\"lang\" id=\"link1\"&gt;Python&lt;/a&gt;,\n",
       "      &lt;a href=\"https://tutorialspoint.com/Java\" class=\"lang\" id=\"link2\"&gt;Java&lt;/a&gt; and\n",
       "      &lt;a href=\"https://tutorialspoint.com/PHP\" class=\"lang\" id=\"link3\"&gt;PHP&lt;/a&gt;;\n",
       "      Enhance your Programming skills.&lt;/p&gt;\n",
       "\n",
       "      &lt;p class=\"tutorial\"&gt;...&lt;/p&gt;\n",
       "\"\"\"\n",
       "</pre>\n",
       "<p>The name of required tag lets you navigate the parse tree. For example soup.head fetches you the &lt;head&gt; element </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "print (soup.head.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;head&gt;\n",
       "   &lt;title&gt;\n",
       "      TutorialsPoint\n",
       "   &lt;/title&gt;\n",
       "&lt;/head&gt;\n",
       "</pre>\n",
       "<h2>Going down</h2>\n",
       "<p>A tag may contain strings or other tags enclosed in it. The .contents property of Tag object returns a list of all the children elements belonging to it.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag = soup.head \n",
       "print (list(tag.children))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;title&gt;TutorialsPoint&lt;/title&gt;]\n",
       "</pre>\n",
       "<p>The returned object is a list, although in this case, there is only a single child tag enclosed in head element.</p>\n",
       "<h3>.children</h3>\n",
       "<p>The .children property also returns a list of all the enclosed elements in a tag. Below, all the elements in body tag are given as a list.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag = soup.body \n",
       "print (list(tag.children))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['\\n', &lt;p class=\"title\"&gt;&lt;b&gt;Online Tutorials Library&lt;/b&gt;&lt;/p&gt;, '\\n', \n",
       "&lt;p class=\"story\"&gt;TutorialsPoint has an excellent collection of tutorials on:\n",
       "&lt;a class=\"lang\" href=\"https://tutorialspoint.com/Python\" id=\"link1\"&gt;Python&lt;/a&gt;,\n",
       "&lt;a class=\"lang\" href=\"https://tutorialspoint.com/Java\" id=\"link2\"&gt;Java&lt;/a&gt; and\n",
       "&lt;a class=\"lang\" href=\"https://tutorialspoint.com/PHP\" id=\"link3\"&gt;PHP&lt;/a&gt;;\n",
       "Enhance your Programming skills.&lt;/p&gt;, '\\n', &lt;p class=\"tutorial\"&gt;...&lt;/p&gt;, '\\n']\n",
       "</pre>\n",
       "<p>Instead of getting them as a list, you can iterate over a tag's children using the .children generator </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag = soup.body \n",
       "for child in tag.children:\n",
       "   print (child)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p class=\"title\"&gt;&lt;b&gt;Online Tutorials Library&lt;/b&gt;&lt;/p&gt;\n",
       "&lt;p class=\"story\"&gt;TutorialsPoint has an excellent collection of tutorials on:\n",
       "&lt;a class=\"lang\" href=\"https://tutorialspoint.com/Python\" id=\"link1\"&gt;Python&lt;/a&gt;,\n",
       "&lt;a class=\"lang\" href=\"https://tutorialspoint.com/Java\" id=\"link2\"&gt;Java&lt;/a&gt; and\n",
       "&lt;a class=\"lang\" href=\"https://tutorialspoint.com/PHP\" id=\"link3\"&gt;PHP&lt;/a&gt;;\n",
       "Enhance your Programming skills.&lt;/p&gt;\n",
       "\n",
       "\n",
       "&lt;p class=\"tutorial\"&gt;...&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>.descendents</h3>\n",
       "<p>The .contents and .children attributes only consider a tag's direct children. The .descendants attribute lets you iterate over all of a tag's children, recursively: its direct children, the children of its direct children, and so on.</p>\n",
       "<p>The BeautifulSoup object is at the top of hierarchy of all the tags. Hence its .descendents property includes all the elements in the HTML string.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "print (soup.descendants)\n",
       "</pre>\n",
       "<p>The .descendents attribute returns a generator, which can be iterated with a for loop. Here, we list out the descendents of the head tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.head\n",
       "for element in tag.descendants:\n",
       "   print (element)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "TutorialsPoint\n",
       "</pre>\n",
       "<p>The head tag contains a title tag, which in turn encloses a NavigableString object TutorialsPoint. The &lt;head&gt; tag has only one child, but it has two descendants: the &lt;title&gt; tag and the &lt;title&gt; tag's child. But the BeautifulSoup object only has one direct child (the &lt;html&gt; tag), but it has many descendants.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tags = list(soup.descendants)\n",
       "print (len(tags))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "27\n",
       "</pre>\n",
       "<h2>Going Up</h2>\n",
       "<p>Just as you navigate the downstream of a document with children and descendents properties, BeautifulSoup offers .parent and .parent properties to navigate the upstream of a tag</p>\n",
       "<h3>.parent</h3>\n",
       "<p>every tag and every string has a parent tag that contains it. You can access an element's parent with the parent attribute. In our example, the &lt;head&gt; tag is the parent of the &lt;title&gt; tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag = soup.title\n",
       "print (tag.parent)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;head&gt;&lt;title&gt;TutorialsPoint&lt;/title&gt;&lt;/head&gt;\n",
       "</pre>\n",
       "<p>Since the title tag contains a string (NavigableString), the parent for the string is title tag itself.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag = soup.title\n",
       "string = tag.string\n",
       "print (string.parent)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "</pre>\n",
       "<h3>.parents</h3>\n",
       "<p>You can iterate over all of an element's parents with .parents. This example uses .parents to travel from an &lt;a&gt; tag buried deep within the document, to the very top of the document. In the following code, we track the parents of the first &lt;a&gt; tag in the example HTML string.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag = soup.a \n",
       "print (tag.string)\n",
       "\n",
       "for parent in tag.parents:\n",
       "   print (parent.name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Python\n",
       "p\n",
       "body\n",
       "html\n",
       "[document]\n",
       "</pre>\n",
       "<h2>Sideways</h2>\n",
       "<p>The HTML tags appearing at the same indentation level are called siblings. Consider the following HTML snippet</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;p&gt;\n",
       "   &lt;b&gt;\n",
       "      Hello\n",
       "   &lt;/b&gt;\n",
       "   &lt;i&gt;\n",
       "      Python\n",
       "   &lt;/i&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<p>In the outer &lt;p&gt; tag, we have &lt;b&gt; and &lt;i&gt; tags at the same indent level, hence they are called siblings. BeautifulSoup makes it possible to navigate between the tags at same level.</p>\n",
       "<h3>.next_sibling and .previous_sibling</h3>\n",
       "<p>These attributes respectively return the next tag at the same level, and the previous tag at same level.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.b \n",
       "print (\"next:\",tag1.next_sibling)\n",
       "\n",
       "tag2 = soup.i \n",
       "print (\"previous:\",tag2.previous_sibling)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next: &lt;i&gt;Python&lt;/i&gt;\n",
       "previous: &lt;b&gt;Hello&lt;/b&gt;\n",
       "</pre>\n",
       "<p>Since the &lt;b&gt; tag doesn't have a sibling to its left, and &lt;i&gt; tag doesn't have a sibling to its right, it returns Nobe in both cases.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.b \n",
       "print (\"next:\",tag1.previous_sibling)\n",
       "\n",
       "tag2 = soup.i \n",
       "print (\"previous:\",tag2.next_sibling)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next: None\n",
       "previous: None\n",
       "</pre>\n",
       "<h3>.next_siblings and .previous_siblings</h3>\n",
       "<p>If there are two or more siblings to the right or left of a tag, they can be navigated with the help of the .next_siblings and .previous_siblings attributes respectively. Both of them return generator object so that a for loop can be used to iterate.</p>\n",
       "<p>Let us use the following HTML snippet for this purpose </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;p&gt;\n",
       "   &lt;b&gt;\n",
       "      Excellent\n",
       "   &lt;/b&gt;\n",
       "   &lt;i&gt;\n",
       "      Python\n",
       "   &lt;/i&gt;\n",
       "   &lt;u&gt;\n",
       "      Tutorial\n",
       "   &lt;/u&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<p>Use the following code to traverse next and previous sibling tags.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;u&gt;Tutorial&lt;/u&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.b \n",
       "print (\"next siblings:\")\n",
       "for tag in tag1.next_siblings:\n",
       "   print (tag)\n",
       "print (\"previous siblings:\")\n",
       "tag2 = soup.u \n",
       "for tag in tag2.previous_siblings:\n",
       "   print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next siblings:\n",
       "&lt;i&gt;Python&lt;/i&gt;\n",
       "&lt;u&gt;Tutorial&lt;/u&gt;\n",
       "previous siblings:\n",
       "&lt;i&gt;Python&lt;/i&gt;\n",
       "&lt;b&gt;Excellent&lt;/b&gt;\n",
       "</pre>\n",
       "<h2>Back and forth</h2>\n",
       "<p>In Beautiful Soup, the next_element property returns the next string or tag in the parse tree. On the other hand, the previous_element property returns the previous string or tag in the parse tree. Sometimes, the return value of next_element and previous_element attributes is similar to next_sibling and previous_sibling properties.</p>\n",
       "<h3>.next_element and .previous_element</h3>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;html&gt;&lt;head&gt;&lt;title&gt;TutorialsPoint&lt;/title&gt;&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p class=\"title\"&gt;&lt;b&gt;Online Tutorials Library&lt;/b&gt;&lt;/p&gt;\n",
       "\n",
       "&lt;p class=\"story\"&gt;TutorialsPoint has an excellent collection of tutorials on:\n",
       "&lt;a href=\"https://tutorialspoint.com/Python\" class=\"lang\" id=\"link1\"&gt;Python&lt;/a&gt;,\n",
       "&lt;a href=\"https://tutorialspoint.com/Java\" class=\"lang\" id=\"link2\"&gt;Java&lt;/a&gt; and\n",
       "&lt;a href=\"https://tutorialspoint.com/PHP\" class=\"lang\" id=\"link3\"&gt;PHP&lt;/a&gt;;\n",
       "Enhance your Programming skills.&lt;/p&gt;\n",
       "\n",
       "&lt;p class=\"tutorial\"&gt;...&lt;/p&gt;\n",
       "\"\"\"\n",
       "\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag = soup.find(\"a\", id=\"link3\")\n",
       "print (tag.next_element)\n",
       "\n",
       "tag = soup.find(\"a\", id=\"link1\")\n",
       "print (tag.previous_element)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "PHP\n",
       "TutorialsPoint has an excellent collection of tutorials on:\n",
       "</pre>\n",
       "<p>The next_element after &lt;a&gt; tag with id = \"link3\" is the string PHP. Similarly, the previous_element returns the string before &lt;a&gt; tag with id = \"link1\".</p>\n",
       "<h3>.next_elements and .previous_elements</h3>\n",
       "<p>These attributes of the Tag object return generator respectively of all tags and strings after and before it.</p>\n",
       "<p><b>Next elements example</b></p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag = soup.find(\"a\", id=\"link1\")\n",
       "for element in tag.next_elements:\n",
       "   print (element)\n",
       "</pre>\n",
       "<p><b>Output</b></p>\n",
       "<pre class=\"result notranslate\">\n",
       "Python\n",
       ",\n",
       "\n",
       "&lt;a class=\"lang\" href=\"https://tutorialspoint.com/Java\" id=\"link2\"&gt;Java&lt;/a&gt;\n",
       "Java\n",
       " and\n",
       "\n",
       "&lt;a class=\"lang\" href=\"https://tutorialspoint.com/PHP\" id=\"link3\"&gt;PHP&lt;/a&gt;\n",
       "PHP\n",
       ";\n",
       "Enhance your Programming skills.\n",
       "\n",
       "\n",
       "&lt;p class=\"tutorial\"&gt;...&lt;/p&gt;\n",
       "...\n",
       "</pre>\n",
       "<p><b>Previous elements example</b></p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag = soup.find(\"body\")\n",
       "for element in tag.previous_elements:\n",
       "   print (element)\n",
       "</pre>\n",
       "<p><b>Output</b></p>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;&lt;head&gt;&lt;title&gt;TutorialsPoint&lt;/title&gt;&lt;/head&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Modifying the Tree</h1>\n",
       "<p>One of the powerful features of Beautiful Soup library is to be able to be able to manipulate the parsed HTML or XML document and modify its contents.</p>\n",
       "<p>Beautiful Soup library has different functions to perform the following operations </p>\n",
       "<ul class=\"list\">\n",
       "<li><p>Add contents or a new tag to an existing tag of the document</p></li>\n",
       "<li><p>Insert contents before or after an existing tag or string</p></li>\n",
       "<li><p>Clear the contents of an already existing tag</p></li>\n",
       "<li><p>Modify the contents of a tag element</p></li>\n",
       "</ul>\n",
       "<h2>Add content</h2>\n",
       "<p>You can add to the content of an existing tag by using <b>append()</b> method on a Tag object. It works like the append() method of Python's list object.</p>\n",
       "<p>In the following example, the HTML script has a &lt;p&gt; tag. With append(), additional text is appended.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "markup = '&lt;p&gt;Hello&lt;/p&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "print (soup)\n",
       "tag = soup.p\n",
       "\n",
       "tag.append(\" World\")\n",
       "print (soup) \n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Hello&lt;/p&gt;\n",
       "&lt;p&gt;Hello World&lt;/p&gt;\n",
       "</pre>\n",
       "<p>With the append() method, you can add a new tag at the end of an existing tag. First create a new Tag object with <b>new_tag()</b> method and then pass it to the append() method.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, Tag\n",
       "\n",
       "markup = '&lt;b&gt;Hello&lt;/b&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.b \n",
       "tag1 = soup.new_tag('i')\n",
       "tag1.string = 'World'\n",
       "tag.append(tag1)\n",
       "print (soup.prettify()) \n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Hello\n",
       "   &lt;i&gt;\n",
       "      World\n",
       "   &lt;/i&gt;\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<p>If you have to add a string to the document, you can append a <b>NavigableString</b> object.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Hello&lt;/b&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.b \n",
       "new_string = NavigableString(\" World\")\n",
       "tag.append(new_string)\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Hello\n",
       "   World\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<p>From Beautiful Soup version 4.7 onwards, the extend() method has been added to Tag class. It adds all the elements in a list to the tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "markup = '&lt;b&gt;Hello&lt;/b&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.b \n",
       "vals = ['World.', 'Welcome to ', 'TutorialsPoint']\n",
       "tag.extend(vals)\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Hello\n",
       "   World.\n",
       "   Welcome to\n",
       "   TutorialsPoint\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<h2>Insert Contents</h2>\n",
       "<p>Instead of adding a new element at the end, you can use <b>insert()</b> method to add an element at the given position in a the list of children of a Tag element. The insert() method in Beautiful Soup behaves similar to insert() on a Python list object.</p>\n",
       "<p>In the following example, a new string is added to the &lt;b&gt; tag at position 1. The resultant parsed document shows the result.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Excellent &lt;/b&gt;&lt;u&gt;from TutorialsPoint&lt;/u&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.b\n",
       "\n",
       "tag.insert(1, \"Tutorial \")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Excellent\n",
       "   Tutorial\n",
       "&lt;/b&gt;\n",
       "&lt;u&gt;\n",
       "   from TutorialsPoint\n",
       "&lt;/u&gt;\n",
       "</pre>\n",
       "<p>Beautiful Soup also has <b>insert_before()</b> and <b>insert_after()</b> methods. Their respective purpose is to insert a tag or a string before or after a given Tag object. The following code shows that a string \"Python Tutorial\" is added after the &lt;b&gt; tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Excellent &lt;/b&gt;&lt;u&gt;from TutorialsPoint&lt;/u&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.b\n",
       "\n",
       "tag.insert_after(\"Python Tutorial\")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Excellent\n",
       "&lt;/b&gt;\n",
       "Python Tutorial\n",
       "&lt;u&gt;\n",
       "   from TutorialsPoint\n",
       "&lt;/u&gt;\n",
       "</pre>\n",
       "<p>On the other hand, insert_before() method is used below, to add \"Here is an \" text before the &lt;b&gt; tag.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag.insert_before(\"Here is an \")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Here is an\n",
       "&lt;b&gt;\n",
       "   Excellent\n",
       "&lt;/b&gt;\n",
       "Python Tutorial\n",
       "&lt;u&gt;\n",
       "   from TutorialsPoint\n",
       "&lt;/u&gt;\n",
       "</pre>\n",
       "<h2>Clear the Contents</h2>\n",
       "<p>Beautiful Soup provides more than one ways to remove contents of an element from the document tree. Each of these methods has its unique features.</p>\n",
       "<p>The <b>clear()</b> method is the most straight-forward. It simply removes the contents of a specified Tag element. Following example shows its usage.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Excellent &lt;/b&gt;&lt;u&gt;from TutorialsPoint&lt;/u&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.find('u')\n",
       "\n",
       "tag.clear()\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Excellent\n",
       "&lt;/b&gt;\n",
       "&lt;u&gt;\n",
       "&lt;/u&gt;\n",
       "</pre>\n",
       "<p>It can be seen that the clear() method removes the contents, keeping the tag intact.</p>\n",
       "<p>For the following example, we parse the following HTML document and call clear() metho on all tags.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt; Bawds jog, flick quartz, vex nymphs./p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Here is the Python code using clear() method</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tags = soup.find_all()\n",
       "for tag in tags:\n",
       "   tag.clear()\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The <b>extract()</b> method removes either a tag or a string from the document tree, and returns the object that was removed.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tags = soup.find_all()\n",
       "for tag in tags:\n",
       "   obj = tag.extract()\n",
       "   print (\"Extracted:\",obj)\n",
       "\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Extracted: &lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "&lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "&lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "&lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "Extracted: &lt;body&gt;\n",
       "&lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "&lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "&lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "&lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "Extracted: &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "Extracted: &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "Extracted: &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "Extracted: &lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "</pre>\n",
       "<p>You can extract either a tag or a string. The following example shows antag being extracted.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;ol id=\"HR\"&gt;\n",
       "   &lt;li&gt;Rani&lt;/li&gt;\n",
       "   &lt;li&gt;Ankita&lt;/li&gt;\n",
       "   &lt;/ol&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "obj=soup.find('ol')\n",
       "obj.find_next().extract()\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;ol id=\"HR\"&gt;\n",
       "   &lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ol&gt;\n",
       "</pre>\n",
       "<p>Change the extract() statement to remove inner text of first &lt;li&gt; element.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj.find_next().string.extract()\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;ol id=\"HR\"&gt;\n",
       "   &lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ol&gt;\n",
       "</pre>\n",
       "<p>There is another method decompose() that removes a tag from the tree, then completely destroys it and its contents </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;ol id=\"HR\"&gt;\n",
       "      &lt;li&gt;Rani&lt;/li&gt;\n",
       "      &lt;li&gt;Ankita&lt;/li&gt;\n",
       "   &lt;/ol&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag1=soup.find('ol')\n",
       "tag2 = soup.find('li')\n",
       "tag2.decompose()\n",
       "print (soup)\n",
       "print (tag2.decomposed)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;ol id=\"HR\"&gt;\n",
       "\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ol&gt;\n",
       "</pre>\n",
       "<p>The decomposed property returns True or False - whether an element has been decomposed or not.</p>\n",
       "<h2>Modify the Contents</h2>\n",
       "<p>We shall look at the <b>replace_with()</b> method that allows contents of a tag to be replaced.</p>\n",
       "<p>Just as a Python string, which is immutable, the NavigableString also can't be modified in place. However, use replace_with() to replace the inner string of a tag with another.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(\"&lt;h2 id='message'&gt;Hello, Tutorialspoint!&lt;/h2&gt;\",'html.parser')\n",
       "\n",
       "tag = soup.h2\n",
       "tag.string.replace_with(\"OnLine Tutorials Library\")\n",
       "print (tag.string)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "OnLine Tutorials Library\n",
       "</pre>\n",
       "<p>Here is another example to show the use of replace_with(). Two parsed documents can be combined if you pass a BeautifulSoup object as an argument to a certain function such as replace_with().2524</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "obj1 = BeautifulSoup(\"&lt;book&gt;&lt;title&gt;Python&lt;/title&gt;&lt;/book&gt;\", features=\"xml\")\n",
       "obj2 = BeautifulSoup(\"&lt;b&gt;Beautiful Soup parser&lt;/b&gt;\", \"lxml\")\n",
       "\n",
       "obj2.find('b').replace_with(obj1)\n",
       "print (obj2)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;&lt;body&gt;&lt;book&gt;&lt;title&gt;Python&lt;/title&gt;&lt;/book&gt;&lt;/body&gt;&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The <b>wrap()</b> method wraps an element in the tag you specify. It returns the new wrapper.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;Hello Python&lt;/p&gt;\", 'html.parser')\n",
       "tag = soup.p\n",
       "newtag = soup.new_tag('b')\n",
       "tag.string.wrap(newtag)\n",
       "\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;&lt;b&gt;Hello Python&lt;/b&gt;&lt;/p&gt;\n",
       "</pre>\n",
       "<p>On the other hand, the <b>unwrap()</b> method replaces a tag with whatever's inside that tag. It's good for stripping out markup.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;Hello &lt;b&gt;Python&lt;/b&gt;&lt;/p&gt;\", 'html.parser')\n",
       "tag = soup.p\n",
       "tag.b.unwrap()\n",
       "\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Hello Python&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Parsing a Section of a Document</h1>\n",
       "<p>Let's say you want to use Beautiful Soup look at a document's &lt;a&gt; tags only. Normally you would parse the tree and use find_all() method with the required tag as the argument.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(fp, \"html.parser\")\n",
       "\n",
       "tags = soup.find_all('a')\n",
       "</pre>\n",
       "<p>But that would be time consuming as well as it will take up more memory unnecessarily. Instead, you can create an object of SoupStrainer class and use it as value of parse_only argument to BeautifulSoup constructor.</p>\n",
       "<p>A SoupStrainer tells BeautifulSoup what parts extract, and the parse tree consists of only these elements. If you narrow down your required information to a specific portion of the HTML, this will speed up your search result.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "product = SoupStrainer('div',{'id': 'products_list'})\n",
       "soup = BeautifulSoup(html,parse_only=product)\n",
       "</pre>\n",
       "<p>Above lines of code will parse only the titles from a product site, which might be inside a tag field.</p>\n",
       "<p>Similarly, like above we can use other soupStrainer objects, to parse specific information from an HTML tag. Below are some of the examples </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, SoupStrainer\n",
       "\n",
       "#Only \"a\" tags\n",
       "only_a_tags = SoupStrainer(\"a\")\n",
       "\n",
       "#Will parse only the below mentioned \"ids\".\n",
       "parse_only = SoupStrainer(id=[\"first\", \"third\", \"my_unique_id\"])\n",
       "soup = BeautifulSoup(my_document, \"html.parser\", parse_only=parse_only)\n",
       "\n",
       "#parse only where string length is less than 10\n",
       "def is_short_string(string):\n",
       "   return len(string) &lt; 10\n",
       "\n",
       "only_short_strings = SoupStrainer(string=is_short_string)\n",
       "</pre>\n",
       "<p>The SoupStrainer class takes the same arguments as a typical method from Searching the tree: name, attrs, text, and **kwargs.</p>\n",
       "<p>Note that this feature won't work if you're using the html5lib parser, because the whole document will be parsed in that case, no matter what. Hence, you should use either the inbuilt html.parser or lxml parser.</p>\n",
       "<p>You can also pass a SoupStrainer into any of the methods covered in Searching the tree.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import SoupStrainer\n",
       "\n",
       "a_tags = SoupStrainer(\"a\")\n",
       "soup = BeautifulSoup(html_doc, 'html.parser')\n",
       "soup.find_all(a_tags)\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Find all Children of an Element</h1>\n",
       "<p>The structure of tags in a HTML script is hierarchical. The elements are nested one inside the other. For example, the top level &lt;HTML&gt; tag includes &lt;HEAD&gt; and &lt;BODY&gt; tags, each may have other tags in it. The top level element is called as parent. The elements nested inside the parent are its children. With the help of Beautiful Soup, we can find all the children elements of a parent element. In this chapter, we shall find out how to obtain the children of a HTML element.</p>\n",
       "<p>There are two provisions in BeautifulSoup class to fetch the children elements.</p>\n",
       "<ul class=\"list\">\n",
       "<li>The .children property</li>\n",
       "<li>The findChildren() method</li>\n",
       "</ul>\n",
       "<p>Examples in this chapter use the following HTML script (index.html)</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "&lt;h2&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "&lt;ul id=\"dept\"&gt;\n",
       "&lt;li&gt;Accounts&lt;/li&gt;\n",
       "   &lt;ul id='acc'&gt;\n",
       "   &lt;li&gt;Anand&lt;/li&gt;\n",
       "   &lt;li&gt;Mahesh&lt;/li&gt;\n",
       "   &lt;/ul&gt;\n",
       "&lt;li&gt;HR&lt;/li&gt;\n",
       "   &lt;ul id=\"HR\"&gt;\n",
       "   &lt;li&gt;Rani&lt;/li&gt;\n",
       "   &lt;li&gt;Ankita&lt;/li&gt;\n",
       "   &lt;/ul&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h2>Using .children property</h2>\n",
       "<p>The .children property of a Tag object returns a generator of all the child elements in a recursive manner.</p>\n",
       "<p>The following Python code gives a list of all the children elements of top level &lt;ul&gt; tag. We first obtain the Tag element corresponding to the &lt;ul&gt; tag, and then read its .children property</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "with open(\"index.html\") as fp:\n",
       "   soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.ul\n",
       "print (list(tag.children))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['\\n', &lt;li&gt;Accounts&lt;/li&gt;, '\\n', &lt;ul&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;, '\\n', &lt;li&gt;HR&lt;/li&gt;, '\\n', &lt;ul&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ul&gt;, '\\n']\n",
       "</pre>\n",
       "<p>Since the .children property returns a list_iterator, we can use a for loop to traverse the hierarchy.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "for child in tag.children:\n",
       "   print (child)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;li&gt;Accounts&lt;/li&gt;\n",
       "\n",
       "&lt;ul&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "\n",
       "&lt;li&gt;HR&lt;/li&gt;\n",
       "\n",
       "&lt;ul&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "</pre>\n",
       "<h2>Using findChildren() method</h2>\n",
       "<p>The findChildren() method offers a more comprehensive alternative. It returns all the child elements under any top level tag. </p>\n",
       "<p>In the index.html document, we have two nested unordered lists. The top level &lt;ul&gt; element has id = \"dept\" and the two enclosed lists are having id = \"acc' and \"HR' respectively.</p>\n",
       "<p>In the following example, we first instantiate a Tag object pointing to top level &lt;ul&gt; element and extract the list of children under it.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.find(\"ul\", {\"id\": \"dept\"})\n",
       "\n",
       "children = tag.findChildren()\n",
       " \n",
       "for child in children:\n",
       "   print(child)\n",
       "</pre>\n",
       "<p>Note that the resultset includes the children under an element in a recursive fashion. Hence, in the following output, you'll find the entire inner list, followed by individual elements in it.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;li&gt;Accounts&lt;/li&gt;\n",
       "&lt;ul id=\"acc\"&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;li&gt;HR&lt;/li&gt;\n",
       "&lt;ul id=\"HR\"&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "</pre>\n",
       "<p>Let us extract the children under an inner &lt;ul&gt; element with id='acc'. Here is the code </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.find(\"ul\", {\"id\": \"acc\"})\n",
       "\n",
       "children = tag.findChildren()\n",
       " \n",
       "for child in children:\n",
       "\tprint(child)\n",
       "</pre>\n",
       "<p>When the above program is run, you'll obtain the &lt;li&gt;elements under the &lt;ul&gt; with id as acc.</p>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "</pre>\n",
       "<p>Thus, BeautifulSoup makes it very easy to parse the children elements under any top level HTML element.</p>\n",
       "<h1>Beautiful Soup - Find Element using CSS Selectors</h1>\n",
       "<p>In Beautiful Soup library, the select() method is an important tool for scraping the HTML/XML document. Similar to find() and the other find_*() methods, the select() method also helps in locating an element that satisfies a given criteria. However, the find*() methods search for the PageElements according to the Tag name and its attributes, the select() method searches the document tree for the given CSS selector.</p>\n",
       "<p>Beautiful Soup also has select_one() method. Difference in select() and select_one() is that, select() returns a ResultSet of all the elements belonging to the PageElement and characterized by the CSS selector; whereas select_one() returns the first occurrence of the element satisfying the CSS selector based selection criteria.</p>\n",
       "<p>Prior to Beautiful Soup version 4.7, the select() method used to be able to support only the common CSS selectors. With version 4.7, Beautiful Soup was integrated with Soup Sieve CSS selector library. As a result, much more selectors can now be used. In the version 4.12, a .css property has been added in addition to the existing convenience methods, select() and select_one().The parameters for select() method are as follows </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "select(selector, limit, **kwargs)\n",
       "</pre>\n",
       "<p><b>selector</b>  A string containing a CSS selector.</p>\n",
       "<p><b>limit</b>  After finding this number of results, stop looking.</p>\n",
       "<p><b>kwargs</b>  Keyword arguments to be passed.</p>\n",
       "<p>If the limit parameter is set to 1, it becomes equivalent to select_one() method. While the select() method returns a ResultSet of Tag objects, the select_one() method returns a single Tag object.</p>\n",
       "<h2>Soup Sieve Library</h2>\n",
       "<p>Soup Sieve is a CSS selector library. It has been integrated with Beautiful Soup 4, so it is installed along with Beautiful Soup package. It provides ability to select, match, and filter he document tree tags using modern CSS selectors. Soup Sieve currently implements most of the CSS selectors from the CSS level 1 specifications up to CSS level 4, except for some that are not yet implemented.</p>\n",
       "<p>The Soup Sieve library has different types of CSS selectors. The basic CSS selectors are </p>\n",
       "<h3>Type selector</h3>\n",
       "<p>Matching elements is done by node name. For example </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.select('div')\n",
       "</pre>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tags = soup.select('div')\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;div id=\"Languages\"&gt;\n",
       "&lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "&lt;/div&gt;]\n",
       "</pre>\n",
       "<h3>Universal selector (*) </h3>\n",
       "<p>It matches elements of any type. Example </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.select('*')\n",
       "</pre>\n",
       "<h3>ID selector</h3>\n",
       "<p>It matches an element based on its id attribute. The symbol # denotes the ID selector. Example </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.select(\"#nm\")\n",
       "</pre>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "html = '''\n",
       "   &lt;form&gt;\n",
       "      &lt;input type = 'text' id = 'nm' name = 'name'&gt;\n",
       "      &lt;input type = 'text' id = 'age' name = 'age'&gt;\n",
       "      &lt;input type = 'text' id = 'marks' name = 'marks'&gt;\n",
       "   &lt;/form&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "obj = soup.select(\"#nm\")\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h3>Class selector </h3>\n",
       "<p>It matches an element based on the values contained in the class attribute. The . symbol prefixed to the class name is the CSS class selector. Example </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.select(\".submenu\")\n",
       "</pre>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tags = soup.select('div')\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;div id=\"Languages\"&gt;\n",
       "&lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "&lt;/div&gt;]\n",
       "</pre>\n",
       "<h3>Attribute Selectors</h3>\n",
       "<p>The attribute selector matches an element based on its attributes.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup.select('[attr]')\n",
       "</pre>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "html = '''\n",
       "   &lt;h1&gt;Tutorialspoint Online Library&lt;/h1&gt;\n",
       "   &lt;p&gt;&lt;b&gt;It's all Free&lt;/b&gt;&lt;/p&gt;\n",
       "   &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/java/java_overview.htm\" id=\"link1\"&gt;Java&lt;/a&gt; \n",
       "   &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/cprogramming/index.htm\" id=\"link2\"&gt;C&lt;/a&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(html, 'html5lib')\n",
       "print(soup.select('[href]'))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/java/java_overview.htm\" id=\"link1\"&gt;Java&lt;/a&gt;, &lt;a class=\"prog\" href=\"https://www.tutorialspoint.com/cprogramming/index.htm\" id=\"link2\"&gt;C&lt;/a&gt;]\n",
       "</pre>\n",
       "<h2>Pseudo Classes</h2>\n",
       "<p>CSS specification defines a number of pseudo CSS classes. A pseudo-class is a keyword added to a selector so as to define a special state of the selected elements. It adds an effect to the existing elements. For example, :link selects a link (every &lt;a&gt; and &lt;area&gt; element with an href attribute) that has not yet been visited.</p>\n",
       "<p>The pseudo-class selectors nth-of-type and nth-child are very widely used.</p>\n",
       "<h3>:nth-of-type()</h3>\n",
       "<p>The selector :nth-of-type() matches elements of a given type, based on their position among a group of siblings. The keywords even and odd, and will respectively select elements, from a sub-group of sibling elements.</p>\n",
       "<p>In the following example, second element of &lt;p&gt; type is selected.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "html = '''\n",
       "&lt;p id=\"0\"&gt;&lt;/p&gt;\n",
       "&lt;p id=\"1\"&gt;&lt;/p&gt;\n",
       "&lt;span id=\"2\"&gt;&lt;/span&gt;\n",
       "&lt;span id=\"3\"&gt;&lt;/span&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(html, 'html5lib')\n",
       "print(soup.select('p:nth-of-type(2)'))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;p id=\"1\"&gt;&lt;/p&gt;]\n",
       "</pre>\n",
       "<h3>:nth-child()</h3>\n",
       "<p>This selector matches elements based on their position in a group of siblings. The keywords even and odd will respectively select elements whose position is either even or odd amongst a group of siblings.</p>\n",
       "<h3>Usage</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       ":nth-child(even)\n",
       ":nth-child(odd)\n",
       ":nth-child(2)\n",
       "</pre>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.div\n",
       "\n",
       "child = tag.select_one(':nth-child(2)')\n",
       "print (child)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Python&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Find all Comments</h1>\n",
       "<p>Inserting comments in a computer code is supposed to be a good programming practice. Comments are helpful for understanding the logic of the program. They also serve as a documentation. You can put comments in a HTML as well as XML script, just as in a program written in C, Java, Python etc. BeautifulSoup API can be helpful to identify all the comments in a HTML document.</p>\n",
       "<p>In HTML and XML, the comment text is written between &lt;!-- and --&gt; tags.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "&lt;!-- Comment Text --&gt;\n",
       "</pre>\n",
       "<p>The BeutifulSoup package, whose internal name is bs4, defines Comment as an important object. The Comment object is a special type of NavigableString object. Hence, the string property of any Tag that is found between &lt;!-- and --&gt; is recognized as a Comment.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "markup = \"&lt;b&gt;&lt;!--This is a comment text in HTML--&gt;&lt;/b&gt;\"\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "comment = soup.b.string\n",
       "print (comment, type(comment))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "This is a comment text in HTML &lt;class 'bs4.element.Comment'&gt;\n",
       "</pre>\n",
       "<p>To search for all the occurrences of comment in a HTML document, we shall use find_all() method. Without any argument, find_all() returns all the elements in the parsed HTML document. You can pass a keyword argument 'string' to find_all() method. We shall assign the return value of a function iscomment() to it.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "comments = soup.find_all(string=iscomment)\n",
       "</pre>\n",
       "<p>The iscomment() function verifies if the text in a tag is a comment object or not, with the help of isinstance() function.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "def iscomment(elem):\n",
       "   return isinstance(elem, Comment)\n",
       "</pre>\n",
       "<p>The comments variable shall store all the comment text occurrences in the given HTML document. We shall use the following index.html file in the example code </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;!-- Title of document --&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;!-- Page heading --&gt;\n",
       "      &lt;h2&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "      &lt;!-- top level list--&gt;\n",
       "      &lt;ul id=\"dept\"&gt;\n",
       "      &lt;li&gt;Accounts&lt;/li&gt;\n",
       "         &lt;ul id='acc'&gt;\n",
       "         &lt;!-- first inner list --&gt;\n",
       "         &lt;li&gt;Anand&lt;/li&gt;\n",
       "         &lt;li&gt;Mahesh&lt;/li&gt;\n",
       "         &lt;/ul&gt;\n",
       "      &lt;li&gt;HR&lt;/li&gt;\n",
       "         &lt;ul id=\"HR\"&gt;\n",
       "         &lt;!-- second inner list --&gt;\n",
       "         &lt;li&gt;Rani&lt;/li&gt;\n",
       "         &lt;li&gt;Ankita&lt;/li&gt;\n",
       "         &lt;/ul&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The following Python program scrapes the above HTML document, and finds all the comments in it.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, Comment\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "def iscomment(elem):\n",
       "    return isinstance(elem, Comment)\n",
       "\n",
       "comments = soup.find_all(string=iscomment)\n",
       "print (comments)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[' Title of document ', ' Page heading ', ' top level list', ' first inner list ', ' second inner list ']\n",
       "</pre>\n",
       "<p>The above output shows a list of all comments. We can also use a for loop over the collection of comments.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "i=0\n",
       "for comment in comments:\n",
       "   i+=1\n",
       "   print (i,\".\",comment)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "1 .  Title of document \n",
       "2 .  Page heading\n",
       "3 .  top level list\n",
       "4 .  first inner list\n",
       "5 .  second inner list\n",
       "</pre>\n",
       "<p>In this chapter, we learned how to extract all the comment strings in a HTML document.</p>\n",
       "<h1>Beautiful Soup - Scraping List from HTML</h1>\n",
       "<p>Web pages usually contain important data in the formation in the form of ordered or unordered lists. With Beautiful Soup, we can easily extract the HTML list elements, bring the data in Python objects to store in databases for further analysis. In this chapter, we shall use find() and select() methods to scrape the list data from a HTML document.</p>\n",
       "<p>Easiest way to search a parse tree is to search the tag by its name. soup.&lt;tag&gt; fetches the contents of the given tag.</p>\n",
       "<p>HTML provides &lt;ol&gt; and &lt;ul&gt; tags to compose ordered and unordered lists. Like any other tag, we can fetch the contents of these tags.</p>\n",
       "<p>We shall use the following HTML document </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "      &lt;ul id=\"dept\"&gt;\n",
       "      &lt;li&gt;Accounts&lt;/li&gt;\n",
       "         &lt;ul id='acc'&gt;\n",
       "         &lt;li&gt;Anand&lt;/li&gt;\n",
       "         &lt;li&gt;Mahesh&lt;/li&gt;\n",
       "         &lt;/ul&gt;\n",
       "      &lt;li&gt;HR&lt;/li&gt;\n",
       "         &lt;ol id=\"HR\"&gt;\n",
       "         &lt;li&gt;Rani&lt;/li&gt;\n",
       "         &lt;li&gt;Ankita&lt;/li&gt;\n",
       "         &lt;/ol&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h2>Scraping lists by Tag</h2>\n",
       "<p>In the above HTML document, we have a top-level &lt;ul&gt; list, inside which there's another &lt;ul&gt; tag and another &lt;ol&gt; tag. We first parse the document in soup object and retrieve contents of first &lt;ul&gt; in soup.ul Tag object.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "lst=soup.ul\n",
       "\n",
       "print (lst)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;ul id=\"dept\"&gt;\n",
       "&lt;li&gt;Accounts&lt;/li&gt;\n",
       "&lt;ul id=\"acc\"&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;li&gt;HR&lt;/li&gt;\n",
       "&lt;ol id=\"HR\"&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ol&gt;\n",
       "&lt;/ul&gt;\n",
       "</pre>\n",
       "<p>Change value of lst to point to &lt;ol&gt; element to get the inner list.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "lst=soup.ol\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;ol id=\"HR\"&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ol&gt;\n",
       "</pre>\n",
       "<h2>Using select() method</h2>\n",
       "<p>The select() method is essentially used to obtain data using CSS selector. However, you can also pass a tag to it. Here, we can pass the ol tag to select() method. The select_one() method is also available. It fetches the first occurrence of the given tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "lst=soup.select(\"ol\")\n",
       "\n",
       "print (lst)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;ol id=\"HR\"&gt;\n",
       "&lt;li&gt;Rani&lt;/li&gt;\n",
       "&lt;li&gt;Ankita&lt;/li&gt;\n",
       "&lt;/ol&gt;]\n",
       "</pre>\n",
       "<h2>Using find_all() method</h2>\n",
       "<p>The find() and fin_all() methods are more comprehensive. You can pass various types of filters such as tag, attributes or string etc. to these methods. In this case, we want to fetch the contents of a list tag.</p>\n",
       "<p>In the following code, find_all() method returns a list of all elements in the &lt;ul&gt; tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "lst=soup.find_all(\"ul\")\n",
       "\n",
       "print (lst)\n",
       "</pre>\n",
       "<p>We can refine the search filter by including the attrs argument. In our HTML document, the &lt;ul&gt; and &lt;ol&gt; tags, we have specified their respective id attributes. So, let us fetch the contents of &lt;ul&gt; element having id=\"acc\".</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "lst=soup.find_all(\"ul\", {\"id\":\"acc\"})\n",
       "\n",
       "print (lst)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;ul id=\"acc\"&gt;\n",
       "&lt;li&gt;Anand&lt;/li&gt;\n",
       "&lt;li&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;]\n",
       "</pre>\n",
       "<p>Here's another example. We collect all elements with &lt;li&gt; tag with the inner text starting with 'A'. The find_all() method takes a keyword argument string. It takes the value of the text if the startingwith() function returns True.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "def startingwith(ch):\n",
       "   return ch.startswith('A')\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "lst=soup.find_all('li',string=startingwith)\n",
       "\n",
       "print (lst)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;li&gt;Accounts&lt;/li&gt;, &lt;li&gt;Anand&lt;/li&gt;, &lt;li&gt;Ankita&lt;/li&gt;]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Scraping Paragraphs from HTML</h1>\n",
       "<p>One of the frequently appearing tags in a HTML document is the &lt;p&gt; tag that marks a paragraph text. With Beautiful Soup, you can easily extract paragraph from the parsed document tree. In this chapter, we shall discuss the following ways of scraping paragraphs with the help of BeautifulSoup library.</p>\n",
       "<ul class=\"list\">\n",
       "<li><p>Scraping HTML paragraph with &lt;p&gt; tag</p></li>\n",
       "<li><p>Scraping HTML paragraph with find_all() method</p></li>\n",
       "<li><p>Scraping HTML paragraph with select() method</p></li>\n",
       "</ul>\n",
       "<p>We shall use the following HTML document for these exercises </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;BeautifulSoup - Scraping Paragraph&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p id='para1'&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;h2&gt;Hello&lt;/h2&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      \n",
       "      &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      \n",
       "      &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h2>Scraping by &lt;p&gt; tag</h2>\n",
       "<p>Easiest way to search a parse tree is to search the tag by its name. Hence, the expression soup.p points towards the first &lt;p&gt; tag in the scouped document.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "para = soup.p\n",
       "</pre>\n",
       "<p>To fetch all the subsequent &lt;p&gt; tags, you can run a loop till the soup object is exhausted of all the &lt;p&gt; tags. The following program displays the prettified output of all the paragraph tags.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "para = soup.p \n",
       "print (para.prettify())\n",
       "while True:\n",
       "   p = para.find_next('p')\n",
       "   if p is None:\n",
       "      break\n",
       "   print (p.prettify())\n",
       "   para=p\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;\n",
       " The quick, brown fox jumps over a lazy dog.\n",
       "&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;\n",
       " DJs flock by when MTV ax quiz prog.\n",
       "&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;\n",
       " Junk MTV quiz graced by fox whelps.\n",
       "&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;\n",
       " Bawds jog, flick quartz, vex nymphs.\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<h2>Using find_all() method</h2>\n",
       "<p>The find_all() methods is more comprehensive. You can pass various types of filters such as tag, attributes or string etc. to this method. In this case, we want to fetch the contents of a &lt;p&gt; tag.</p>\n",
       "<p>In the following code, find_all() method returns a list of all elements in the &lt;p&gt; tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "paras = soup.find_all('p') \n",
       "for para in paras:\n",
       "   print (para.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;\n",
       " The quick, brown fox jumps over a lazy dog.\n",
       "&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;\n",
       " DJs flock by when MTV ax quiz prog.\n",
       "&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;\n",
       " Junk MTV quiz graced by fox whelps.\n",
       "&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;\n",
       " Bawds jog, flick quartz, vex nymphs.\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<p>We can use another approach to find all &lt;p&gt; tags. To begin with, obtain list of all tags using find_all() and check Tag.name of each equals ='p'.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tags = soup.find_all()\n",
       "paras = [tag.contents for tag in tags if tag.name=='p']\n",
       "print (paras)\n",
       "</pre>\n",
       "<p>The find_all() method also has attrs parameter. It is useful when you want to extract the &lt;p&gt; tag with specific attributes. For example, in the given document, the first &lt;p&gt; element has id='para1'. To fetch it, we need to modify the tag object as </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "paras = soup.find_all('p', attrs={'id':'para1'})\n",
       "</pre>\n",
       "<h2>Using select() method</h2>\n",
       "<p>The select() method is essentially used to obtain data using CSS selector. However, you can also pass a tag to it. Here, we can pass the &lt;p&gt; tag to select() method. The select_one() method is also available. It fetches the first occurrence of the &lt;p&gt; tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "paras = soup.select('p')\n",
       "print (paras)\n",
       "\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[\n",
       "&lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;, \n",
       "&lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;, \n",
       "&lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;, \n",
       "&lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "]\n",
       "</pre>\n",
       "<p>To filter out &lt;p&gt; tags with a certain id, use a for loop as follows </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tags = soup.select('p')\n",
       "for tag in tags:\n",
       "   if tag.has_attr('id') and tag['id']=='para1':\n",
       "      print (tag.contents)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['The quick, brown fox jumps over a lazy dog.']\n",
       "</pre>\n",
       "<h1>BeautifulSoup - Scraping Link from HTML</h1>\n",
       "<p>While scraping and analysing the content from resources with a website, you are often required to extract all the links that a certain page contains. In this chapter, we shall find out how we can extract links from a HTML document.</p>\n",
       "<p>HTML has the anchor tag &lt;a&gt; to insert a hyperlink. The href attribute of anchor tag lets you to establish the link. It uses the following syntax </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "&lt;a href==\"web page URL\"&gt;hypertext&lt;/a&gt;\n",
       "</pre>\n",
       "<p>With the find_all() method we can collect all the anchor tags in a document and then print the value of href attribute of each of them.</p>\n",
       "<p>In the example below, we extract all the links found on Google's home page. We use requests library to collect the HTML contents of <a href=\"https://google.com\" rel=\"nofollow\" target=\"_blank\">https://google.com</a>, parse it in a soup object, and then collect all &lt;a&gt; tags. Finally, we print href attributes.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "import requests\n",
       "\n",
       "url = \"https://www.google.com/\"\n",
       "req = requests.get(url)\n",
       "\n",
       "soup = BeautifulSoup(req.content, \"html.parser\")\n",
       "\n",
       "tags = soup.find_all('a')\n",
       "links = [tag['href'] for tag in tags]\n",
       "for link in links:\n",
       "   print (link)\n",
       "</pre>\n",
       "<p>Here's the partial output when the above program is run </p>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "https://www.google.co.in/imghp?hl=en&amp;tab=wi\n",
       "https://maps.google.co.in/maps?hl=en&amp;tab=wl\n",
       "https://play.google.com/?hl=en&amp;tab=w8\n",
       "https://www.youtube.com/?tab=w1\n",
       "https://news.google.com/?tab=wn\n",
       "https://mail.google.com/mail/?tab=wm\n",
       "https://drive.google.com/?tab=wo\n",
       "https://www.google.co.in/intl/en/about/products?tab=wh\n",
       "http://www.google.co.in/history/optout?hl=en\n",
       "/preferences?hl=en\n",
       "https://accounts.google.com/ServiceLogin?hl=en&amp;passive=true&amp;continue=https://www.google.com/&amp;ec=GAZAAQ\n",
       "/advanced_search?hl=en-IN&amp;authuser=0\n",
       "https://www.google.com/url?q=https://io.google/2023/%3Futm_source%3Dgoogle-hpp%26utm_medium%3Dembedded_marketing%26utm_campaign%3Dhpp_watch_live%26utm_content%3D&amp;source=hpp&amp;id=19035434&amp;ct=3&amp;usg=AOvVaw0qzqTkP5AEv87NM-MUDd_u&amp;sa=X&amp;ved=0ahUKEwiPzpjku-z-AhU1qJUCHVmqDJoQ8IcBCAU\n",
       "</pre>\n",
       "<p>However, a HTML document may have hyperlinks of different protocol schemes, such as mailto: protocol for link to an email ID, tel: scheme for link to a telephone number, or a link to a local file with file:// URL scheme. In such a case, if we are interested in extracting links with https:// scheme, we can do so by the following example. We have a HTML document that consists of hyperlinks of different types, out of which only ones with https:// prefix are being extracted.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;a href=\"https://www.tutorialspoint.com\"&gt;Web page link &lt;/a&gt;&lt;/p&gt;\n",
       "&lt;p&gt;&lt;a href=\"https://www.example.com\"&gt;Web page link &lt;/a&gt;&lt;/p&gt;\n",
       "&lt;p&gt;&lt;a href=\"mailto:nowhere@mozilla.org\"&gt;Email link&lt;/a&gt;&lt;/p&gt;\n",
       "&lt;p&gt;&lt;a href=\"tel:+4733378901\"&gt;Telephone link&lt;/a&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "import requests\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tags = soup.find_all('a')\n",
       "links = [tag['href'] for tag in tags]\n",
       "for link in links:\n",
       "   if link.startswith(\"https\"):\n",
       "      print (link)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "https://www.tutorialspoint.com\n",
       "https://www.example.com\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Get all HTML Tags</h1>\n",
       "<p>Tags in HTML are like keywords in a traditional programming language like Python or Java. Tags have a predefined behaviour according to which the its content is rendered by the browser. With Beautiful Soup, it is possible to collect all the tags in a given HTML document.</p>\n",
       "<p>The simplest way to obtain a list of tags is to parse the web page into a soup object, and call find_all() methods without any argument. It returns a list generator, giving us a list of all the tags.</p>\n",
       "<p>Let us extract the list of all tags in Google's homepage.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "import requests\n",
       "\n",
       "url = \"https://www.google.com/\"\n",
       "req = requests.get(url)\n",
       "\n",
       "soup = BeautifulSoup(req.content, \"html.parser\")\n",
       "\n",
       "tags = soup.find_all()\n",
       "print ([tag.name for tag in tags])\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['html', 'head', 'meta', 'meta', 'title', 'script', 'style', 'style', 'script', 'body', 'script', 'div', 'div', 'nobr', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'u', 'div', 'nobr', 'span', 'span', 'span', 'a', 'a', 'a', 'div', 'div', 'center', 'br', 'div', 'img', 'br', 'br', 'form', 'table', 'tr', 'td', 'td', 'input', 'input', 'input', 'input', 'input', 'div', 'input', 'br', 'span', 'span', 'input', 'span', 'span', 'input', 'script', 'input', 'td', 'a', 'input', 'script', 'div', 'div', 'br', 'div', 'style', 'div', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'span', 'div', 'div', 'a', 'a', 'a', 'a', 'p', 'a', 'a', 'script', 'script', 'script']\n",
       "</pre>\n",
       "<p>Naturally, you may get such a list where one certain tag may appear more than once. To obtain a list of unique tags (avoiding the duplication), construct a set from the list of tag objects.</p>\n",
       "<p>Change the print statement in above code to</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "print ({tag.name for tag in tags})\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "{'body', 'head', 'p', 'a', 'meta', 'tr', 'nobr', 'script', 'br', 'img', 'b', 'form', 'center', 'span', 'div', 'input', 'u', 'title', 'style', 'td', 'table', 'html'}\n",
       "</pre>\n",
       "<p>To obtain tags with some text associated with them, check the string property and print if it is not None</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.find_all()\n",
       "for tag in tags:\n",
       "   if tag.string is not None:\n",
       "      print (tag.name, tag.string)\n",
       "</pre>\n",
       "<p>There may be some singleton tags without text but with one or more attributes as in the &lt;img&gt; tag. Following loop constructs lists out such tags.</p>\n",
       "<p>In the following code, the HTML string is not a complete HTML document in the sense that thr &lt;html&gt; and &lt;body&gt; tags are not given. But the html5lib and lxml parsers add these tags on their own while parsing the document tree. Hence, when we extract the tag list, the additional tags will also be seen.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;h1 style=\"color:blue;text-align:center;\"&gt;This is a heading&lt;/h1&gt;\n",
       "&lt;p style=\"color:red;\"&gt;This is a paragraph.&lt;/p&gt;\n",
       "&lt;p&gt;This is another paragraph&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html5lib\")\n",
       "\n",
       "tags = soup.find_all()\n",
       "print ({tag.name for tag in tags} )\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "{'head', 'html', 'p', 'h1', 'body'}\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Get Text Inside Tag</h1>\n",
       "<p>There are two types of tags in HTML. Many of the tags are in pairs of opening and closing counterparts. The top level &lt;html&gt; tag having a corresponding closing &lt;/html&gt; tag is the main example. Others are &lt;body&gt; and &lt;/body&gt;, &lt;p&gt; and &lt;/p&gt;, &lt;h1&gt; and &lt;/h1&gt; and many more. Other tags are self-closing tags - such as &lt;img&gt; and&lt;a&gt;. The self-closing tags don't have a text as most of the tags with opening and closing symbols (such as &lt;b&gt;Hello&lt;/b&gt;). In this chapter, we shall have a look at how can we get the text part inside such tags, with the help of Beautiful Soup library.</p>\n",
       "<p>There are more than one methods/properties available in Beautiful Soup, with which we can fetch the text associated with a tag object.</p>\n",
       "<div class=\"table-wrapper\"><table class=\"table table-bordered\">\n",
       "<tr>\n",
       "<th style=\"text-align: center;\">Sr.No</th>\n",
       "<th style=\"text-align: center;\">Methods &amp; Description</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>1</td>\n",
       "<td><b>text property</b><p>Get all child strings of a PageElement, concatenated using a separator if specified.</p></td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>2</td>\n",
       "<td><b>string property</b><p>Convenience property to string from a child element.</p></td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>3</td>\n",
       "<td><b>strings property</b><p>yields string parts from all the child objects under the current PageElement.</p></td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>4</td>\n",
       "<td><b>stripped_strings property</b><p>Same as strings property, with the linebreaks and whitespaces removed.</p></td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>5</td>\n",
       "<td><b>get_text() method</b><p>returns all child strings of this PageElement, concatenated using a separator if specified.</p></td>\n",
       "</tr>\n",
       "</table></div>\n",
       "<p>Consider the following HTML document </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;div id=\"outer\"&gt;\n",
       "   &lt;div id=\"inner\"&gt;\n",
       "      &lt;p&gt;Hello&lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "      &lt;img src='logo.jpg'&gt;\n",
       "   &lt;/div&gt;\n",
       "&lt;/div&gt;\n",
       "</pre>\n",
       "<p>If we retrieve the stripped_string property of each tag in the parsed document tree, we will find that the two div tags and the p tag have two NavigableString objects, Hello and World. The &lt;b&gt; tag embeds world string, while &lt;img&gt; doesn't have a text part.</p>\n",
       "<p>The following example fetches the text from each of the tags in the given HTML document </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;div id=\"outer\"&gt;\n",
       "   &lt;div id=\"inner\"&gt;\n",
       "      &lt;p&gt;Hello&lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "      &lt;img src='logo.jpg'&gt;\n",
       "   &lt;/div&gt;\n",
       "&lt;/div&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "for tag in soup.find_all():\n",
       "   print (\"Tag: {} attributes: {} \".format(tag.name, tag.attrs))\n",
       "   for txt in tag.stripped_strings:\n",
       "      print (txt)\n",
       "       \n",
       "   print()\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Tag: div attributes: {'id': 'outer'} \n",
       "Hello\n",
       "World\n",
       "\n",
       "Tag: div attributes: {'id': 'inner'} \n",
       "Hello\n",
       "World\n",
       "\n",
       "Tag: p attributes: {} \n",
       "Hello\n",
       "World\n",
       "\n",
       "Tag: b attributes: {} \n",
       "World\n",
       "\n",
       "Tag: img attributes: {'src': 'logo.jpg'}\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Find all Headings</h1>\n",
       "<p>In this chapter, we shall explore how to find all heading elements in a HTML document with BeautifulSoup. HTML defines six heading styles from H1 to H6, each with decreasing font size. Suitable tags are used for different page sections, such as main heading, heading for section, topic etc. Let us use the find_all() method in two different ways to extract all the heading elements in a HTML document.</p>\n",
       "<p>We shall use the following HTML script (saved as index.html) in the code examples in this chapter </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;BeautifulSoup - Scraping Headings&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2&gt;Scraping Headings&lt;/h2&gt;\n",
       "      &lt;b&gt;The quick, brown fox jumps over a lazy dog.&lt;/b&gt;\n",
       "      &lt;h3&gt;Paragraph Heading&lt;/h3&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;h3&gt;List heading&lt;/h3&gt;\n",
       "      &lt;ul&gt;\n",
       "         &lt;li&gt;Junk MTV quiz graced by fox whelps.&lt;/li&gt;\n",
       "         &lt;li&gt;Bawds jog, flick quartz, vex nymphs.&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Example 1</h3>\n",
       "<p>In this approach, we collect all the tags in the parsed tree, and check if the name of each tag is found in a list of all heading tags.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "headings = ['h1','h2','h3', 'h4', 'h5', 'h6']\n",
       "tags = soup.find_all()\n",
       "heads = [(tag.name, tag.contents[0]) for tag in tags if tag.name in headings]\n",
       "print (heads)\n",
       "</pre>\n",
       "<p>Here, headings is a list of all heading styles h1 to h6. If the name of a tag is any of these, the tag and its contents are collected in a lists named heads.</p>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[('h2', 'Scraping Headings'), ('h3', 'Paragraph Heading'), ('h3', 'List heading')]\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>You can pass a regex expression to the find_all() method. Take a look at the following regex.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "re.compile('^h[1-6]$')\n",
       "</pre>\n",
       "<p>This regex finds all tags that start with h, have a digit after the h, and then end after the digit. Let use this as an argument to find_all() method in the code below </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "import re\n",
       "\n",
       "fp = open('index.html')\n",
       "\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tags = soup.find_all(re.compile('^h[1-6]$'))\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;h2&gt;Scraping Headings&lt;/h2&gt;, &lt;h3&gt;Paragraph Heading&lt;/h3&gt;, &lt;h3&gt;List heading&lt;/h3&gt;]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Extract Title Tag</h1>\n",
       "<p>The &lt;title&gt; tag is used to provide a text caption to the page that appears in the browser's title bar. It is not a part of the main content of the web page. The title tag is always present inside the &lt;head&gt; tag.</p>\n",
       "<p>We can extract the contents of title tag by Beautiful Soup. We parse the HTML tree and obtain the title tag object.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;Title&gt;Python Libraries&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p Hello World&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html5lib\")\n",
       "\n",
       "title = soup.title\n",
       "print (title)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;title&gt;Python Libraries&lt;/title&gt;\n",
       "</pre>\n",
       "<p>In HTML, we can use title attribute with all tags. The title attribute gives additional information about an element. The information is works as a tooltip text when the mouse hovers over the element.</p>\n",
       "<p>We can extract the text of title attribute of each tag with following code snippet </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p title='parsing HTML and XML'&gt;Beautiful Soup&lt;/p&gt;\n",
       "      &lt;p title='HTTP library'&gt;requests&lt;/p&gt;\n",
       "      &lt;p title='URL handling'&gt;urllib&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html5lib\")\n",
       "tags = soup.find_all()\n",
       "for tag in tags:\n",
       "   if tag.has_attr('title'):\n",
       "      print (tag.attrs['title'])\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "parsing HTML and XML\n",
       "HTTP library\n",
       "URL handling\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Extract Email IDs</h1>\n",
       "<p>To Extract Email addresses from a web page is an important application a web scraping library such as BeautifulSoup. In any web page, the Email IDs usually appear in the href attribute of anchor &lt;a&gt; tag. The Email ID is written using mailto URL scheme. Many a times, the Email Address may be present in page content as a normal text (without any hyperlink). In this chapter, we shall use BeautifulSoup library to fetch Email IDs from HTML page, with simple techniques.</p>\n",
       "<p>A typical usage of Email ID in href attribute is as below </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "&lt;a href = \"mailto:xyz@abc.com\"&gt;test link&lt;/a&gt;\n",
       "</pre>\n",
       "<p>In the first example, we shall consider the following HTML document for extracting the Email IDs from the hyperlinks </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;BeautifulSoup - Scraping Email IDs&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2&gt;Contact Us&lt;/h2&gt;\n",
       "      &lt;ul&gt;\n",
       "      &lt;li&gt;&lt;a href = \"mailto:sales@company.com\"&gt;Sales Enquiries&lt;/a&gt;&lt;/li&gt;\n",
       "      &lt;li&gt;&lt;a href = \"mailto:careers@company.com\"&gt;Careers&lt;/a&gt;&lt;/li&gt;\n",
       "      &lt;li&gt;&lt;a href = \"mailto:partner@company.com\"&gt;Partner with us&lt;/a&gt;&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Here's the Python code that finds the Email Ids.  We collect all the &lt;a&gt; tags in the document, and check if the tag has href attribute. If true, the part of its value after 6th character is the email Id.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "import re\n",
       "fp = open(\"contact.html\")\n",
       "soup = BeautifulSoup(fp, \"html.parser\")\n",
       "tags = soup.find_all(\"a\")\n",
       "for tag in tags:\n",
       "   if tag.has_attr(\"href\") and tag['href'][:7]=='mailto:':\n",
       "      print (tag['href'][7:])\n",
       "</pre>\n",
       "<p>For the given HTML document, the Email IDs will be extracted as follows </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "sales@company.com\n",
       "careers@company.com\n",
       "partner@company.com\n",
       "</pre>\n",
       "<p>In the second example, we assume that the Email IDs appear anywhere in the text. To extract them, we use the regex searching mechanism. Regex is a complex character pattern. Python's re module helps in processing the regex (Regular Expression) patterns. The following regex pattern is used for searching the email address </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "pat = r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+'\n",
       "</pre>\n",
       "<p>For this exercise, we shall use the following HTML document, having Email IDs in &lt;li&gt;tags.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;BeautifulSoup - Scraping Email IDs&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2&gt;Contact Us&lt;/h2&gt;\n",
       "      &lt;ul&gt;\n",
       "      &lt;li&gt;Sales Enquiries: sales@company.com&lt;/a&gt;&lt;/li&gt;\n",
       "      &lt;li&gt;Careers: careers@company.com&lt;/a&gt;&lt;/li&gt;\n",
       "      &lt;li&gt;Partner with us: partner@company.com&lt;/a&gt;&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Using the email regex, we'll find the appearance of the pattern in each &lt;li&gt; tag string. Here is the Python code </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "import re\n",
       "\n",
       "def isemail(s):\n",
       "   pat = r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+'\n",
       "   grp=re.findall(pat,s)\n",
       "   return (grp)\n",
       "\n",
       "fp = open(\"contact.html\")\n",
       "soup = BeautifulSoup(fp, \"html.parser\")\n",
       "tags = soup.find_all('li')\n",
       "\n",
       "for tag in tags:\n",
       "   emails = isemail(tag.string)\n",
       "   if emails:\n",
       "      print (emails)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['sales@company.com']\n",
       "['careers@company.com']\n",
       "['partner@company.com']\n",
       "</pre>\n",
       "<p>Using the simple techniques described above, we can use BeautifulSoup to extract Email IDs from web pages.</p>\n",
       "<h1>Beautiful Soup - Scrape Nested Tags</h1>\n",
       "<p>The arrangement of tags or elements in a HTML document is hierarchical nature. The tags are nested upto multiple levels. For example, the &lt;head&gt; and &lt;body&gt; tags are nested inside &lt;html&gt; tag. Similarly, one or more &lt;li&gt; tags may be inside a &lt;ul&gt; tag.  In this chapter, we shall find out how to scrape a tag that has one or more children tags nested in it.</p>\n",
       "<p>Let us consider the following HTML document </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;div id=\"outer\"&gt;\n",
       "   &lt;div id=\"inner\"&gt;\n",
       "      &lt;p&gt;Hello&lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "      &lt;img src='logo.jpg'&gt;\n",
       "   &lt;/div&gt;\n",
       "&lt;/div&gt;\n",
       "</pre>\n",
       "<p>In this case, the two &lt;div&gt; tags and a &lt;p&gt; tag has one or more child elements nested inside. Whereas, the &lt;img&gt; and &lt;b&gt; tag donot have any children tags.</p>\n",
       "<p>The findChildren() method returns a ResultSet of all the children under a tag. So, if a tag doesn't have any children, the ResultSet will be an empty list like []. </p>\n",
       "<p>Taking this as a cue, the following code finds out the tags under each tag in the document tree and displays the list.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "   &lt;div id=\"outer\"&gt;\n",
       "      &lt;div id=\"inner\"&gt;\n",
       "         &lt;p&gt;Hello&lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "         &lt;img src='logo.jpg'&gt;\n",
       "      &lt;/div&gt;\n",
       "   &lt;/div&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "for tag in soup.find_all():\n",
       "   print (\"Tag: {} attributes: {}\".format(tag.name, tag.attrs))\n",
       "   print (\"Child tags: \", tag.findChildren())\n",
       "   print()\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Tag: div attributes: {'id': 'outer'}\n",
       "Child tags:  [&lt;div id=\"inner\"&gt;\n",
       "&lt;p&gt;Hello&lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "&lt;img src=\"logo.jpg\"/&gt;\n",
       "&lt;/div&gt;, &lt;p&gt;Hello&lt;b&gt;World&lt;/b&gt;&lt;/p&gt;, &lt;b&gt;World&lt;/b&gt;, &lt;img src=\"logo.jpg\"/&gt;]\n",
       "\n",
       "Tag: div attributes: {'id': 'inner'}\n",
       "Child tags:  [&lt;p&gt;Hello&lt;b&gt;World&lt;/b&gt;&lt;/p&gt;, &lt;b&gt;World&lt;/b&gt;, &lt;img src=\"logo.jpg\"/&gt;]\n",
       "\n",
       "Tag: p attributes: {}\n",
       "Child tags:  [&lt;b&gt;World&lt;/b&gt;]\n",
       "\n",
       "Tag: b attributes: {}\n",
       "Child tags:  []\n",
       "\n",
       "Tag: img attributes: {'src': 'logo.jpg'}\n",
       "Child tags:  []\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Parsing Tables</h1>\n",
       "<p>In addition to a textual content, a HTML document may also have a structured data in the form of HTML tables. With Beautiful Soup, we can extract the tabular data in Python objects such as list or dictionary, if required store it in databases or spreadsheets, and perform processing. In this chapter, we shall parse HTML table using Beautiful Soup.</p>\n",
       "<p>Although Beautiful Soup doesn't any special function or method for extracting table data, we can achieve it by simple scraping techniques. Just like any table, say in SQL or spreadsheet, HTML table consists of rows and columns.</p>\n",
       "<p>HTML has &lt;table&gt; tag to build a tabular structure. There are one or more nested &lt;tr&gt; tags one each for a row. Each row consists of &lt;td&gt; tags to hold the data in each cell of the row. First row usually is used for column headings, and the headings are placed in &lt;th&gt; tag instead of &lt;td&gt;</p>\n",
       "<p>Following HTML script renders a simple table on the browser window </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "   &lt;h2&gt;Beautiful Soup - Parse Table&lt;/h2&gt;\n",
       "      &lt;table border=\"1\"&gt;\n",
       "         &lt;tr&gt;\n",
       "            &lt;th&gt;Name&lt;/th&gt;\n",
       "            &lt;th&gt;Age&lt;/th&gt;\n",
       "            &lt;th&gt;Marks&lt;/th&gt;\n",
       "         &lt;/tr&gt;\n",
       "         &lt;tr class='data'&gt;\n",
       "            &lt;td&gt;Ravi&lt;/td&gt;\n",
       "            &lt;td&gt;23&lt;/td&gt;\n",
       "            &lt;td&gt;67&lt;/td&gt;\n",
       "         &lt;/tr&gt;\n",
       "         &lt;tr class='data'&gt;\n",
       "            &lt;td&gt;Anil&lt;/td&gt;\n",
       "            &lt;td&gt;27&lt;/td&gt;\n",
       "            &lt;td&gt;84&lt;/td&gt;\n",
       "         &lt;/tr&gt;\n",
       "      &lt;/table&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Note that, the appearance of data rows is customized with a CSS class data, in order to distinguish it from the header row.</p>\n",
       "<p>We shall now see how to parse the table data. First, we obtain the document tree in the BeautifulSoup object. Then collect all the column headers in a list.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(markup, \"html.parser\")\n",
       "\n",
       "tbltag = soup.find('table')\n",
       "headers = []\n",
       "headings = tbltag.find_all('th')\n",
       "for h in headings: headers.append(h.string)\n",
       "</pre>\n",
       "<p>The data row tags with class='data' attribute following the header row are then fetched. A dictionary object with column header as key and corresponding value in each cell is formed and appended to a list of dict objects.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "rows = tbltag.find_all_next('tr', {'class':'data'})\n",
       "trows=[]\n",
       "for i in rows:\n",
       "   row = {}\n",
       "   \n",
       "   data = i.find_all('td')\n",
       "   n=0\n",
       "   for j in data: \n",
       "      \n",
       "      row[headers[n]] = j.string\n",
       "      n+=1\n",
       "   trows.append(row)\n",
       "</pre>\n",
       "<p>A list of dictionary objects is collected in trows. You can then use it for different purposes such as storing in a SQL table, saving as a JSON or pandas dataframe object.</p>\n",
       "<p>The complete code is given below </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "markup = \"\"\"\n",
       "&lt;html&gt;\n",
       "\t&lt;body&gt;\n",
       "\t   &lt;p&gt;Beautiful Soup - Parse Table&lt;/p&gt;\n",
       "\t\t&lt;table&gt;\n",
       "\t\t\t&lt;tr&gt;\n",
       "\t\t\t\t&lt;th&gt;Name&lt;/th&gt;\n",
       "\t\t\t\t&lt;th&gt;Age&lt;/th&gt;\n",
       "\t\t\t\t&lt;th&gt;Marks&lt;/th&gt;\n",
       "\t\t\t&lt;/tr&gt;\n",
       "\t\t\t&lt;tr class='data'&gt;\n",
       "\t\t\t\t&lt;td&gt;Ravi&lt;/td&gt;\n",
       "\t\t\t\t&lt;td&gt;23&lt;/td&gt;\n",
       "\t\t\t\t&lt;td&gt;67&lt;/td&gt;\n",
       "\t\t\t&lt;/tr&gt;\n",
       "\t\t\t&lt;tr class='data'&gt;\n",
       "\t\t\t\t&lt;td&gt;Anil&lt;/td&gt;\n",
       "\t\t\t\t&lt;td&gt;27&lt;/td&gt;\n",
       "\t\t\t\t&lt;td&gt;84&lt;/td&gt;\n",
       "\t\t\t&lt;/tr&gt;\n",
       "\t\t&lt;/table&gt;\n",
       "\t&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "\"\"\"\n",
       "\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(markup, \"html.parser\")\n",
       "\n",
       "tbltag = soup.find('table')\n",
       "headers = []\n",
       "headings = tbltag.find_all('th')\n",
       "for h in headings: headers.append(h.string)\n",
       "print (headers)\n",
       "\n",
       "rows = tbltag.find_all_next('tr', {'class':'data'})\n",
       "trows=[]\n",
       "for i in rows:\n",
       "   row = {}\n",
       "   \n",
       "   data = i.find_all('td')\n",
       "   n=0\n",
       "   for j in data: \n",
       "      \n",
       "      row[headers[n]] = j.string\n",
       "      n+=1\n",
       "   trows.append(row)\n",
       "\n",
       "print (trows)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[{'Name': 'Ravi', 'Age': '23', 'Marks': '67'}, {'Name': 'Anil', 'Age': '27', 'Marks': '84'}]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Selecting nth Child</h1>\n",
       "<p>HTML is characterized by the hierarchical order of tags. For example, the &lt;html&gt; tag encloses &lt;body&gt; tag, inside which there may be a &lt;div&gt; tag further may have &lt;ul&gt; and &lt;li&gt; elements nested respectively. The findChildren() method and .children property both return a ResultSet (list) of all the child tags directly under an element. By traversing the list, you can obtain the child located at a desired position, nth child.</p>\n",
       "<p>The code below uses the children property of a &lt;div&gt; tag in the HTML document. Since the return type of children property is a list iterator, we shall retrieve a Python list from it. We also need to remove the whitespaces and line breaks from the iterator. Once done, we can fetch the desired child. Here the child element with index 1 of the &lt;div&gt; tag is displayed.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.div\n",
       "children = tag.children\n",
       "childlist = [child for child in children if child not in ['\\n', ' ']]\n",
       "print (childlist[1])\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Python&lt;/p&gt;\n",
       "</pre>\n",
       "<p>To use findChildren() method instead of children property, change the statement to</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "children = tag.findChildren()\n",
       "</pre>\n",
       "<p>There will be no change in the output.</p>\n",
       "<p>A more efficient approach toward locating nth child is with the select() method. The select() method uses CSS selectors to obtain required PageElements from the current element.</p>\n",
       "<p>The Soup and Tag objects support CSS selectors through their .css property, which is an interface to the CSS selector API. The selector implementation is handled by the Soup Sieve package, which gets installed along with bs4 package.</p>\n",
       "<p>The Soup Sieve package defines different types of CSS selectors, namely simple, compound and complex CSS selectors that are made up of one or more type selectors, ID selectors, class selectors. These selectors are defined in CSS language.</p>\n",
       "<p>There are pseudo class selectors as well in Soup Sieve. A CSS pseudo-class is a keyword added to a selector that specifies a special state of the selected element(s). We shall use :nth-child pseudo class selector in this example. Since we need to select a child from &lt;div&gt; tag at 2<sup>nd</sup> position, we shall pass :nthchild(2) to the select_one() method.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.div\n",
       "\n",
       "child = tag.select_one(':nth-child(2)')\n",
       "print (child)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Python&lt;/p&gt;\n",
       "</pre>\n",
       "<p>We get the same result as with the findChildren() method. Note that the child numbering starts with 1 and not 0 as in case of a Python list.</p>\n",
       "<h1>Beautiful Soup - Search by text inside a Tag</h1>\n",
       "<p>Beautiful Soup provides different means to search for a certain text in the given HTML document. Here, we use the string argument of the find() method for the purpose.</p>\n",
       "<p>In the following example, we use the find() method to search for the word 'by'</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "   &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "   &lt;p&gt; Bawds jog, flick quartz, vex nymphs./p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "def search(tag):\n",
       "   if 'by' in tag.text:\n",
       "      return True\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.find('p', string=search)\n",
       "print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "You can find all occurrences of the word with find_all() method\n",
       "tag = soup.find_all('p', string=search)\n",
       "print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;, &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;]\n",
       "</pre>\n",
       "<p>There may be a situation where the required text may be somewhere in a child tag deep inside the document tree. We need to first locate a tag which has no further elements and then check whether the required text is in it.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "   &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "   &lt;p&gt; Bawds jog, flick quartz, vex nymphs./p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tags = soup.find_all(lambda tag: len(tag.find_all()) == 0 and \"by\" in tag.text)\n",
       "for tag in tags:\n",
       "   print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "&lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Remove HTML Tags</h1>\n",
       "<p>In this chapter, let us see how we can remove all tags from a HTML document. HTML is a markup language, made up of predefined tags. A tag marks a certain text associated with it so that the browser renders it as per its predefined meaning. For example, the word Hello marked with &lt;b&gt; tag for example &lt;b&gt;Hello&lt;/b), is rendered in bold face by the browser.</p>\n",
       "<p>If we want to filter out the raw text between different tags in a HTML document, we can use any of the two methods - get_text() or extract() in Beautiful Soup library. </p>\n",
       "<p>The get_text() method collects all the raw text part from the document and returns a string. However, the original document tree is not changed.</p>\n",
       "<p>In the example below, the get_text() method removes all the HTML tags.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "text = soup.get_text()\n",
       "print(text)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "The quick, brown fox jumps over a lazy dog.\n",
       " DJs flock by when MTV ax quiz prog.\n",
       " Junk MTV quiz graced by fox whelps.\n",
       " Bawds jog, flick quartz, vex nymphs.\n",
       "</pre>\n",
       "<p>Not that the soup object in the above example still contains the parsed tree of the HTML document.</p>\n",
       "<p>Another approach is to collect the string enclosed in a Tag object before extracting it from the soup object. In HTML, some tags don't have a string property (we can say that tag.string is None for some tags such as &lt;html&gt; or &lt;body&gt;). So, we concatenate strings from all other tags to obtain the plain text out of the HTML document.</p>\n",
       "<p>Following program demonstrates this approach.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tags = soup.find_all()\n",
       "\n",
       "string=''\n",
       "for tag in tags:\n",
       "   #print (tag.name, tag.string)\n",
       "   if tag.string != None:\n",
       "      string=string+tag.string+'\\n'\n",
       "   tag.extract()\n",
       "print (\"Document text after removing tags:\")\n",
       "print (string)\n",
       "print (\"Document:\")\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Document text after removing tags:\n",
       "The quick, brown fox jumps over a lazy dog.\n",
       "DJs flock by when MTV ax quiz prog.\n",
       "Junk MTV quiz graced by fox whelps.\n",
       "Bawds jog, flick quartz, vex nymphs.\n",
       "\n",
       "Document:\n",
       "</pre>\n",
       "<p>The clear() method removes the inner string of a tag object but doesn't return it. Similarly the decompose() method destroys the tag as well as all its children elements. Hence, these methods are not suitable to retrieve the plain text from HTML document.</p>\n",
       "<h1>Beautiful Soup - Remove all Styles</h1>\n",
       "<p>This chapter explains how to remove all styles from a HTML document. Cascaded style sheets (CSS) are used to control the appearance of different aspects of a HTML document. It includes styling the rendering of text with a specific font, color, alignment, spacing etc. CSS is applied to HTML tags in different ways.</p>\n",
       "<p>One is to define different styles in a CSS file and include in the HTML script with the &lt;link&gt; tag in the &lt;head&gt; section in the document. For example,</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;link rel=\"stylesheet\" href=\"style.css\"&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "   . . .\n",
       "   . . .\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The different tags in the body part of the HTML script will use the definitions in mystyle.css file</p>\n",
       "<p>Another approach is to define the style configuration inside the &lt;head&gt; part of the HTML document itself. Tags in the body part will be rendered by using the definitions provided internally.</p>\n",
       "<p>Example of internal styling </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "   &lt;style&gt;\n",
       "      p {\n",
       "         text-align: center;\n",
       "         color: red;\n",
       "      } \n",
       "   &lt;/style&gt;\n",
       "&lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;para1.&lt;/p&gt;\n",
       "      &lt;p id=\"para1\"&gt;para2&lt;/p&gt;\n",
       "      &lt;p&gt;para3&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>In either cases, to remove the styles programmatically, simple remove the head tag from the soup object.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "soup.head.extract()\n",
       "</pre>\n",
       "<p>Third approach is to define the styles inline by including style attribute in the tag itself. The style attribute may contain one or more style attribute definitions such as color, size etc. For example</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;body&gt;\n",
       "   &lt;h1 style=\"color:blue;text-align:center;\"&gt;This is a heading&lt;/h1&gt;\n",
       "   &lt;p style=\"color:red;\"&gt;This is a paragraph.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "</pre>\n",
       "<p>To remove such inline styles from a HTML document, you need to check if attrs dictionary of a tag object has style key defined in it, and if yes delete the same.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags=soup.find_all()\n",
       "for tag in tags:\n",
       "   if tag.has_attr('style'):\n",
       "      del tag.attrs['style']\n",
       "print (soup)\n",
       "</pre>\n",
       "<p>The following code removes the inline styles as well as removes the head tag itself, so that the resultant HTML tree will not have any styles left.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;link rel=\"stylesheet\" href=\"style.css\"&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h1 style=\"color:blue;text-align:center;\"&gt;This is a heading&lt;/h1&gt;\n",
       "      &lt;p style=\"color:red;\"&gt;This is a paragraph.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "soup.head.extract()\n",
       "\n",
       "tags=soup.find_all()\n",
       "for tag in tags:\n",
       "   if tag.has_attr('style'):\n",
       "      del tag.attrs['style']\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       " &lt;body&gt;\n",
       "  &lt;h1&gt;\n",
       "   This is a heading\n",
       "  &lt;/h1&gt;\n",
       "  &lt;p&gt;\n",
       "   This is a paragraph.\n",
       "  &lt;/p&gt;\n",
       " &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Remove all Scripts</h1>\n",
       "<p>One of the often used tags in HTML is the &lt;script&gt; tag. It facilitates embedding a client side script such as JavaScript code in HTML. In this chapter, we will use BeautifulSoup to remove script tags from the HTML document.</p>\n",
       "<p>The &lt;script&gt; tag has a corresponding &lt;/script&gt; tag. In between the two, you may include either a reference to an external JavaScript file, or include JavaScript code inline with the HTML script itself.</p>\n",
       "<p>To include an external Javascript file, the syntax used is </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "&lt;head&gt;\n",
       "   &lt;script src=\"javascript.js\"&gt;&lt;/script&gt;\n",
       "&lt;/head&gt;\n",
       "</pre>\n",
       "<p>You can then invoke the functions defined in this file from inside HTML.</p>\n",
       "<p>Instead of referring to an external file, you can put JavaScipt code inside the HTML within the &lt;script&gt; and &lt;/script&gt; code. If it is put inside the &lt;head&gt; section of the HTML document, then the functionality is available throughout the document tree. On the other hand, if put anywhere in the &lt;body&gt; section, the JavaScript functions are available from that point on.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;body&gt;\n",
       "   &lt;p&gt;Hello World&lt;/p&gt;\n",
       "   &lt;script&gt;\n",
       "      alert(\"Hello World\")\n",
       "   &lt;/script&gt;\n",
       "&lt;/body&gt;\n",
       "</pre>\n",
       "<p>To remove all script tags with Beautiful is easy. You have to collect the list of all script tags from the parsed tree and extract them one by one.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;script src=\"javascript.js\"&gt;&lt;/scrript&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Hello World&lt;/p&gt;\n",
       "      &lt;script&gt;\n",
       "      alert(\"Hello World\")\n",
       "      &lt;/script&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "\n",
       "for tag in soup.find_all('script'):\n",
       "   tag.extract()\n",
       "\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "\n",
       "&lt;/head&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>You can also use the decompose() method instead of extract(), the difference being that  that the latter returns the thing that was removed, whereas the former just destroys it. For a more concise code, you may also use list comprehension syntax to achieve the soup object with script tags removed, as follows </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "[tag.decompose() for tag in soup.find_all('script')]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Remove Empty Tags</h1>\n",
       "<p>In HTML, many of the tags have an opening and closing tag. Such tags are mostly used for defining the formatting properties, such as &lt;b&gt; and &lt;/b&gt;, &lt;h1&gt; and &lt;/h1&gt; etc. There are some self-closing tags also which don't have a closing tag and no textual part. For example &lt;img&gt;, &lt;br&gt;, &lt;input&gt; etc. However, while composing HTML, tags such as &lt;p&gt;&lt;/p&gt; without any text may be inadvertently inserted. We need to remove such empty tags with the help of Beautiful Soup library functions.</p>\n",
       "<p>Removing textual tags without any text between opening and closing symbols is easy. You can call extract() method on a tag if length of its inner text is 0.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "for tag in tags:\n",
       "   if (len(tag.get_text(strip=True)) == 0):\n",
       "      tag.extract()\n",
       "</pre>\n",
       "<p>However, this would remove tags such as &lt;hr&gt;, &lt;img&gt;, and &lt;input&gt; etc. These are all self-closing or singleton tags. You would not like to close tags that have one or more attributes even if there is no text associated with it. So, you'll have to check if a tag has any attributes and the get_text() returns none.</p>\n",
       "<p>In the following example, there are both situations where an empty textual tag and some singleton tags are present in the HTML string. The code retains the tags with attributes but removes ones without any text embedded.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html ='''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Paragraph&lt;/p&gt;\n",
       "      &lt;embed type=\"image/jpg\" src=\"Python logo.jpg\" width=\"300\" height=\"200\"&gt;\n",
       "      &lt;hr&gt;\n",
       "      &lt;b&gt;&lt;/b&gt;\n",
       "      &lt;p&gt;\n",
       "      &lt;a href=\"#\"&gt;Link&lt;/a&gt;\n",
       "      &lt;ul&gt;\n",
       "      &lt;li&gt;One&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "      &lt;input type=\"text\" id=\"fname\" name=\"fname\"&gt;\n",
       "      &lt;img src=\"img_orange_flowers.jpg\" alt=\"Flowers\"&gt;\n",
       "   &lt;/body&gt;\n",
       "'''\n",
       "\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tags =soup.find_all()\n",
       "\n",
       "for tag in tags:\n",
       "   if (len(tag.get_text(strip=True)) == 0): \n",
       "      if len(tag.attrs)==0:\n",
       "         tag.extract()\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt;Paragraph&lt;/p&gt;\n",
       "&lt;embed height=\"200\" src=\"Python logo.jpg\" type=\"image/jpg\" width=\"300\"/&gt;\n",
       "\n",
       "&lt;p&gt;\n",
       "&lt;a href=\"#\"&gt;Link&lt;/a&gt;\n",
       "&lt;ul&gt;\n",
       "&lt;li&gt;One&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;input id=\"fname\" name=\"fname\" type=\"text\"/&gt;\n",
       "&lt;img alt=\"Flowers\" src=\"img_orange_flowers.jpg\"/&gt;\n",
       "&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Note that the original html code has a &lt;p&gt; tag without its enclosing &lt;/p&gt;. The parser automatically inserts the closing tag. The position of the closing tag may change if you change the parser to lxml or html5lib.</p>\n",
       "<h1>Beautiful Soup - Remove Child Elements</h1>\n",
       "<p>HTML document is a hierarchical arrangement of different tags, where a tag may have one or more tags nested in it at more than one level. How do we remove the child elements of a certain tag? With BeautifulSoup, it is very easy to do it.</p>\n",
       "<p>There are two main methods in BeautifulSoup library, to remove a certain tag. The decompose() method and extract() method, the difference being that  that the latter returns the thing that was removed, whereas the former just destroys it.</p>\n",
       "<p>Hence to remove the child elements, call findChildren() method for a given Tag object, and then extract() or decompose() on each.</p>\n",
       "<p>Consider the following code segment </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(fp, \"html.parser\")\n",
       "soup.decompose()\n",
       "print (soup)\n",
       "</pre>\n",
       "<p>This will  destroy the entire soup object itself, which is the parsed tree of the document. Obviously, we would not like to do that.</p>\n",
       "<p>Now the following code </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(fp, \"html.parser\")\n",
       "tags = soup.find_all()\n",
       "for tag in tags:\n",
       "   for t in tag.findChildren():\n",
       "      t.extract() \n",
       "</pre>\n",
       "<p>In the document tree, &lt;html&gt; is the first tag, and all other tags are its children, hence it will remove all the tags except &lt;html&gt; and &lt;/html&gt; in the first iteration of the loop itself.</p>\n",
       "<p>More effective use of this can be done if we want to remove the children of a specific tag. For example, you may want to remove the header row of a HTML table.</p>\n",
       "<p>The following HTML script ha a table with first &lt;tr&gt; element having headers marked by &lt;th&gt; tag.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2&gt;Beautiful Soup - Remove Child Elements&lt;/h2&gt;\n",
       "      &lt;table border=\"1\"&gt;\n",
       "         &lt;tr class='header'&gt;\n",
       "            &lt;th&gt;Name&lt;/th&gt;\n",
       "            &lt;th&gt;Age&lt;/th&gt;\n",
       "            &lt;th&gt;Marks&lt;/th&gt;\n",
       "         &lt;/tr&gt;\n",
       "         &lt;tr&gt;\n",
       "            &lt;td&gt;Ravi&lt;/td&gt;\n",
       "            &lt;td&gt;23&lt;/td&gt;\n",
       "            &lt;td&gt;67&lt;/td&gt;\n",
       "         &lt;/tr&gt;\n",
       "         &lt;tr&gt;\n",
       "            &lt;td&gt;Anil&lt;/td&gt;\n",
       "            &lt;td&gt;27&lt;/td&gt;\n",
       "            &lt;td&gt;84&lt;/td&gt;\n",
       "         &lt;/tr&gt;\n",
       "      &lt;/table&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>We can use the following Python code to remove all the children elements of &lt;tr&gt; tag with &lt;th&gt; cells.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, \"html.parser\")\n",
       "tags = soup.find_all('tr', {'class':'header'})\n",
       "\n",
       "for tag in tags:\n",
       "   for t in tag.findChildren():\n",
       "      t.extract()\n",
       "\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;h2&gt;Beautiful Soup - Parse Table&lt;/h2&gt;\n",
       "&lt;table border=\"1\"&gt;\n",
       "&lt;tr class=\"header\"&gt;\n",
       "\n",
       "&lt;/tr&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;td&gt;Ravi&lt;/td&gt;\n",
       "&lt;td&gt;23&lt;/td&gt;\n",
       "&lt;td&gt;67&lt;/td&gt;\n",
       "&lt;/tr&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;td&gt;Anil&lt;/td&gt;\n",
       "&lt;td&gt;27&lt;/td&gt;\n",
       "&lt;td&gt;84&lt;/td&gt;\n",
       "&lt;/tr&gt;\n",
       "&lt;/table&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>It can be seen that the &lt;th&gt; elements have been removed from the parsed tree</p>\n",
       "<h1>Beautiful Soup - find vs find_all</h1>\n",
       "<p>Beautiful Soup library includes find() as well as find_all() methods. Both methods are one of the most frequently used methods while parsing HTML or XML documents. From a particular document tree You often need to locate a PageElement of a certain tag type, or having certain attributes, or having a certain CSS style etc. These criteria are given as argument to both find() and find_all() methods. The main point of difference between the two is that while find() locates the very first child element that satisfies the criteria, find_all() method searches for all the children elements of the criteria.</p>\n",
       "<p>The find() method is defined with following syntax </p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find(name, attrs, recursive, string, **kwargs)\n",
       "</pre>\n",
       "<p>The name argument specifies a filter on tag name. With attrs, a filter on tag attribute values can be set up. The recursive argument forces a recursive search if it is True. You can pass variable kwargs as dictionary of filters on attribute values.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup.find(id = 'nm')\n",
       "soup.find(attrs={\"name\":'marks'})\n",
       "</pre>\n",
       "<p>The find_all() method takes all the arguments as for the find() method, in addition there is a limit argument. It is an integer, restricting the search the specified number of occurrences of the given filter criteria. If not set, find_all() searches for the criteria among all the children under the said PageElement.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup.find_all('input')\n",
       "lst=soup.find_all('li', limit =2)\n",
       "</pre>\n",
       "<p>If the limit argument for find_all() method is set to 1, it virtually acts as find() method.</p>\n",
       "<p>The return type of both the methods differs. The find() method returns either a Tag object or a NavigableString object first found. The find_all() method returns a ResultSet consisting of all the PageElements satisfying the filter criteria.</p>\n",
       "<p>Here is an example that demonstrates the difference between find and find_all methods.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "markup =open(\"index.html\")\n",
       "\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "ret1 = soup.find('input')\n",
       "ret2 = soup.find_all ('input')\n",
       "print (ret1, 'Return type of find:', type(ret1))\n",
       "print (ret2)\n",
       "print ('Return tyoe find_all:', type(ret2))\n",
       "\n",
       "#set limit =1\n",
       "ret3 = soup.find_all ('input', limit=1)\n",
       "print ('find:', ret1)\n",
       "print ('find_all:', ret3)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt; Return type of find: &lt;class 'bs4.element.Tag'&gt;\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;, &lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;, &lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;]\n",
       "Return tyoe find_all: &lt;class 'bs4.element.ResultSet'&gt;\n",
       "find: &lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "find_all: [&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Specifying the Parser</h1>\n",
       "<p>A HTML document tree is parsed into an object of BeautifulSoup class. The constructor of this class needs the mandatory argument as the HTML string or a file object pointing to the html file. The constructor has all other optional arguments, important being features.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "BeautifulSoup(markup, features)\n",
       "</pre>\n",
       "<p>Here markup is a HTML string or file object. The features parameter specifies the parser to be used. It may be a specific parser such as \"lxml\", \"lxml-xml\", \"html.parser\", or \"html5lib; or type of markup to be used (\"html\", \"html5\", \"xml\").</p>\n",
       "<p>If the features argument is not given, BeautifulSoup chooses the best HTML parser that's installed. Beautiful Soup ranks lxml's parser as being the best, then html5lib's, then Python's built-in parser.</p>\n",
       "<p>You can specify one of the following </p>\n",
       "<p>The type of markup you want to parse. Beautiful Soup currently supports are \"html\", \"xml\", and \"html5\".</p>\n",
       "<p>The name of the parser library to be used. Currently supported options are \"lxml\", \"html5lib\", and \"html.parser\" (Python's built-in HTML parser).</p>\n",
       "<p>To install lxml or html5lib parser, use the command </p>\n",
       "<pre class=\"result notranslate\">\n",
       "pip3 install lxml\n",
       "pip3 install html5lib\n",
       "</pre>\n",
       "<p>These parsers have their advantages and disadvantages as shown below </p>\n",
       "<h2>Parser: Python's html.parser</h2>\n",
       "<p><b>Usage</b>  BeautifulSoup(markup, \"html.parser\")</p>\n",
       "<h3>Advantages</h3>\n",
       "<ul class=\"list\">\n",
       "<li>Batteries included</li>\n",
       "<li>Decent speed</li>\n",
       "<li>Lenient (As of Python 3.2)</li>\n",
       "</ul>\n",
       "<h3>Disadvantages</h3>\n",
       "<ul class=\"list\">\n",
       "<li>Not as fast as lxml, less lenient than html5lib.</li>\n",
       "</ul>\n",
       "<h2>Parser: lxml's HTML parser</h2>\n",
       "<p><b>Usage</b>  BeautifulSoup(markup, \"lxml\")</p>\n",
       "<h3>Advantages</h3>\n",
       "<ul class=\"list\">\n",
       "<li>Very fast</li>\n",
       "<li>Lenient</li>\n",
       "<li></li>\n",
       "</ul>\n",
       "<h3>Disadvantages</h3>\n",
       "<ul class=\"list\">\n",
       "<li>External C dependency</li>\n",
       "</ul>\n",
       "<h2>Parser: lxml's XML parser</h2>\n",
       "<p><b>Usage</b>  BeautifulSoup(markup, \"lxml-xml\") <p> Or BeautifulSoup(markup, \"xml\")</p></p>\n",
       "<h3>Advantages</h3>\n",
       "<ul class=\"list\">\n",
       "<li>Very fast</li>\n",
       "<li>The only currently supported XML parser</li>\n",
       "</ul>\n",
       "<h3>Disadvantages</h3>\n",
       "<ul class=\"list\">\n",
       "<li>External C dependency</li>\n",
       "</ul>\n",
       "<h2>Parser: html5lib</h2>\n",
       "<p><b>Usage</b>  BeautifulSoup(markup, \"html5lib\")</p>\n",
       "<h3>Advantages</h3>\n",
       "<ul class=\"list\">\n",
       "<li>Extremely lenient</li>\n",
       "<li>Parses pages the same way a web browser does</li>\n",
       "<li>Creates valid HTML5</li>\n",
       "</ul>\n",
       "<h3>Disadvantages</h3>\n",
       "<ul class=\"list\">\n",
       "<li>Very slow</li>\n",
       "<li>External Python dependency</li>\n",
       "</ul>\n",
       "<p>Different parsers will create different parse trees from the same document. The biggest differences are between the HTML parsers and the XML parsers. Here's a short document, parsed as HTML </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;a&gt;&lt;b /&gt;&lt;/a&gt;\", \"html.parser\")\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;a&gt;&lt;b&gt;&lt;/b&gt;&lt;/a&gt;\n",
       "</pre>\n",
       "<p>An empty &lt;b /&gt; tag is not valid HTML. Hence the parser turns it into a &lt;b&gt;&lt;/b&gt; tag pair.</p>\n",
       "<p>The same document is now parsed as XML. Note that the empty &lt;b /&gt; tag is left alone, and that the document is given an XML declaration instead of being put into an &lt;html&gt; tag.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;a&gt;&lt;b /&gt;&lt;/a&gt;\", \"xml\")\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n",
       "&lt;a&gt;&lt;b/&gt;&lt;/a&gt;\n",
       "</pre>\n",
       "<p>In case of a perfectly-formed HTML document, all HTML parsers result in similar parsed tree though one parser will be faster than another.</p>\n",
       "<p>However, if HTML document is not perfect, there will be different results by different types of parsers. See how the results differ when \"&lt;a&gt;&lt;/p&gt;\" is parsed with different parsers </p>\n",
       "<h3>lxml parser</h3>\n",
       "<p><b>Example</b></p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;a&gt;&lt;/p&gt;\", \"lxml\")\n",
       "print (soup)\n",
       "</pre>\n",
       "<p><b>Output</b></p>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;&lt;body&gt;&lt;a&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Note that the dangling &lt;/p&gt; tag is simply ignored.</p>\n",
       "<h3>html5lib parser</h3>\n",
       "<p><b>Example</b></p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;a&gt;&lt;/p&gt;\", \"html5lib\")\n",
       "print (soup)\n",
       "</pre>\n",
       "<p><b>Output</b></p>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;a&gt;&lt;p&gt;&lt;/p&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The html5lib pairs it with an opening &lt;p&gt; tag. This parser also adds an empty &lt;head&gt; tag to the document.</p>\n",
       "<h3>Built-in html parser</h3>\n",
       "<p><b>Example</b></p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Built in from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;a&gt;&lt;/p&gt;\", \"html.parser\")\n",
       "print (soup)\n",
       "</pre>\n",
       "<p><b>Output</b></p>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;a&gt;&lt;/a&gt;\n",
       "</pre>\n",
       "<p>This parser also ignores the closing &lt;/p&gt; tag. But this parser makes no attempt to create a well-formed HTML document by adding a &lt;body&gt; tag, doesn't even bother to add an &lt;html&gt; tag.</p>\n",
       "<p>The html5lib parser uses techniques that are part of the HTML5 standard, so it has the best claim on being the \"correct\" way.</p>\n",
       "<h1>Beautiful Soup - Comparing Objects</h1>\n",
       "<p>As per the beautiful soup, two navigable string or tag objects are equal if they represent the same HTML/XML markup. </p>\n",
       "<p>Now let us see the below example, where the two &lt;b&gt; tags are treated as equal, even though they live in different parts of the object tree, because they both look like \"&lt;b&gt;Java&lt;/b&gt;\".</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "markup = \"&lt;p&gt;Learn &lt;i&gt;Python&lt;/i&gt;, &lt;b&gt;Java&lt;/b&gt;, advanced &lt;i&gt;Python&lt;/i&gt; and advanced &lt;b&gt;Java&lt;/b&gt;! from Tutorialspoint&lt;/p&gt;\"\n",
       "soup = BeautifulSoup(markup, \"html.parser\")\n",
       "b1 = soup.find('b')\n",
       "b2 = b1.find_next('b')\n",
       "print(b1== b2)\n",
       "\n",
       "print(b1 is b2)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "True\n",
       "False\n",
       "</pre>\n",
       "<p>In the following examples, tow NavigableString objects are compared.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "markup = \"&lt;p&gt;Learn &lt;i&gt;Python&lt;/i&gt;, &lt;b&gt;Java&lt;/b&gt;, advanced &lt;i&gt;Python&lt;/i&gt; and advanced &lt;b&gt;Java&lt;/b&gt;! from Tutorialspoint&lt;/p&gt;\"\n",
       "soup = BeautifulSoup(markup, \"html.parser\")\n",
       "i1 = soup.find('i')\n",
       "i2 = i1.find_next('i')\n",
       "print(i1.string== i2.string)\n",
       "\n",
       "print(i1.string is i2.string)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "True\n",
       "False\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Copying Objects</h1>\n",
       "<p>To create a copy of any tag or NavigableString, use copy() function from the copy module from Python's standard library.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "import copy\n",
       "\n",
       "markup = \"&lt;p&gt;Learn &lt;b&gt;Python, Java&lt;/b&gt;, &lt;i&gt;advanced Python and advanced Java&lt;/i&gt;! from Tutorialspoint&lt;/p&gt;\"\n",
       "soup = BeautifulSoup(markup, \"html.parser\")\n",
       "i1 = soup.find('i')\n",
       "icopy = copy.copy(i1)\n",
       "\n",
       "print (icopy)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;i&gt;advanced Python and advanced Java&lt;/i&gt;\n",
       "</pre>\n",
       "<p>Although the two copies (original and copied one) contain the same markup however, the two do not represent the same object.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "print (i1 == icopy)\n",
       "print (i1 is icopy)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "True\n",
       "False\n",
       "</pre>\n",
       "<p>The copied object is completely detached from the original Beautiful Soup object tree, just as if extract() had been called on it.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "print (icopy.parent)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "None\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Get Tag Position</h1>\n",
       "<p>The Tag object in Beautiful Soup possesses two useful properties that give the information about its position in the HTML document. They are </p>\n",
       "<p><b>sourceline</b>  line number at which the tag is found</p>\n",
       "<p><b>sourcepos</b>  The starting index of the tag in the line in which it is found.</p>\n",
       "<p>These properties are supported by the html.parser which is Python's in-built parser and html5lib parser. They are not available when you are using lmxl parser.</p>\n",
       "<p>In the following example, a HTML string is parsed with html.parser and we find the line number and position of &lt;p&gt; tag in the HTML string.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Web frameworks&lt;/p&gt;\n",
       "      &lt;ul&gt;\n",
       "      &lt;li&gt;Django&lt;/li&gt;\n",
       "      &lt;li&gt;Flask&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "      &lt;p&gt;GUI frameworks&lt;/p&gt;\n",
       "      &lt;ol&gt;\n",
       "      &lt;li&gt;Tkinter&lt;/li&gt;\n",
       "      &lt;li&gt;PyQt&lt;/li&gt;\n",
       "      &lt;/ol&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "p_tags = soup.find_all('p')\n",
       "for p in p_tags:\n",
       "   print (p.sourceline, p.sourcepos, p.string)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "4 0 Web frameworks\n",
       "9 0 GUI frameworks\n",
       "</pre>\n",
       "<p>For html.parser, these numbers represent the position of the initial less-than sign, which is 0 in this example. It is slightly different when html5lib parser is used.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Web frameworks&lt;/p&gt;\n",
       "      &lt;ul&gt;\n",
       "      &lt;li&gt;Django&lt;/li&gt;\n",
       "      &lt;li&gt;Flask&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "      &lt;p&gt;GUI frameworks&lt;/p&gt;\n",
       "      &lt;ol&gt;\n",
       "      &lt;li&gt;Tkinter&lt;/li&gt;\n",
       "      &lt;li&gt;PyQt&lt;/li&gt;\n",
       "      &lt;/ol&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html5lib')\n",
       "\n",
       "li_tags = soup.find_all('li')\n",
       "for l in li_tags:\n",
       "   print (l.sourceline, l.sourcepos, l.string)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "6 3 Django\n",
       "7 3 Flask\n",
       "11 3 Tkinter\n",
       "12 3 PyQt\n",
       "</pre>\n",
       "<p>When using html5lib, the sourcepos property returns the position of the final greater-than sign.</p>\n",
       "<h1>Beautiful Soup - Encoding</h1>\n",
       "<p>All HTML or XML documents are written in some specific encoding like ASCII or UTF-8. However, when you load that HTML/XML document into BeautifulSoup, it has been converted to Unicode.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "markup = \"&lt;p&gt;I will display &lt;/p&gt;\"\n",
       "soup = BeautifulSoup(markup, \"html.parser\")\n",
       "print (soup.p)\n",
       "print (soup.p.string)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;I will display &lt;/p&gt;\n",
       "I will display \n",
       "</pre>\n",
       "<p>Above behavior is because BeautifulSoup internally uses the sub-library called Unicode, Dammit to detect a document's encoding and then convert it into Unicode. </p>\n",
       "<p>However, not all the time, the Unicode, Dammit guesses correctly. As the document is searched byte-by-byte to guess the encoding, it takes lot of time. You can save some time and avoid mistakes, if you already know the encoding by passing it to the BeautifulSoup constructor as from_encoding.</p>\n",
       "<p>Below is one example where the BeautifulSoup misidentifies, an ISO-8859-8 document as ISO-8859-7 </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "markup = b\"&lt;h1&gt;\\xed\\xe5\\xec\\xf9&lt;/h1&gt;\"\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "print (soup.h1)\n",
       "\n",
       "print (soup.original_encoding)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;h1&gt;&lt;/h1&gt;\n",
       "ISO-8859-7\n",
       "</pre>\n",
       "<p>To resolve above issue, pass it to BeautifulSoup using from_encoding </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "markup = b\"&lt;h1&gt;\\xed\\xe5\\xec\\xf9&lt;/h1&gt;\"\n",
       "soup = BeautifulSoup(markup, \"html.parser\", from_encoding=\"iso-8859-8\")\n",
       "print (soup.h1)\n",
       "\n",
       "print (soup.original_encoding)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;h1&gt;&lt;/h1&gt;\n",
       "iso-8859-8\n",
       "</pre>\n",
       "<p>Another new feature added from BeautifulSoup 4.4.0 is, exclude_encoding. It can be used, when you don't know the correct encoding but sure that Unicode, Dammit is showing wrong result.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(markup, exclude_encodings=[\"ISO-8859-7\"])\n",
       "</pre>\n",
       "<h2>Output encoding</h2>\n",
       "<p>The output from a BeautifulSoup is UTF-8 document, irrespective of the entered document to BeautifulSoup. Below a document, where the polish characters are there in ISO-8859-2 format.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "markup = \"\"\"\n",
       "&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"&gt;\n",
       "&lt;HTML&gt;\n",
       "   &lt;HEAD&gt;\n",
       "      &lt;META HTTP-EQUIV=\"content-type\" CONTENT=\"text/html; charset=iso-8859-2\"&gt;\n",
       "   &lt;/HEAD&gt;\n",
       "   &lt;BODY&gt;\n",
       "                    \n",
       "   &lt;/BODY&gt;\n",
       "&lt;/HTML&gt;\n",
       "\"\"\"\n",
       "\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(markup, \"html.parser\", from_encoding=\"iso-8859-8\")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"&gt;\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "                       \n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>In the above example, if you notice, the &lt;meta&gt; tag has been rewritten to reflect the generated document from BeautifulSoup is now in UTF-8 format.</p>\n",
       "<p>If you don't want the generated output in UTF-8, you can assign the desired encoding in prettify().</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "print(soup.prettify(\"latin-1\"))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "b'&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"&gt;\\n&lt;html&gt;\\n &lt;head&gt;\\n  &lt;meta content=\"text/html; charset=latin-1\" http-equiv=\"content-type\"/&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n       \\xf3         \\xd3   \\n &lt;/body&gt;\\n&lt;/html&gt;\\n'\n",
       "</pre>\n",
       "<p>In the above example, we have encoded the complete document, however you can encode, any particular element in the soup as if they were a python string </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup.p.encode(\"latin-1\")\n",
       "soup.h1.encode(\"latin-1\")\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "b'&lt;p&gt;My first paragraph.&lt;/p&gt;'\n",
       "b'&lt;h1&gt;My First Heading&lt;/h1&gt;'\n",
       "</pre>\n",
       "<p>Any characters that can't be represented in your chosen encoding will be converted into numeric XML entity references. Below is one such example </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "markup = u\"&lt;b&gt;\\N{SNOWMAN}&lt;/b&gt;\"\n",
       "snowman_soup = BeautifulSoup(markup)\n",
       "tag = snowman_soup.b\n",
       "print(tag.encode(\"utf-8\"))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "b'&lt;b&gt;\\xe2\\x98\\x83&lt;/b&gt;'\n",
       "</pre>\n",
       "<p>If you try to encode the above in \"latin-1\" or \"ascii\", it will generate \"&amp;#9731\", indicating there is no representation for that.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "print (tag.encode(\"latin-1\"))\n",
       "print (tag.encode(\"ascii\"))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "b'&lt;b&gt;&lt;/b&gt;'\n",
       "b'&lt;b&gt;&lt;/b&gt;'\n",
       "</pre>\n",
       "<h2>Unicode, Dammit</h2>\n",
       "<p>Unicode, Dammit is used mainly when the incoming document is in unknown format (mainly foreign language) and we want to encode in some known format (Unicode) and also we don't need Beautifulsoup to do all this. </p>\n",
       "<h1>Beautiful Soup - Output Formatting</h1>\n",
       "<p>If the HTML string given to BeautifulSoup constructor contains any of the HTML entities, they will be converted to Unicode characters. </p>\n",
       "<p>An HTML entity is a string that begins with an ampersand ( &amp; ) and ends with a semicolon ( ; ). They are used to display reserved characters (which would otherwise be interpreted as HTML code). Some of the examples of HTML entities are </p>\n",
       "<div class=\"table-wrapper\"><table class=\"table table-bordered\">\n",
       "<tr>\n",
       "<td>&lt;</td>\n",
       "<td>less than</td>\n",
       "<td>&amp;lt;</td>\n",
       "<td>&amp;#60;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>&gt;</td>\n",
       "<td>greater than</td>\n",
       "<td>&amp;gt;</td>\n",
       "<td>&amp;#62;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>&amp;</td>\n",
       "<td>ampersand</td>\n",
       "<td>&amp;<span>amp</span>;</td>\n",
       "<td>&amp;#38;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\"</td>\n",
       "<td>double quote</td>\n",
       "<td>&amp;quot;</td>\n",
       "<td>&amp;#34;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>'</td>\n",
       "<td>single quote</td>\n",
       "<td>&amp;apos;</td>\n",
       "<td>&amp;#39;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\"</td>\n",
       "<td>Left Double quote</td>\n",
       "<td>&amp;ldquo;</td>\n",
       "<td>&amp;#8220;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\"</td>\n",
       "<td>Right double quote</td>\n",
       "<td>&amp;rdquo;</td>\n",
       "<td>&amp;#8221;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td></td>\n",
       "<td>Pound</td>\n",
       "<td>&amp;pound;</td>\n",
       "<td>&amp;#163;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td></td>\n",
       "<td>yen</td>\n",
       "<td>&amp;yen;</td>\n",
       "<td>&amp;#165;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td></td>\n",
       "<td>euro</td>\n",
       "<td>&amp;euro;</td>\n",
       "<td>&amp;#8364;</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td></td>\n",
       "<td>copyright</td>\n",
       "<td>&amp;copy;</td>\n",
       "<td>&amp;#169;</td>\n",
       "</tr>\n",
       "</table></div>\n",
       "<p>By default, the only characters that are escaped upon output are bare ampersands and angle brackets. These get turned into \"&amp;<span>amp</span>;\", \"&amp;lt;\", and \"&amp;gt;\"</p>\n",
       "<p>For others, they'll be converted to Unicode characters.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"Hello World!\", 'html.parser')\n",
       "print (str(soup))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Hello \"World!\"\n",
       "</pre>\n",
       "<p>If you then convert the document to a bytestring, the Unicode characters will be encoded as UTF-8. You won't get the HTML entities back </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"Hello World!\", 'html.parser')\n",
       "print (soup.encode())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "b'Hello \\xe2\\x80\\x9cWorld!\\xe2\\x80\\x9d'\n",
       "</pre>\n",
       "<p>To change this behavior provide a value for the formatter argument to prettify() method. There are following possible values for the formatter.</p>\n",
       "<p><b>formatter=\"minimal\"</b>  This is the default. Strings will only be processed enough to ensure that Beautiful Soup generates valid HTML/XML</p>\n",
       "<p><b>formatter=\"html\"</b>  Beautiful Soup will convert Unicode characters to HTML entities whenever possible.</p>\n",
       "<p><b>formatter=\"html5\"</b>  it's similar to formatter=\"html\", but Beautiful Soup will omit the closing slash in HTML void tags like \"br\"</p>\n",
       "<p><b>formatter=None</b>  Beautiful Soup will not modify strings at all on output. This is the fastest option, but it may lead to Beautiful Soup generating invalid HTML/XML</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "french = \"&lt;p&gt;Il a dit &lt;&lt;Sacr bleu!&gt;&gt;&lt;/p&gt;\"\n",
       "soup = BeautifulSoup(french, 'html.parser')\n",
       "print (\"minimal: \")\n",
       "print(soup.prettify(formatter=\"minimal\"))\n",
       "print (\"html: \")\n",
       "print(soup.prettify(formatter=\"html\"))\n",
       "print (\"None: \")\n",
       "print(soup.prettify(formatter=None))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "minimal: \n",
       "&lt;p&gt;\n",
       " Il a dit &lt;&lt;Sacr bleu!&gt;&gt;\n",
       "&lt;/p&gt;\n",
       "\n",
       "html:\n",
       "&lt;p&gt;\n",
       " Il a dit &lt;&lt;Sacr bleu!&gt;&gt;\n",
       "&lt;/p&gt;\n",
       "\n",
       "None:\n",
       "&lt;p&gt;\n",
       " Il a dit &lt;&lt;Sacr bleu!&gt;&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<p>In addition, Beautiful Soup library provides formatter classes. You can pass an object of any of these classes as argument to prettify() method.</p>\n",
       "<p><b>HTMLFormatter class</b>  Used to customize the formatting rules for HTML documents.</p>\n",
       "<p><b>XMLFormatter class</b>  Used to customize the formatting rules for XML documents.</p>\n",
       "<h1>Beautiful Soup - Pretty Printing</h1>\n",
       "<p>To display the entire parsed tree of an HTML document or the contents of a specific tag, you can use the print() function or call str() function as well.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;h1&gt;Hello World&lt;/h1&gt;\", \"lxml\")\n",
       "print (\"Tree:\",soup)\n",
       "print (\"h1 tag:\",str(soup.h1))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Tree: &lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello World&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\n",
       "h1 tag: &lt;h1&gt;Hello World&lt;/h1&gt;\n",
       "</pre>\n",
       "<p>The str() function returns a string encoded in UTF-8.</p>\n",
       "<p>To get a nicely formatted Unicode string, use Beautiful Soup's prettify() method. It formats the Beautiful Soup parse tree so that there each tag is on its own separate line with indentation. It allows to you to easily visualize the structure of the Beautiful Soup parse tree.</p>\n",
       "<p>Consider the following HTML string.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "&lt;p&gt;The quick, &lt;b&gt;brown fox&lt;/b&gt; jumps over a lazy dog.&lt;/p&gt;\n",
       "</pre>\n",
       "<p>Using the prettify() method we can better understand its structure </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;p&gt;The quick, &lt;b&gt;brown fox&lt;/b&gt; jumps over a lazy dog.&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"lxml\")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       " &lt;body&gt;\n",
       "  &lt;p&gt;\n",
       "   The quick,\n",
       "   &lt;b&gt;\n",
       "    brown fox\n",
       "   &lt;/b&gt;\n",
       "   jumps over a lazy dog.\n",
       "  &lt;/p&gt;\n",
       " &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>You can call prettify() on on any of the Tag objects in the document.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "print (soup.b.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       " brown fox\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<p>The prettify() method is for understanding the structure of the document. However, it should not be used to reformat it, as it adds whitespace (in the form of newlines), and changes the meaning of an HTML document.</p>\n",
       "<p>He prettify() method can optionally be provided formatter argument to specify the formatting to be used.</p>\n",
       "<h1>Beautiful Soup - NavigableString Class</h1>\n",
       "<p>One of the main objects prevalent in Beautiful Soup API is the object of NavigableString class. It represents the string or text between the opening and closing counterparts of most of the HTML tags. For example, if &lt;b&gt;Hello&lt;/b&gt; is the markup to be parsed, Hello is the NavigableString.</p>\n",
       "<p>NavigableString class is subclassed from the PageElement class in bs4 package, as well as Python's built-in str class. Hence, it inherits the PageElement methods such as find_*(), insert, append, wrap,unwrap methods as well as methods from str class such as upper, lower, find, isalpha etc.</p>\n",
       "<p>The constructor of this class takes a single argument, a str object.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import NavigableString\n",
       "new_str = NavigableString('world')\n",
       "</pre>\n",
       "<p>You can now use this NavigableString object to perform all kinds of operations on the parsed tree, such as append, insert, find etc.</p>\n",
       "<p>In the following example, we append the newly created NavigableString object to an existing Tab object.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Hello&lt;/b&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.b \n",
       "new_str = NavigableString('world')\n",
       "tag.append(new_str)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;Helloworld&lt;/b&gt;\n",
       "</pre>\n",
       "<p>Note that the NavigableString is a PageElement, hence it can be appended to the Soup object also. Check the difference if we do so.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "new_str = NavigableString('world')\n",
       "soup.append(new_str)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;Hello&lt;/b&gt;world\n",
       "</pre>\n",
       "<p>As we can see, the string appears after the &lt;b&gt; tag.</p>\n",
       "<p>Beautiful Soup offers a new_string() method. Create a new NavigableString associated with this BeautifulSoup object.</p>\n",
       "<p>Let us new_string() method to create a NavigableString object, and add it to the PageElements.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Hello&lt;/b&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.b \n",
       "\n",
       "ns=soup.new_string(' World')\n",
       "tag.append(ns)\n",
       "print (tag)\n",
       "soup.append(ns)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;Hello World&lt;/b&gt;\n",
       "&lt;b&gt;Hello&lt;/b&gt; World\n",
       "</pre>\n",
       "<p>We find an interesting behaviour here. The NavigableString object is added to a tag inside the tree, as well as to the soup object itself. While the tag shows the appended string, but in the soup object, the text World is appended, but it doesn't show in the tag. This is because the new_string() method creates a NavigableString associated with the Soup object.</p>\n",
       "<h1>Beautiful Soup - Convert Object to String</h1>\n",
       "<p>The Beautiful Soup API has three main types of objects. The soup object, the Tag object, and the NavigableString object. Let us find out how we can convert each of these object to string. In Python, string is a str object.</p>\n",
       "<p>Assuming that we have a following HTML document</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;Hello &lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "'''\n",
       "</pre>\n",
       "<p>Let us put this string as argument for BeautifulSoup constructor. The soup object is then typecast to string object with Python's builtin str() function.</p>\n",
       "<p>The parsed tree of this HTML string will be constructed dpending upon which parser you use. The built-in html parser doesn't add the &lt;html&gt; and &lt;body&gt; tags. </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "print (str(soup))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Hello &lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "</pre>\n",
       "<p>On the other hand, the html5lib parser constructs the tree after inserting the formal tags such as &lt;html&gt; and &lt;body&gt;</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(html, 'html5lib')\n",
       "print (str(soup))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;Hello &lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "&lt;/body&gt;&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The Tag object has a string property that returns a NavigableString object.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag = soup.find('b')\n",
       "obj = (tag.string)\n",
       "print (type(obj),obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "string &lt;class 'bs4.element.NavigableString'&gt; World\n",
       "</pre>\n",
       "<p>There is also a Text property defined for Tag object. It returns the text contained in the tag, stripping off all the inner tags and attributes.</p>\n",
       "<p>If the HTML string is </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "html = '''\n",
       "   &lt;p&gt;Hello &lt;div id='id'&gt;World&lt;/div&gt;&lt;/p&gt;\n",
       "'''\n",
       "</pre>\n",
       "<p>We try to obtain the text property of &lt;p&gt; tag</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag = soup.find('p')\n",
       "obj = (tag.text)\n",
       "print ( type(obj), obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;class 'str'&gt; Hello World\n",
       "</pre>\n",
       "<p>You can also use the get_text() method which returns a string representing the text inside the tag. The function is actually a wrapper arounf the text property as it also gets rid of inner tags and attributes, and returns a string</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj = tag.get_text()\n",
       "print (type(obj),obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;class 'str'&gt; Hello World\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Convert HTML to Text</h1>\n",
       "<p>One of the important and a frequently required application of a web scraper such as Beautiful Soup library is to extract text from a HTML script. You may need to discard all the tags along with the attributes associated if any with each tag and separate out the raw text in the document. The get_text() method in Beautiful Soup is suitable for this purpose.</p>\n",
       "<p>Here is a basic example demonstrating the usage of get_text() method. You get all the text from HTML document by removing all the HTML tags.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "text = soup.get_text()\n",
       "print(text)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "The quick, brown fox jumps over a lazy dog.\n",
       "DJs flock by when MTV ax quiz prog.\n",
       "Junk MTV quiz graced by fox whelps.\n",
       "Bawds jog, flick quartz, vex nymphs.\n",
       "</pre>\n",
       "<p>The get_text() method has an optional separator argument. In the following example, we specify the separator argument of get_text() method as '#'.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "   &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "   &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "text = soup.get_text(separator='#')\n",
       "print(text)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "#The quick, brown fox jumps over a lazy dog.#\n",
       "#DJs flock by when MTV ax quiz prog.#\n",
       "#Junk MTV quiz graced by fox whelps.#\n",
       "#Bawds jog, flick quartz, vex nymphs.#\n",
       "</pre>\n",
       "<p>The get_text() method has another argument strip, which can be True or False. Let us check the effect of strip parameter when it is set to True. By default it is False.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "   &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "   &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "text = soup.get_text(strip=True)\n",
       "print(text)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "The quick, brown fox jumps over a lazy dog.DJs flock by when MTV ax quiz prog.Junk MTV quiz graced by fox whelps.Bawds jog, flick quartz, vex nymphs.\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Parsing XML</h1>\n",
       "<p>BeautifulSoup can also parse a XML document. You need to pass fatures='xml' argument to Beautiful() constructor.</p>\n",
       "<p>Assuming that we have the following books.xml in the current working directory </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-xml\" data-lang=\"xml\">\n",
       "&lt;?xml version=\"1.0\" ?&gt;\n",
       "&lt;books&gt;\n",
       "   &lt;book&gt;\n",
       "      &lt;title&gt;Python&lt;/title&gt;\n",
       "      &lt;author&gt;TutorialsPoint&lt;/author&gt;\n",
       "      &lt;price&gt;400&lt;/price&gt;\n",
       "   &lt;/book&gt;\n",
       "&lt;/books&gt; \n",
       "</pre>\n",
       "<p>The following code parses the given XML file </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "fp = open(\"books.xml\")\n",
       "soup = BeautifulSoup(fp,  features=\"xml\")\n",
       "\n",
       "print (soup)\n",
       "print ('type:', type(soup)) \n",
       "</pre>\n",
       "<p>When the above code is executed, you should get the following result </p>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n",
       "&lt;books&gt;\n",
       "&lt;book&gt;\n",
       "&lt;title&gt;Python&lt;/title&gt;\n",
       "&lt;author&gt;TutorialsPoint&lt;/author&gt;\n",
       "&lt;price&gt;400&lt;/price&gt;\n",
       "&lt;/book&gt;\n",
       "&lt;/books&gt;\n",
       "type: &lt;class 'bs4.BeautifulSoup'&gt; \n",
       "</pre>\n",
       "<h2>XML parser Error</h2>\n",
       "<p>By default, BeautifulSoup package parses the documents as HTML, however, it is very easy-to-use and handle ill-formed XML in a very elegant manner using beautifulsoup4.</p>\n",
       "<p>To parse the document as XML, you need to have lxml parser and you just need to pass the \"xml\" as the second argument to the Beautifulsoup constructor </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(markup, \"lxml-xml\")\n",
       "</pre>\n",
       "<p>or</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(markup, \"xml\")\n",
       "</pre>\n",
       "<p>One common XML parsing error is </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "AttributeError: 'NoneType' object has no attribute 'attrib'\n",
       "</pre>\n",
       "<p>This might happen in case, some element is missing or not defined while using find() or findall() function.</p>\n",
       "<h1>Beautiful Soup - Error Handling</h1>\n",
       "<p>While trying to parse HTML/XML document with Beautiful Soup, you may encounter errors, not from your script but from the structure of the snippet because the BeautifulSoup API throws an error.</p>\n",
       "<p>By default, BeautifulSoup package parses the documents as HTML, however, it is very easy-to-use and handle ill-formed XML in a very elegant manner using beautifulsoup4.</p>\n",
       "<p>To parse the document as XML, you need to have lxml parser and you just need to pass the \"xml\" as the second argument to the Beautifulsoup constructor </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(markup, \"lxml-xml\")\n",
       "</pre>\n",
       "<p>or</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(markup, \"xml\")\n",
       "</pre>\n",
       "<p>One common XML parsing error is </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "AttributeError: 'NoneType' object has no attribute 'attrib'\n",
       "</pre>\n",
       "<p>This might happen in case, some element is missing or not defined while using find() or findall() function.</p>\n",
       "<p>Apart from the above mentioned parsing errors, you may encounter other parsing issues such as environmental issues where your script might work in one operating system but not in another operating system or may work in one virtual environment but not in another virtual environment or may not work outside the virtual environment. All these issues may be because the two environments have different parser libraries available. </p>\n",
       "<p>It is recommended to know or check your default parser in your current working environment. You can check the current default parser available for the current working environment or else pass explicitly the required parser library as second arguments to the BeautifulSoup constructor.</p>\n",
       "<p>As the HTML tags and attributes are case-insensitive, all three HTML parsers convert tag and attribute names to lowercase. However, if you want to preserve mixed-case or uppercase tags and attributes, then it is better to parse the document as XML.</p>\n",
       "<h2>UnicodeEncodeError</h2>\n",
       "<p>Let us look into below code segment </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(response, \"html.parser\")\n",
       "   print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "UnicodeEncodeError: 'charmap' codec can't encode character '\\u011f'\n",
       "</pre>\n",
       "<p>Above problem may be because of two main situations. You might be trying to print out a unicode character that your console doesn't know how to display. Second, you are trying to write to a file and you pass in a Unicode character that's not supported by your default encoding.</p>\n",
       "<p>One way to resolve above problem is to encode the response text/character before making the soup to get the desired result, as follows </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "responseTxt = response.text.encode('UTF-8')\n",
       "KeyError: [attr]\n",
       "</pre>\n",
       "<p>It is caused by accessing tag['attr'] when the tag in question doesn't define the attr attribute. Most common errors are: \"KeyError: 'href'\" and \"KeyError: 'class'\". Use tag.get('attr') if you are not sure attr is defined.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "for item in soup.fetch('a'):\n",
       "   try:\n",
       "      if (item['href'].startswith('/') or \"tutorialspoint\" in item['href']):\n",
       "      (...)\n",
       "   except KeyError:\n",
       "      pass # or some other fallback action\n",
       "</pre>\n",
       "<h2>AttributeError</h2>\n",
       "<p>You may encounter AttributeError as follows </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "AttributeError: 'list' object has no attribute 'find_all'\n",
       "</pre>\n",
       "<p>The above error mainly occurs because you expected find_all() return a single tag or string. However, soup.find_all returns a python list of elements. </p>\n",
       "<p>All you need to do is to iterate through the list and catch data from those elements.</p>\n",
       "<p>To avoid the above errors when parsing a result, that result will be bypassed to make sure that a malformed snippet isn't inserted into the databases </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "except(AttributeError, KeyError) as er:\n",
       "   pass\n",
       "</pre>\n",
       "<h1>Beautiful Soup - Trouble Shooting</h1>\n",
       "<p>If you run into problems while trying to parse a HTML/XML document, it is more likely because how the parser in use is interpreting the document. To help you locate and correct the problem, Beautiful Soup API provides a dignose() utility.</p>\n",
       "<p>The diagnose() method in Beautiful Soup is a diagnostic suite for isolating common problems. If you're facing difficulty in understanding what Beautiful Soup is doing to a document, pass the document as argument to the diagnose() function. A report showing you how different parsers handle the document, and tell you if you're missing a parser.</p>\n",
       "<p>The diagnose() method is defined in bs4.diagnose module. Its output starts with a message as follows </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "diagnose(markup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Diagnostic running on Beautiful Soup 4.12.2\n",
       "Python version 3.11.2 (tags/v3.11.2:878ead1, Feb  7 2023, 16:38:35) [MSC v.1934 64 bit (AMD64)]\n",
       "Found lxml version 4.9.2.0\n",
       "Found html5lib version 1.1\n",
       "Trying to parse your markup with html.parser\n",
       "Here's what html.parser did with the markup:\n",
       "</pre>\n",
       "<p>If it doesn't find any of these parsers, a corresponding message also appears.</p>\n",
       "<pre class=\"result notranslate\">\n",
       "I noticed that html5lib is not installed. Installing it may help.\n",
       "</pre>\n",
       "<p>If the HTML document fed to diagnose() method is perfectly formed, the parsed tree by any of the parsers will be identical. However if it is not properly formed, then different parser interprets differently. If you don't get the tree as you anticipate, changing the parser might help.</p>\n",
       "<p>Sometimes, you may have chosen HTML parser for a XML document. The HTML parsers add all the HTML tags while parsing the document incorrectly. Looking at the output, you will realize the error and can help in correcting.</p>\n",
       "<p>If Beautiful Soup raises HTMLParser.HTMLParseError, try and change the parser. </p>\n",
       "<p>parse errors are HTMLParser.HTMLParseError: malformed start tag and HTMLParser.HTMLParseError: bad end tag are both generated by Python's built-in HTML parser library, and the solution is to install lxml or html5lib.</p>\n",
       "<p>If you encounter SyntaxError: Invalid syntax (on the line ROOT_TAG_NAME = '[document]'), it is caused by running an old Python 2 version of Beautiful Soup under Python 3, without converting the code.</p>\n",
       "<p>The ImportError with message No module named HTMLParser is because of an old Python 2 version of Beautiful Soup under Python 3.</p>\n",
       "<p>While, ImportError: No module named html.parser - is caused by running the Python 3 version of Beautiful Soup under Python 2.</p>\n",
       "<p>If you get ImportError: No module named BeautifulSoup - more often than not, it is because of running Beautiful Soup 3 code on a system that doesn't have BS3 installed. Or, by writing Beautiful Soup 4 code without knowing that the package name has changed to bs4.</p>\n",
       "<p>Finally, ImportError: No module named bs4 - is due to the fact that you are trying a Beautiful Soup 4 code on a system that doesn't have BS4 installed.</p>\n",
       "<h1>Beautiful Soup - Porting Old Code</h1>\n",
       "<p>You can make the code from earlier version of Beautiful Soup compatible with the lates version by making following change in the import statement </p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from BeautifulSoup import BeautifulSoup\n",
       "#becomes this:\n",
       "\n",
       "from bs4 import BeautifulSoup\n",
       "</pre>\n",
       "<p>If you get the ImportError \"No module named BeautifulSoup\", it means you're trying to run Beautiful Soup 3 code, but you only have Beautiful Soup 4 installed. Similarly, If you get the ImportError \"No module named bs4\", because you're trying to run Beautiful Soup 4 code, but you only have Beautiful Soup 3 installed.</p>\n",
       "<p>Beautiful Soup 3 used Python's SGMLParser, a module that has been removed in Python 3.0. Beautiful Soup 4 uses html.parser by default, but you can also use lxml or html5lib. </p>\n",
       "<p>Although BS4 is mostly backwards-compatible with BS3, most of its methods have been deprecated and given new names for PEP 8 compliance. </p>\n",
       "<p>Here are a few examples </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "replaceWith -&gt; replace_with\n",
       "findAll -&gt; find_all\n",
       "findNext -&gt; find_next\n",
       "findParent -&gt; find_parent\n",
       "findParents -&gt; find_parents\n",
       "findPrevious -&gt; find_previous\n",
       "getText -&gt; get_text\n",
       "nextSibling -&gt; next_sibling\n",
       "previousSibling -&gt; previous_sibling\n",
       "</pre>\n",
       "<h1>Beautiful Soup - contents Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The contents property is available with the Soup object as well as Tag object. It returns a list everything that is contained inside the object, all the immediate child elements and text nodes (i.e. Navigable String).</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Tag.contents\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The contents property returns a list of child elements and strings in the Tag/Soup object,.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>Contents of a tag object </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt;\n",
       "      &lt;p&gt;Python&lt;/p&gt;\n",
       "      &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.div\n",
       "print (tag.contents)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['\\n', &lt;p&gt;Java&lt;/p&gt;, '\\n', &lt;p&gt;Python&lt;/p&gt;, '\\n', &lt;p&gt;C++&lt;/p&gt;, '\\n']\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>Contents of the entire document </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "print (soup.contents)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['\\n', &lt;div id=\"Languages\"&gt;\n",
       "&lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "&lt;/div&gt;, '\\n']\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Note that a NavigableString object doesn't have contents property. It throws AttributeError if we try to access the same.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.p\n",
       "s=tag.contents[0]\n",
       "print (s.contents)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\user\\BeautifulSoup\\2.py\", line 11, in &lt;module&gt;\n",
       "    print (s.contents)\n",
       "           ^^^^^^^^^^\n",
       "  File \"C:\\Users\\user\\BeautifulSoup\\Lib\\site-packages\\bs4\\element.py\", line 984, in __getattr__\n",
       "    raise AttributeError(\n",
       "AttributeError: 'NavigableString' object has no attribute 'contents'\n",
       "</pre>\n",
       "<h1>Beautiful Soup - children Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The Tag object in Beautiful Soup library has children property. It returns a generator used to iterate over the immediate child elements and text nodes (i.e. Navigable String).</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Tag.children\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The property returns a generator with which you can iterate over direct children of the PageElement.</p>\n",
       "<h3>Example 1</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.div\n",
       "children = tag.children\n",
       "for child in children:\n",
       "   print (child)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Java&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;Python&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;C++&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>The soup object too bears the children property.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "children = soup.children\n",
       "for child in children:\n",
       "   print (child)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;div id=\"Languages\"&gt;\n",
       "&lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "&lt;/div&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>In the following example, we append NavigableString objects to the &lt;p&gt; Tag and get the list of children.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "soup.p.extend(['and', 'JavaScript'])\n",
       "children = soup.p.children\n",
       "for child in children:\n",
       "    print (child)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Java\n",
       "and\n",
       "JavaScript\n",
       "</pre>\n",
       "<h1>Beautiful Soup - string Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>In Beautiful Soup, the soup and Tag object has a convenience property - string property. It returns a single string within a PageElement, Soup or Tag. If this element has a single string child, then a NavigableString corresponding to it is returned. If this element has one child tag,      return value is the 'string' attribute of the child tag, and if element itself is a string, (with no children), then the string property returns None.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Tag.string\n",
       "</pre>\n",
       "<h3>Example 1</h3>\n",
       "<p>The following code has the HTML string with a &lt;div&gt; tag that encloses three &lt;p&gt; elements. We find the string property of first &lt;p&gt; tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.p\n",
       "\n",
       "navstr = tag.string\n",
       "print (navstr, type(navstr))\n",
       "\n",
       "nav_str = str(navstr)\n",
       "print (nav_str, type(nav_str))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Java &lt;class 'bs4.element.NavigableString'&gt;\n",
       "Java &lt;class 'str'&gt;\n",
       "</pre>\n",
       "<p>The string property returns a NavigableString. It can be cast to a regular Python string with str() function</p>\n",
       "<h3>Example 2</h3>\n",
       "<p>The string property of an element with children elements inside, returns None. Check with the &lt;div&gt; tag.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag = soup.div\n",
       "\n",
       "navstr = tag.string\n",
       "print (navstr)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "None\n",
       "</pre>\n",
       "<h1>Beautiful Soup - strings Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>For any PageElement having more than one children, the inner text of each can be fetched by the strings property. Unlike the string property, strings handles the case when the element contains multiple children. The strings property returns a generator object. It yields a sequence of NavigableStrings corresponding to each of the child elements.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Tag.strings\n",
       "</pre>\n",
       "<h3>Example 1</h3>\n",
       "<p>You can retrieve the value od strings property for soup as well as a tag object. In the following example, the soup object's stings property is checked.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "print ([string for string in soup.strings])\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['\\n', '\\n', 'Java', ' ', 'Python', ' ', 'C++', '\\n', '\\n']\n",
       "</pre>\n",
       "<p>Note the line breaks and white spaces in the list.We can remove them with stripped_strings property.</p>\n",
       "<h3>Example 2</h3>\n",
       "<p>We now obtain a generator object returned by the strings property of &lt;div&gt; tag. With a loop, we print the strings.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag = soup.div\n",
       "\n",
       "navstrs = tag.strings\n",
       "for navstr in navstrs:\n",
       "   print (navstr)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Java\n",
       " \n",
       "Python\n",
       " \n",
       "C++\n",
       "</pre>\n",
       "<p>Note that the line breaks and whiteapces have appeared in the output, which can be removed with stripped_strings property.</p>\n",
       "<h1>Beautiful Soup - stripped_strings Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The stripped_strings property of a Tag/Soup object gives the return similar to strings property, except for the fact that the extra line breaks and whitespaces are stripped off. Hence, it can be said that the stripped_strings property results in a generator of NavigableString objects of the inner elements belonging to the object in use.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Tag.stripped_strings\n",
       "</pre>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the example below, the strings of all the elements in the document tree parsed in a BeautifulSoup object are displayed after applying the stripping.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "print ([string for string in soup.stripped_strings])\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['Java', 'Python', 'C++']\n",
       "</pre>\n",
       "<p>Compared to the output of strings property, you can see that the line breaks and whitespaces are removed.</p>\n",
       "<h3>Example 2</h3>\n",
       "<p>Here we extract the NavigableStrings of each of the child elements under the &lt;div&gt; tag.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag = soup.div\n",
       "\n",
       "navstrs = tag.stripped_strings\n",
       "for navstr in navstrs:\n",
       "   print (navstr)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Java\n",
       "Python\n",
       "C++\n",
       "</pre>\n",
       "<h1>Beautiful Soup - descendants Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>With the descendants property of a PageElement object in Beautiful Soup API you can traverse the list of all children under it. This property returns a generator object, with which the children elements can be retrieved in a breadth-first sequence.</p>\n",
       "<p>While searching a tree structure, the Breadth-first traversal starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level.\n",
       "</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag.descendants\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The descendants property returns a generator object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the code below, we have a HTML document with nested unordered list tags. We scrape through the children elements parsed in breadth-first manner.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;ul id='outer'&gt;\n",
       "   &lt;li class=\"mainmenu\"&gt;Accounts&lt;/li&gt;\n",
       "      &lt;ul&gt;\n",
       "      &lt;li class=\"submenu\"&gt;Anand&lt;/li&gt;\n",
       "      &lt;li class=\"submenu\"&gt;Mahesh&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;li class=\"mainmenu\"&gt;HR&lt;/li&gt;\n",
       "      &lt;ul&gt;\n",
       "      &lt;li class=\"submenu\"&gt;Anil&lt;/li&gt;\n",
       "      &lt;li class=\"submenu\"&gt;Milind&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/ul&gt;\n",
       "''' \n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.find('ul', {'id': 'outer'})\n",
       "tags = soup.descendants\n",
       "for desc in tags:\n",
       "   print (desc)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;ul id=\"outer\"&gt;\n",
       "&lt;li class=\"mainmenu\"&gt;Accounts&lt;/li&gt;\n",
       "&lt;ul&gt;\n",
       "&lt;li class=\"submenu\"&gt;Anand&lt;/li&gt;\n",
       "&lt;li class=\"submenu\"&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;li class=\"mainmenu\"&gt;HR&lt;/li&gt;\n",
       "&lt;ul&gt;\n",
       "&lt;li class=\"submenu\"&gt;Anil&lt;/li&gt;\n",
       "&lt;li class=\"submenu\"&gt;Milind&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "&lt;/ul&gt;\n",
       "\n",
       "&lt;li class=\"mainmenu\"&gt;Accounts&lt;/li&gt;\n",
       "Accounts\n",
       "&lt;ul&gt;\n",
       "&lt;li class=\"submenu\"&gt;Anand&lt;/li&gt;\n",
       "&lt;li class=\"submenu\"&gt;Mahesh&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "\n",
       "&lt;li class=\"submenu\"&gt;Anand&lt;/li&gt;\n",
       "Anand\n",
       "&lt;li class=\"submenu\"&gt;Mahesh&lt;/li&gt;\n",
       "Mahesh\n",
       "\n",
       "&lt;li class=\"mainmenu\"&gt;HR&lt;/li&gt;\n",
       "HR\n",
       "&lt;ul&gt;\n",
       "&lt;li class=\"submenu\"&gt;Anil&lt;/li&gt;\n",
       "&lt;li class=\"submenu\"&gt;Milind&lt;/li&gt;\n",
       "&lt;/ul&gt;\n",
       "\n",
       "&lt;li class=\"submenu\"&gt;Anil&lt;/li&gt;\n",
       "Anil\n",
       "&lt;li class=\"submenu\"&gt;Milind&lt;/li&gt;\n",
       "Milind\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the following example, we list out the descendants of &lt;head&gt; tag</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;html&gt;&lt;head&gt;&lt;title&gt;TutorialsPoint&lt;/title&gt;&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt;Hello World&lt;/p&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.head\n",
       "for element in tag.descendants:\n",
       "   print (element)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "TutorialsPoint\n",
       "</pre>\n",
       "<h1>Beautiful Soup - parent Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The parent property in BeautifulSoup library returns the immediate parent element of the said PegeElement. The type of the value returned by the parents property is a Tag object. For the BeautifulSoup object, its parent is a document object</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Element.parent\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The parent property returns a Tag object. For Soup object, it returns document object</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>This example uses .parent property to find the immediate parent element of the first &lt;p&gt; tag in the example HTML string.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Hello World&lt;/p&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.p\n",
       "print (tag.parent.name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "body\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the following example, we see that the &lt;title&gt; tag is enclosed inside a &lt;head&gt; tag. Hence, the parent property for &lt;title&gt; tag returns the &lt;head&gt; tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Hello World&lt;/p&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.title\n",
       "print (tag.parent)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;head&gt;&lt;title&gt;TutorialsPoint&lt;/title&gt;&lt;/head&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The behaviour of Python's built-in HTML parser is a little different from html5lib and lxml parsers. The built-in parser doesn't try to build a perfect document out of the string provided. It doesn't add additional parent tags like body or html if they don't exist in the string. On the other hand, html5lib and lxml parsers add these tags to make the document a perfect HTML document.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;p&gt;&lt;b&gt;Hello World&lt;/b&gt;&lt;/p&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "print (soup.p.parent.name)\n",
       "\n",
       "soup = BeautifulSoup(html, 'html5lib')\n",
       "print (soup.p.parent.name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[document]\n",
       "Body\n",
       "</pre>\n",
       "<p>As the HTML parser doesn't add additional tags, the parent of parsed soup is document object. However, when we use html5lib, the parent tag's name property is Body.</p>\n",
       "<h1>Beautiful Soup - parents Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The parents property in BeautifulSoup library retrieves all the parent elements of the said PegeElement in a recursive manner. The type of the value returned by the parents property is a generator, with the help of which we can list out the parents in the down-to-up order.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Element.parents\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The parents property returns a generator object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>This example uses .parents to travel from an &lt;a&gt; tag buried deep within the document, to the very top of the document. In the following code, we track the parents of the first &lt;p&gt; tag in the example HTML string.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;html&gt;&lt;head&gt;&lt;title&gt;TutorialsPoint&lt;/title&gt;&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt;Hello World&lt;/p&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.p\n",
       "for element in tag.parents:\n",
       "   print (element.name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "body\n",
       "html\n",
       "[document]\n",
       "</pre>\n",
       "<p>Note that the parent to the BeautifulSoup object is [document].</p>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the following example, we see that the &lt;b&gt; tag is enclosed inside a &lt;p&gt; tag. The two div tags above it have an id attribute. We try to print the only those elements having id attribute. The has_attr() method is used for the purpose.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;div id=\"outer\"&gt;\n",
       "&lt;div id=\"inner\"&gt;\n",
       "&lt;p&gt;Hello&lt;b&gt;World&lt;/b&gt;&lt;/p&gt;\n",
       "&lt;/div&gt;\n",
       "&lt;/div&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.b\n",
       "for parent in tag.parents:\n",
       "   if parent.has_attr(\"id\"):\n",
       "      print(parent[\"id\"])   \n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "inner\n",
       "outer\n",
       "</pre>\n",
       "<h1>Beautiful Soup - next_sibling Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The HTML tags appearing at the same indentation level are called siblings. The next_sibling property of the PageElement returns next tag at the same level, or under the same parent.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "element.next_sibling\n",
       "</pre>\n",
       "<h3>Return type</h3>\n",
       "<p>The next_sibling property returns a PageElement, a Tag or a NavigableString object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>The index.html wage page consists of a HTML form with three input elements each with a name attribute. In the following example, the next sibling of an input tag with name attribute as nm is located.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.find('input', {'name':'age'})\n",
       "print (tag.find_previous())\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.find('input', {'id':'nm'})\n",
       "sib = tag.next_sibling\n",
       "print (sib)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the next example, we have a HTML document with a couple of tags inside a &lt;p&gt; tag. The next_sibling property returns the tag next to &lt;b&gt; tag in it.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup \n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.b \n",
       "print (\"next:\",tag1.next_sibling)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next: &lt;i&gt;Python&lt;/i&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Consider the HTML string in the following document. It has two &lt;p&gt; tags at the same level. The next_sibling of first &lt;p&gt; should give the second &lt;p&gt; tag's contents.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;/p&gt;\n",
       "&lt;p&gt;TutorialsPoint&lt;/p&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag1 = soup.p\n",
       "print (\"next:\",tag1.next_sibling)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next:\n",
       "</pre>\n",
       "<p>The blank line after the word next: is unexpected. But that's because of the \\n character after the first &lt;p&gt; tag. Change the print statement as shown below to obtain the contents of the next_sibling</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tag1 = soup.p\n",
       "print (\"next:\",tag1.next_sibling.next_sibling)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next: &lt;p&gt;TutorialsPoint&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - previous_sibling Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The HTML tags appearing at the same indentation level are called siblings. The previous_sibling property of the PageElement returns a previous tag (a tag appearing before the current tag) at the same level, or under the same parent. This property encapsulates the find_previous_sibling() method.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "element.previous_sibling\n",
       "</pre>\n",
       "<h3>Return type</h3>\n",
       "<p>The previous_sibling property returns a PageElement, a Tag or a NavigableString object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the following code, the HTML string consists of two adjacent tags inside a &lt;p&gt; tag. It shows the sibling tag for &lt;b&gt; tag appearing before it.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;/p&gt;\", 'html.parser')\n",
       "tag = soup.i\n",
       "sibling = tag.previous_sibling\n",
       "print (sibling)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;Hello&lt;/b&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>We are using the index.html file for parsing. The page contains a HTML form with three input elements. Which element is a previous sibling of input element with its id attribute as age? The following code shows it </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.find('input', {'id':'age'})\n",
       "sib = tag.previous_sibling.previous_sibling\n",
       "print (sib)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>First we find the &lt;p&gt; tag containing the string 'Tutorial' and then fins a tag previous to it.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;Excellent&lt;/p&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p&gt;Tutorial&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag = soup.find('p', string='Tutorial')\n",
       "print (tag.previous_sibling)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Python&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - next_siblings Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The HTML tags appearing at the same indentation level are called siblings. The next_siblings property in Beautiful Soup returns returns a generator object used to iterate over all the subsequent tags and strings under the same parent.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "element.next_siblings\n",
       "</pre>\n",
       "<h3>Return type</h3>\n",
       "<p>The next_siblings property returns a generator of sibling PageElements.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In HTML form code in index.html contains three input elements. Following script uses next_siblings property to collect next siblings of an input element wit id attribute as nm</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.find('input', {'id':'nm'})\n",
       "siblings = tag.next_siblings\n",
       "print (list(siblings))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['\\n', &lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;, '\\n', &lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;, '\\n']\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>Let us use the following HTML snippet for this purpose </p>\n",
       "<p>Use the following code to traverse next siblings tags.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;u&gt;Tutorial&lt;/u&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.b \n",
       "print (\"next siblings:\")\n",
       "for tag in tag1.next_siblings:\n",
       "   print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next siblings:\n",
       "&lt;i&gt;Python&lt;/i&gt;\n",
       "&lt;u&gt;Tutorial&lt;/u&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Next example shows that the &lt;head&gt; tag has only one next sibling in the form of body tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;Hello&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Excellent&lt;/p&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p&gt;Tutorial&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "   &lt;/head&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tags = soup.head.next_siblings\n",
       "print (\"next siblings:\")\n",
       "for tag in tags:\n",
       "   print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next siblings:\n",
       "\n",
       "&lt;body&gt;\n",
       "&lt;p&gt;Excellent&lt;/p&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p&gt;Tutorial&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "</pre>\n",
       "<p>The additional lines are because of the linebreaks in the generator.</p>\n",
       "<h1>Beautiful Soup - previous_siblings Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The HTML tags appearing at the same indentation level are called siblings. The previous_siblings property in Beautiful Soup returns returns a generator object used to iterate over all the tags and strings before the current tag, under the same parent. This gives he similar output as find_previous_siblings() method.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "element.previous_siblings\n",
       "</pre>\n",
       "<h3>Return type</h3>\n",
       "<p>The previous_siblings property returns a generator of sibling PageElements.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>The following example parses the given HTML string that has a few tags embedded inside the outer &lt;p&gt; tag. The previous siblings of the &lt;u&gt; tag are fetched with the help of previous_siblings property.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;u&gt;Tutorial&lt;/u&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.u\n",
       "print (\"previous siblings:\")\n",
       "for tag in tag1.previous_siblings:\n",
       "   print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "previous siblings:\n",
       "&lt;i&gt;Python&lt;/i&gt;\n",
       "&lt;b&gt;Excellent&lt;/b&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the index.html file used in the following example, there are three input elements in the HTML form. We find out what are the sibling tags previous to the one with id set as marks, and under the &lt;form&gt; tag.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.find('input', {'id':'marks'})\n",
       "sibs = tag.previous_siblings\n",
       "print (\"previous siblings:\")\n",
       "for sib in sibs:\n",
       "   print (sib)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "previous siblings:\n",
       "\n",
       "&lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;\n",
       "\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The top level &lt;html&gt; tag always has two sibling tags - head and body. Hence, the &lt;body&gt; tag has only one previous sibling i.e. head, as the following code shows </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;Hello&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Excellent&lt;/p&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p&gt;Tutorial&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "   &lt;/head&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tags = soup.body.previous_siblings\n",
       "print (\"previous siblings:\")\n",
       "for tag in tags:\n",
       "   print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "previous siblings:\n",
       "\n",
       "&lt;head&gt;\n",
       "&lt;title&gt;Hello&lt;/title&gt;\n",
       "&lt;/head&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - next_element Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>In Beautiful Soup library, the next_element property returns the Tag or NavigableString that appears immediately next to the current PageElement, even if it is out of the parent tree. There is also a next property which has similar behaviour</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Element.next_element\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The next_element and next properties return a tag or a NavigableString appearing immediately next to the current tag.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the document tree parsed from the given HTML string, we find the next_element of the &lt;b&gt; tag</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p id='id1'&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'lxml')\n",
       "tag = soup.b \n",
       "print (tag)\n",
       "nxt = tag.next_element\n",
       "print (\"Next:\",nxt)\n",
       "\n",
       "nxt = tag.next_element.next_element\n",
       "print (\"Next:\",nxt)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;Excellent&lt;/b&gt;\n",
       "Next: Excellent\n",
       "Next: &lt;p&gt;Python&lt;/p&gt;\n",
       "</pre>\n",
       "<p>The output is a little strange as the next element for &lt;b&gt;Excellent&lt;/b&gt; is shown to be 'Excellent', that is because the inner string is registered as the next element. To obtain the desired result (&lt;p&gt;Python&lt;/p&gt;) as the next element, fetch the next_element property of the inner NavigableString object.</p>\n",
       "<h3>Example 2</h3>\n",
       "<p>The BeautifulSoup PageElements also support next property which is analogous to next_element property</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p id='id1'&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(html, 'lxml')\n",
       "tag = soup.b \n",
       "print (tag)\n",
       "nxt = tag.next\n",
       "print (\"Next:\",nxt)\n",
       "\n",
       "nxt = tag.next.next\n",
       "print (\"Next:\",nxt)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;Excellent&lt;/b&gt;\n",
       "Next: Excellent\n",
       "Next: &lt;p&gt;Python&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>In the next example, we try to determine the element next to &lt;body&gt; tag. As it is followed by a line break (\\n), we need to find the next element of the one next to body tag. It happens to be &lt;h1&gt; tag.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.find('body')\n",
       "nxt = tag.next_element.next\n",
       "print (\"Next:\",nxt)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Next: &lt;h1&gt;TutorialsPoint&lt;/h1&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - previous_element Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>In Beautiful Soup library, the previous_element property returns the Tag or NavigableString that appears immediately prior to the current PageElement, even if it is out of the parent tree. There is also a previous property which has similar behaviour</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Element.previous_element\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The previous_element and previous properties return a tag or a NavigableString appearing immediately before the current tag.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the document tree parsed from the given HTML string, we find the previous_element of the &lt;p id='id1'&gt; tag</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p id='id1'&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'lxml')\n",
       "tag = soup.find('p', id='id1')\n",
       "print (tag)\n",
       "pre = tag.previous_element\n",
       "print (\"Previous:\",pre)\n",
       "\n",
       "pre = tag.previous_element.previous_element\n",
       "print (\"Previous:\",pre)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p id=\"id1\"&gt;Tutorial&lt;/p&gt;\n",
       "Previous: Python\n",
       "Previous: &lt;p&gt;Python&lt;/p&gt;\n",
       "</pre>\n",
       "<p>The output is a little strange as the previous element for shown to be 'Python, that is because the inner string is registered as the previous element. To obtain the desired result (&lt;p&gt;Python&lt;/p&gt;) as the previous element, fetch the previous_element property of the inner NavigableString object.</p>\n",
       "<h3>Example 2</h3>\n",
       "<p>The BeautifulSoup PageElements also supports previous property which is analogous to previous_element property</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p id='id1'&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'lxml')\n",
       "tag = soup.find('p', id='id1')\n",
       "print (tag)\n",
       "pre = tag.previous\n",
       "print (\"Previous:\",pre)\n",
       "\n",
       "pre = tag.previous.previous\n",
       "print (\"Previous:\",pre)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p id=\"id1\"&gt;Tutorial&lt;/p&gt;\n",
       "Previous: Python\n",
       "Previous: &lt;p&gt;Python&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>In the next example, we try to determine the element next to &lt;input&gt; tag whose id attribute is 'age'</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html5lib')\n",
       "\n",
       "tag = soup.find('input', id='age')\n",
       "pre = tag.previous_element.previous\n",
       "print (\"Previous:\",pre)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Previous: &lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - next_elements Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>In Beautiful Soup library, the next_elements property returns a generator object containing the next strings or tags in the parse tree.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Element.next_elements\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The next_elements property returns a generator.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>The next_elements property returns tags and NavibaleStrings appearing after the &lt;b&gt; tag in the document string below </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p id='id1'&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.find('b')\n",
       "\n",
       "nexts = tag.next_elements\n",
       "print (\"Next elements:\")\n",
       "for next in nexts:\n",
       "   print (next)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Next elements:\n",
       "Excellent\n",
       "<p>Python</p>\n",
       "Python\n",
       "&lt;p id=\"id1\"&gt;Tutorial&lt;/p&gt;\n",
       "Tutorial\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>All the elements appearing after the &lt;p&gt; tag are listed below </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "html = '''\n",
       "   &lt;p&gt;\n",
       "   &lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;\n",
       "   &lt;/p&gt;\n",
       "   &lt;u&gt;Tutorial&lt;/u&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag1 = soup.find('p')\n",
       "print (\"Next elements:\")\n",
       "print (list(tag1.next_elements))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Next elements:\n",
       "['\\n', &lt;b&gt;Excellent&lt;/b&gt;, 'Excellent', &lt;i&gt;Python&lt;/i&gt;, 'Python', '\\n', '\\n', &lt;u&gt;Tutorial&lt;/u&gt;, 'Tutorial', '\\n']\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The elements next to the input tag present in the HTML form of index.html are listed below </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html5lib')\n",
       "\n",
       "tag = soup.find('input')\n",
       "nexts = soup.previous_elements\n",
       "print (\"Next elements:\")\n",
       "for next in nexts:\n",
       "   print (next)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Next elements:\n",
       "\n",
       "&lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;\n",
       "\n",
       "&lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - previous_elements Property</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>In Beautiful Soup library, the previous_elements property returns a generator object containing the previous strings or tags in the parse tree.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Element.previous_elements\n",
       "</pre>\n",
       "<h3>Return value</h3>\n",
       "<p>The previous_elements property returns a generator.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>The previous_elements property returns tags and NavibaleStrings appearing before the &lt;p&gt; tag in the document string below </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p id='id1'&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.find('p', id='id1')\n",
       "\n",
       "pres = tag.previous_elements\n",
       "print (\"Previous elements:\")\n",
       "for pre in pres:\n",
       "   print (pre)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Previous elements:\n",
       "Python\n",
       "&lt;p&gt;Python&lt;/p&gt;\n",
       "Excellent\n",
       "&lt;b&gt;Excellent&lt;/b&gt;\n",
       "&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p id=\"id1\"&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>All the elements appearing before the &lt;u&gt; tag are listed below </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "html = '''\n",
       "&lt;p&gt;\n",
       "&lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;\n",
       "&lt;/p&gt;\n",
       "&lt;u&gt;Tutorial&lt;/u&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag1 = soup.find('u')\n",
       "print (\"previous elements:\")\n",
       "print (list(tag1.previous_elements))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "previous elements:\n",
       "['\\n', '\\n', 'Python', &lt;i&gt;Python&lt;/i&gt;, 'Excellent', &lt;b&gt;Excellent&lt;/b&gt;, '\\n', &lt;p&gt;\n",
       "&lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;\n",
       "&lt;/p&gt;, '\\n']\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The BeautifulSoup object itself doesn't have any previous elements </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html5lib')\n",
       "\n",
       "tag = soup.find('input', id='marks')\n",
       "pres = soup.previous_elements\n",
       "print (\"Previous elements:\")\n",
       "for pre in pres:\n",
       "   print (pre.name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Previous elements:\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find() method in Beautiful Soup looks for the first Element that matches the given criteria in the children of this PageElement and returns it.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Soup.find(name, attrs, recursive, string, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<p><b>name</b>  A filter on tag name.</p>\n",
       "<p><b>attrs</b>  A dictionary of filters on attribute values.</p>\n",
       "<p><b>recursive</b>  If this is True, find() a recursive search will be performed. Otherwise, only the direct children will be considered.</p>\n",
       "<p><b>limit</b>  Stop looking after specified number of occurrences have been found.</p>\n",
       "<p><b>kwargs</b>  A dictionary of filters on attribute values.</p>\n",
       "<h3>Return value</h3>\n",
       "<p>The find() method returns Tag object or a NavigableString object</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>Let us use the following HTML script (as index.html) for the purpose</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;form&gt;\n",
       "      &lt;input type = 'text' id = 'nm' name = 'name'&gt;\n",
       "      &lt;input type = 'text' id = 'age' name = 'age'&gt;\n",
       "      &lt;input type = 'text' id = 'marks' name = 'marks'&gt;\n",
       "      &lt;/form&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The following Python code finds the element with its id as nm</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "obj = soup.find(id = 'nm')\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>The find() method returns the first tag in the parsed document that has the given attributes.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj = soup.find(attrs={\"name\":'marks'})\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>If find() can't find anything, it returns None</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "obj = soup.find('dummy')\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "None\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_all() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_all() method in Beautiful Soup looks for the elements that match the given criteria in the children of this PageElement and returns a list of all elements.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Soup.find_all(name, attrs, recursive, string, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<p><b>name</b>  A filter on tag name.</p>\n",
       "<p><b>attrs</b>  A dictionary of filters on attribute values.</p>\n",
       "<p><b>recursive</b>  If this is True, find() a recursive search will be performed. Otherwise, only the direct children will be considered.</p>\n",
       "<p><b>limit</b>  Stop looking after specified number of occurrences have been found.</p>\n",
       "<p><b>kwargs</b>  A dictionary of filters on attribute values.</p>\n",
       "<h3>Return type</h3>\n",
       "<p>The find_all() method returns a ResultSet object which is a list generator.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>When we can pass in a value for name, Beautiful Soup only considers tags with certain names. Text strings will be ignored, as will tags whose names that don't match. In this example we pass title to find_all() method.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "html = open('index.html')\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "obj = soup.find_all('input')\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;, &lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;, &lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>We shall use following HTML script in this example </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "      &lt;ul id=\"dept\"&gt;\n",
       "      &lt;li&gt;Accounts&lt;/li&gt;\n",
       "         &lt;ul id='acc'&gt;\n",
       "         &lt;li&gt;Anand&lt;/li&gt;\n",
       "         &lt;li&gt;Mahesh&lt;/li&gt;\n",
       "         &lt;/ul&gt;\n",
       "      &lt;li&gt;HR&lt;/li&gt;\n",
       "         &lt;ol id=\"HR\"&gt;\n",
       "         &lt;li&gt;Rani&lt;/li&gt;\n",
       "         &lt;li&gt;Ankita&lt;/li&gt;\n",
       "         &lt;/ol&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>We can pass a string to the name argument of find_all() method. With string you can search for strings instead of tags. You can pass in a string, a regular expression, a list, a function, or the value True.</p>\n",
       "<p>In this example, a function is passed to name argument. All the name starting with 'A' are returned by find_all() method.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "def startingwith(ch):\n",
       "   return ch.startswith('A')\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "lst=soup.find_all(string=startingwith)\n",
       "\n",
       "print (lst)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['Accounts', 'Anand', 'Ankita']\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>In this example, we pass limit=2 argument to find_all() method. The method returns first two appearances of &lt;li&gt; tag.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "lst=soup.find_all('li', limit =2)\n",
       "\n",
       "print (lst)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;li&gt;Accounts&lt;/li&gt;, &lt;li&gt;Anand&lt;/li&gt;]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_parents() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_parent() method in BeautifulSoup package finds all parents of this Element that matches the given criteria.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_parents( name, attrs, limit, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<p><b>name</b>  A filter on tag name.</p>\n",
       "<p><b>attrs</b>  A dictionary of filters on attribute values.</p>\n",
       "<p><b>limit</b>  Stop looking after specified number of occurrences have been found.</p>\n",
       "<p><b>kwargs</b>  A dictionary of filters on attribute values.</p>\n",
       "<h3>Return Type</h3>\n",
       "<p>The find_parents() method returns a ResultSet consisting of all the parent elements in a reverse order.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>We shall use following HTML script in this example </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "   &lt;h2&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "   &lt;ul id=\"dept\"&gt;\n",
       "   &lt;li&gt;Accounts&lt;/li&gt;\n",
       "      &lt;ul id='acc'&gt;\n",
       "      &lt;li&gt;Anand&lt;/li&gt;\n",
       "      &lt;li&gt;Mahesh&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;li&gt;HR&lt;/li&gt;\n",
       "      &lt;ol id=\"HR\"&gt;\n",
       "      &lt;li&gt;Rani&lt;/li&gt;\n",
       "      &lt;li&gt;Ankita&lt;/li&gt;\n",
       "      &lt;/ol&gt;\n",
       "   &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "ul\n",
       "body\n",
       "html\n",
       "[document]\n",
       "</pre>\n",
       "<p>Note that the name property of BeautifulSoup object always returns [document].</p>\n",
       "<h3>Example 2</h3>\n",
       "<p>In this example, the limit argument is passed to find_parents() method to restrict the parent search to two levels up.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "obj=soup.find('li')\n",
       "parents=obj.find_parents(limit=2)\n",
       "for parent in parents:\n",
       "   print (parent.name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "ul\n",
       "body\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_parent() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_parent() method in BeautifulSoup package finds the closest parent of this PageElement that matches the given criteria.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_parent( name, attrs, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The find_parent() method returns Tag object or a NavigableString object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>We shall use following HTML script in this example </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h2&gt;Departmentwise Employees&lt;/h2&gt;\n",
       "      &lt;ul id=\"dept\"&gt;\n",
       "      &lt;li&gt;Accounts&lt;/li&gt;\n",
       "      &lt;ul id='acc'&gt;\n",
       "      &lt;li&gt;Anand&lt;/li&gt;\n",
       "      &lt;li&gt;Mahesh&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "      &lt;li&gt;HR&lt;/li&gt;\n",
       "      &lt;ol id=\"HR\"&gt;\n",
       "      &lt;li&gt;Rani&lt;/li&gt;\n",
       "      &lt;li&gt;Ankita&lt;/li&gt;\n",
       "      &lt;/ol&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>In the following example, we find the name of the tag that is parent to the string 'HR'.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup \n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "obj=soup.find(string='HR')\n",
       "print (obj.find_parent().name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "li\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>The &lt;body&gt; tag is always enclosed within the top level &lt;html&gt; tag. In the following example, we confirm this fact with find_parent() method </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "obj=soup.find('body')\n",
       "print (obj.find_parent().name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "html\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_next_siblings() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_next_siblings() method is similar to next_sibling property. It finds all siblings at the same level of this PageElement that match the given criteria and appear later in the document.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_fnext_siblings(name, attrs, string, limit, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>string</b>  The string to search for (rather than tag).</p></li>\n",
       "<li><p><b>limit</b>  Stop looking after specified number of occurrences have been found.</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The find_next_siblings() method returns a list of Tag objects or a NavigableString objects.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>Let us use the following HTML snippet for this purpose </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;p&gt;\n",
       "   &lt;b&gt;\n",
       "      Excellent\n",
       "   &lt;/b&gt;\n",
       "   &lt;i&gt;\n",
       "      Python\n",
       "   &lt;/i&gt;\n",
       "   &lt;u&gt;\n",
       "      Tutorial\n",
       "   &lt;/u&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<p>In the code below, we try to find all the siblings of &lt;b&gt; tag. There are two more tags at the same level in the HTML string used for scraping.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;u&gt;Tutorial&lt;/u&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.find('b')\n",
       "print (\"next siblings:\")\n",
       "for tag in tag1.find_next_siblings():\n",
       "    print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<p>The ResultSet of find_next_siblings() is being iterated with the help of for loop.</p>\n",
       "<pre class=\"result notranslate\">\n",
       "next siblings:\n",
       "&lt;i&gt;Python&lt;/i&gt;\n",
       "&lt;u&gt;Tutorial&lt;/u&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>If there are no siblings to be found after a tag, this method returns an empty list.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;u&gt;Tutorial&lt;/u&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.find('u')\n",
       "print (\"next siblings:\")\n",
       "print (tag1.find_next_siblings())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next siblings:\n",
       "[]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_next_sibling() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_next_sibling() method in Beautiful Soup Find the closest sibling at the same level to this PageElement that matches the  given criteria and appears later in the document. This method is similar to next_sibling property.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_fnext_sibling(name, attrs, string, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>string</b>  The string to search for (rather than tag).</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The find_next_sibling() method returns Tag object or a NavigableString object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.find('b')\n",
       "print (\"next:\",tag1.find_next_sibling())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next: &lt;i&gt;Python&lt;/i&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>If the next node doesn't exist, the method returns None.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.find('i')\n",
       "print (\"next:\",tag1.find_next_sibling())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "next: None\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_previous_siblings() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_previous_siblings() method in Beautiful Soup package returns all siblings that appear earlier to this PAgeElement in the document and match the given criteria.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_previous_siblings(name, attrs, string, limit, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>string</b>  A filter for a NavigableString with specific text.</p></li>\n",
       "<li><p><b>limit</b>  Stop looking after finding this many results.</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The find_previous_siblings() method a ResultSet of PageElements.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>Let us use the following HTML snippet for this purpose </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;p&gt;\n",
       "   &lt;b&gt;\n",
       "      Excellent\n",
       "   &lt;/b&gt;\n",
       "   &lt;i&gt;\n",
       "      Python\n",
       "   &lt;/i&gt;\n",
       "   &lt;u&gt;\n",
       "      Tutorial\n",
       "   &lt;/u&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<p>In the code below, we try to find all the siblings of &lt;&gt; tag. There are two more tags at the same level in the HTML string used for scraping.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;u&gt;Tutorial&lt;/u&gt;&lt;/p&gt;\", 'html.parser')\n",
       "\n",
       "tag1 = soup.find('u')\n",
       "print (\"previous siblings:\")\n",
       "for tag in tag1.find_previous_siblings():\n",
       "   print (tag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;i&gt;Python&lt;/i&gt;\n",
       "&lt;b&gt;Excellent&lt;/b&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>The web page (index.html) has a HTML form with three input elements. We locate one with id attribute as marks and then find its previous siblings.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.find('input', {'id':'marks'})\n",
       "sibs = tag.find_previous_sibling()\n",
       "print (sibs)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;, &lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The HTML string has two &lt;p&gt; tags. We find out the siblings previous to the one with id1 as its id attribute.</p>\n",
       "<pre class=\"demo-code notranslate language-html\" data-lang=\"html\">\n",
       "html = '''\n",
       "&lt;p&gt;&lt;b&gt;Excellent&lt;/b&gt;&lt;p&gt;Python&lt;/p&gt;&lt;p id='id1'&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.find('p', id='id1')\n",
       "ptags = tag.find_previous_siblings()\n",
       "for ptag in ptags:\n",
       "   print (\"Tag: {}, Text: {}\".format(ptag.name, ptag.text))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Tag: p, Text: Python\n",
       "Tag: b, Text: Excellent\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_previous_sibling() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_previous_sibling() method in Beautiful Soup returns the closest sibling to this PageElement that matches the given criteria and appears earlier in the document.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_previous_sibling(name, attrs, string, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>string</b>  A filter for a NavigableString with specific text.</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The find_previous_sibling() method returns a PageElement that could be a Tag or a NavigableString.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>From the HTML string used in the following example, we find out the previous sibling of &lt;i&gt; tag, having the tag name as 'u'</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(\"&lt;p&gt;&lt;u&gt;Excellent&lt;/u&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;i&gt;Python&lt;/i&gt;&lt;/p&gt;\", 'html.parser')\n",
       "tag = soup.i\n",
       "sibling = tag.find_previous_sibling('u')\n",
       "print (sibling)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;u&gt;Excellent&lt;/u&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>The web page (index.html) has a HTML form with three input elements. We locate one with id attribute as marks and then find its previous sibling that had id set to nm.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.find('input', {'id':'marks'})\n",
       "sib = tag.find_previous_sibling(id='nm')\n",
       "print (sib)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>In the code below, the HTML string has two &lt;p&gt; elements and a string inside the outer &lt;p&gt; tag. We use find_previous_string() method to search for the NavigableString object sibling of &lt;p&gt;Tutorial&lt;/p&gt; tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;Excellent&lt;p&gt;Python&lt;/p&gt;&lt;p&gt;Tutorial&lt;/p&gt;&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "\n",
       "tag = soup.find('p', string='Tutorial')\n",
       "ptag = tag.find_previous_sibling(string='Excellent')\n",
       "print (ptag, type(ptag))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Excellent &lt;class 'bs4.element.NavigableString'&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_all_next() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_all_next() method in Beautiful Soup finds all PageElements that match the given criteria and appear after this element in the document. This method returns tags or NavigableString objects and method takes in the exact same parameters as find_all().</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_all_next(name, attrs, string, limit, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>recursive</b>  If this is True, find() a recursive search will be performed. Otherwise, only the direct children will be considered.</p></li>\n",
       "<li><p><b>limit</b>  Stop looking after specified number of occurrences have been found.</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>This method returns a ResultSet containing PageElements (Tags or NavigableString objects).</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>Using the index.html as the HTML document for this example, we first locate the &lt;form&gt; tag and collect all the elements after it with find_all_next() method.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.form\n",
       "tags = tag.find_all_next()\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;, &lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;, &lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>Here, we apply a filter to the find_all_next() method to collect all the tags subsequent to &lt;form&gt;, with id being nm or age.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.form\n",
       "tags = tag.find_all_next(id=['nm', 'age'])\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;, &lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>If we check the tags following the body tag, it includes a &lt;h1&gt; tag as well as &lt;form&gt; tag, that includes three input elements.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.body\n",
       "tags = tag.find_all_next()\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;h1&gt;TutorialsPoint&lt;/h1&gt;\n",
       "&lt;form&gt;\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "&lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;\n",
       "&lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;\n",
       "&lt;/form&gt;\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "&lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;\n",
       "&lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_next() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_next() method in Beautiful soup finds the first PageElement that matches the given criteria and appears later in the document. returns the first tag or NavigableString that comes after the current tag in the document. Like all other find methods, this method has the following syntax </p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_next(name, attrs, string, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>string</b>  A filter for a NavigableString with specific text.</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>This find_next () method returns a Tag or a NavigableString</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>A web page index.html with following script has been used for this example</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h1&gt;TutorialsPoint&lt;/h1&gt;\n",
       "      &lt;form&gt;\n",
       "         &lt;input type = 'text' id = 'nm' name = 'name'&gt;\n",
       "         &lt;input type = 'text' id = 'age' name = 'age'&gt;\n",
       "         &lt;input type = 'text' id = 'marks' name = 'marks'&gt;\n",
       "      &lt;/form&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>We first locate the &lt;form&gt; tag and then the one next to it.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.h1\n",
       "print (tag.find_next())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;form&gt;\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "&lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;\n",
       "&lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;\n",
       "&lt;/form&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In this example, we first locate the &lt;input&gt; tag with its name='age' and obtain its next tag.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.find('input', {'name':'age'})\n",
       "print (tag.find_next())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The tag next to the &lt;head&gt; tag happens to be &lt;title&gt; tag.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "\n",
       "tag = soup.head\n",
       "print (tag.find_next())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_all_previous() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_all_previous() method in Beautiful Soup look backwards in the document from this PageElement and finds all the PageElements that match the given criteria and appear before the current element. It returns a ResultsSet of PageElements that comes before the current tag in the document. Like all other find methods, this method has the following syntax </p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_previous(name, attrs, string, limit, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>string</b>  A filter for a NavigableString with specific text.</p></li>\n",
       "<li><p><b>limit</b>  Stop looking after finding this many results.</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The find_all_previous() method returns a ResultSet of Tag or NavigableString objects. If the limit parameter is 1, the method is equivalent to find_previous() method.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In this example, name property of each object that appears before the first input tag is displayed.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.find('input')\n",
       "for t in tag.find_all_previous():\n",
       "   print (t.name)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "form\n",
       "h1\n",
       "body\n",
       "title\n",
       "head\n",
       "html\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the HTML document under consideration (index.html), there are three input elements. With the following code, we print the tag names of all preceding tags before thr &lt;input&gt; tag with nm attribute as marks. To differentiate between the two input tags before it, we also print the attrs property. Note that the other tags don't have any attributes.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.find('input', {'name':'marks'})\n",
       "pretags = tag.find_all_previous()\n",
       "for pretag in pretags:\n",
       "   print (pretag.name, pretag.attrs)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "input {'type': 'text', 'id': 'age', 'name': 'age'}\n",
       "input {'type': 'text', 'id': 'nm', 'name': 'name'}\n",
       "form {}\n",
       "h1 {}\n",
       "body {}\n",
       "title {}\n",
       "head {}\n",
       "html {}\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The BeautifulSoup object stores the entire document's tree. It doesn't have any previous element, as the example below shows </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tags = soup.find_all_previous()\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - find_previous() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The find_previous() method in Beautiful Soup look backwards in the document from this PageElement and find the first PageElement that matches the given criteria. It returns the first tag or NavigableString that comes before the current tag in the document. Like all other find methods, this method has the following syntax </p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "find_previous(name, attrs, string, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  A filter on tag name.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "<li><p><b>string</b>  A filter for a NavigableString with specific text.</p></li>\n",
       "<li><p><b>kwargs</b>  A dictionary of filters on attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The find_previous() method returns a Tag or NavigableString object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the example below, we try to find which is the previous object before the &lt;body&gt; tag. It happens to be &lt;title&gt; element.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.body\n",
       "print (tag.find_previous())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>There are three input elements in the HTML document used in this example. The following code locates the input element with name attribute = age and looks for its previous element.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.find('input', {'name':'age'})\n",
       "print (tag.find_previous())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The element before &lt;title&gt; happens to be &lt;head&gt; element.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open(\"index.html\")\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tag = soup.find('title')\n",
       "print (tag.find_previous())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;head&gt;\n",
       "&lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "&lt;/head&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - select() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>In Beautiful Soup library, the select() method is an important tool for scraping the HTML/XML document. Similar to find() and find_*() methods, the select() method also helps in locating an element that satisfies a given criteria. The selection of an element in the document tree is done based on the CSS selector given to it as an argument.</p>\n",
       "<p>Beautiful Soup also has select_one() method. Difference in select() and select_one() is that, select() returns a ResultSet of all the elements belonging to the PageElement and characterized by the CSS selector; whereas select_one() returns the first occurrence of the element satisfying the CSS selector based selection criteria.</p>\n",
       "<p>Prior to Beautiful Soup version 4.7, the select() method used to be able to support only the common CSS selectors. With version 4.7, Beautiful Soup was integrated with Soup Sieve CSS selector library. As a result, much more selectors can now be used. In the version 4.12, a .css property has been added in addition to the existing convenience methods, select() and select_one().</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "select(selector, limit, **kwargs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>selector</b>  A string containing a CSS selector.</p></li>\n",
       "<li><p><b>limit</b>  After finding this number of results, stop looking.</p></li>\n",
       "<li><p><b>kwargs</b>  Keyword arguments to be passed.</p></li>\n",
       "</ul>\n",
       "<p>If the limit parameter is set to 1, it becomes equivalent to select_one() method.</p>\n",
       "<h3>Return Value</h3>\n",
       "<p>The select() method returns a ResultSet of Tag objects. The select_one() method returns a single Tag object.</p>\n",
       "<p>The Soup Sieve library has different types of CSS selectors. The basic CSS selectors are </p>\n",
       "<ul class=\"list\">\n",
       "<li><p>Type selectors match elements by node name. For example </p></li>\n",
       "</ul>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.select('div')\n",
       "</pre>\n",
       "<ul class=\"list\">\n",
       "<li><p>The Universal selector (*) matches elements of any type. Example </p></li>\n",
       "</ul>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.select('*')\n",
       "</pre>\n",
       "<ul class=\"list\">\n",
       "<li><p>The ID selector matches an element based on its id attribute. The symbol # denotes the ID selector. Example </p></li>\n",
       "</ul>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.select(\"#nm\")\n",
       "</pre>\n",
       "<ul class=\"list\">\n",
       "<li><p>The class selector matches an element based on the values contained in the class attribute. The . symbol prefixed to the class name is the CSS class selector. Example </p></li>\n",
       "</ul>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "tags = soup.select(\".submenu\")\n",
       "</pre>\n",
       "<h2>Example: Type Selector</h2>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '''\n",
       "   &lt;div id=\"Languages\"&gt;\n",
       "      &lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tags = soup.select('div')\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;div id=\"Languages\"&gt;\n",
       "&lt;p&gt;Java&lt;/p&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;C++&lt;/p&gt;\n",
       "&lt;/div&gt;]\n",
       "</pre>\n",
       "<h2>Example: ID selector</h2>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "html = '''\n",
       "   &lt;form&gt;\n",
       "      &lt;input type = 'text' id = 'nm' name = 'name'&gt;\n",
       "      &lt;input type = 'text' id = 'age' name = 'age'&gt;\n",
       "      &lt;input type = 'text' id = 'marks' name = 'marks'&gt;\n",
       "   &lt;/form&gt;\n",
       "'''\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "obj = soup.select(\"#nm\")\n",
       "print (obj)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;]\n",
       "</pre>\n",
       "<h2>Example: class selector</h2>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;ul&gt;\n",
       "      &lt;li class=\"mainmenu\"&gt;Accounts&lt;/li&gt;\n",
       "      &lt;ul&gt;\n",
       "         &lt;li class=\"submenu\"&gt;Anand&lt;/li&gt;\n",
       "         &lt;li class=\"submenu\"&gt;Mahesh&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "      &lt;li class=\"mainmenu\"&gt;HR&lt;/li&gt;\n",
       "      &lt;ul&gt;\n",
       "         &lt;li class=\"submenu\"&gt;Rani&lt;/li&gt;\n",
       "         &lt;li class=\"submenu\"&gt;Ankita&lt;/li&gt;\n",
       "      &lt;/ul&gt;\n",
       "   &lt;/ul&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tags = soup.select(\".mainmenu\")\n",
       "print (tags)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "[&lt;li class=\"mainmenu\"&gt;Accounts&lt;/li&gt;, &lt;li class=\"mainmenu\"&gt;HR&lt;/li&gt;]\n",
       "</pre>\n",
       "<h1>Beautiful Soup - append() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The append() method in Beautiful Soup adds a given string or another tag at the end of the current Tag object's contents. The append() method works similar to the append() method of Python's list object.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "append(obj)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>obj</b>  any PageElement, may be a string, a NavigableString object or a Tag object.</p></li>\n",
       "</ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The append() method doesn't return a new object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the following example, the HTML script has a &lt;p&gt; tag. With append(), additional text is appended.In the following example, the HTML script has a &lt;p&gt; tag. With append(), additional text is appended.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "markup = '&lt;p&gt;Hello&lt;/p&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "print (soup)\n",
       "tag = soup.p\n",
       "\n",
       "tag.append(\" World\")\n",
       "print (soup) \n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Hello&lt;/p&gt;\n",
       "&lt;p&gt;Hello World&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>With the append() method, you can add a new tag at the end of an existing tag. First create a new Tag object with new_tag() method and then pass it to the append() method.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, Tag\n",
       "\n",
       "markup = '&lt;b&gt;Hello&lt;/b&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.b \n",
       "tag1 = soup.new_tag('i')\n",
       "tag1.string = 'World'\n",
       "tag.append(tag1)\n",
       "print (soup.prettify()) \n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "   &lt;b&gt;\n",
       "      Hello\n",
       "   &lt;i&gt;\n",
       "      World\n",
       "   &lt;/i&gt;\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>If you have to add a string to the document, you can append a NavigableString object.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Hello&lt;/b&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.b \n",
       "new_string = NavigableString(\" World\")\n",
       "tag.append(new_string)\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Hello\n",
       "   World\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - extend() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The extend() method in Beautiful Soup has been added to Tag class  from version 4.7 onwards. It adds all the elements in a list to the tag. This method is analogous to a standard Python List's extend() method - it takes in an array of strings to append to the tag's content.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "extend(tags)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>tags</b>  A list of srings or NavigableString objects to be appended.</p></li>\n",
       "</ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The extend() method doesn't return any new object.</p>\n",
       "<h3>Example</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "markup = '&lt;b&gt;Hello&lt;/b&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "\n",
       "tag = soup.b \n",
       "vals = ['World.', 'Welcome to ', 'TutorialsPoint']\n",
       "tag.extend(vals)\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Hello\n",
       "   World.\n",
       "   Welcome to\n",
       "   TutorialsPoint\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - NavigableString() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The NavigableString() method in bs4 package is the constructor method for NavigableString class. A NavigableString represents the innermost child element of a parsed document. This method casts a regular Python string to a NavigableString. Conversely, the built-in str() method coverts NavigableString object to a Unicode string.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "NavigableString(string)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>string</b>  an object of Python's str class.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The NavigableString() method returns a NavigableString object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the code below, the HTML string contains an empty &lt;b&gt; tag. We add a NavigableString object in it.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "navstr = NavigableString(\"Hello World\")\n",
       "soup.b.append(navstr)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;&lt;b&gt;Hello World&lt;/b&gt;&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In this example, we see that two NavigableString objects are appended to an empty &lt;b&gt; tag. The tag responds to strings property instead of string property. It is a generator of NavigableString objects.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "navstr = NavigableString(\"Hello\")\n",
       "soup.b.append(navstr)\n",
       "navstr = NavigableString(\"World\")\n",
       "soup.b.append(navstr)\n",
       "for s in soup.b.strings:\n",
       "   print (s, type(s))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Hello &lt;class 'bs4.element.NavigableString'&gt;\n",
       "World &lt;class 'bs4.element.NavigableString'&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Instead of strings property, if we access the stripped_strings property of &lt;b&gt; tag object, we get a generator of Unicode strings i.e. str objects.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = \"\"\"\n",
       "&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;\n",
       "\"\"\"\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "navstr = NavigableString(\"Hello\")\n",
       "soup.b.append(navstr)\n",
       "navstr = NavigableString(\"World\")\n",
       "soup.b.append(navstr)\n",
       "for s in soup.b.stripped_strings:\n",
       "   print (s, type(s))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Hello &lt;class 'str'&gt;\n",
       "World &lt;class 'str'&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - new_tag() Method</h1>\n",
       "<p>The new_tag() method in Beautiful Soup library creates a new Tag object, that is associated with an existing BeautifulSoup object. You can use this factory method to append or insert the new tag into the document tree.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "new_tag(name, namespace, nsprefix, attrs, sourceline, sourcepos, **kwattrs)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>name</b>  The name of the new Tag.</p></li>\n",
       "<li><p><b>namespace</b>  The URI of the new Tag's XML namespace, optional.</p></li>\n",
       "<li><p><b>prefix</b>  The prefix for the new Tag's XML namespace, optional.</p></li>\n",
       "<li><p><b>attrs</b>  A dictionary of this Tag's attribute values.</p></li>\n",
       "<li><p><b>sourceline</b>  The line number where this tag was found in its source document.</p></li>\n",
       "<li><p><b>sourcepos</b>  The character position within `sourceline` where this tag was found.</p></li>\n",
       "<li><p><b>kwattrs</b>  Keyword arguments for the new Tag's attribute values.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>This method returns a new Tag object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>The following example shows the use of new_tag() method. A new tag for &lt;a&gt; element. The tag object is initialized with the href and string attributes and then inserted in the document tree.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup('&lt;p&gt;Welcome to &lt;b&gt;online Tutorial library&lt;/b&gt;&lt;/p&gt;', 'html.parser')\n",
       "tag = soup.new_tag('a')\n",
       "tag.attrs['href'] = \"www.tutorialspoint.com\"\n",
       "tag.string = \"Tutorialspoint\"\n",
       "soup.b.insert_before(tag)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;Welcome to &lt;a href=\"www.tutorialspoint.com\"&gt;Tutorialspoint&lt;/a&gt;&lt;b&gt;online Tutorial library&lt;/b&gt;&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the following example, we have a HTML form with two input elements. We create a new input tag and append it to the form tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;form&gt;\n",
       "      &lt;input type = 'text' id = 'nm' name = 'name'&gt;\n",
       "      &lt;input type = 'text' id = 'age' name = 'age'&gt;\n",
       "   &lt;/form&gt;'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, 'html.parser')\n",
       "tag = soup.form\n",
       "newtag=soup.new_tag('input', attrs={'type':'text', 'id':'marks', 'name':'marks'})\n",
       "tag.append(newtag)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;form&gt;\n",
       "&lt;input id=\"nm\" name=\"name\" type=\"text\"/&gt;\n",
       "&lt;input id=\"age\" name=\"age\" type=\"text\"/&gt;\n",
       "&lt;input id=\"marks\" name=\"marks\" type=\"text\"/&gt;&lt;/form&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Here we have an empty &lt;p&gt; tag in the HTML string. A new tag is inserted in it.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "soup = BeautifulSoup('&lt;p&gt;&lt;/p&gt;', 'html.parser')\n",
       "tag = soup.new_tag('b')\n",
       "tag.string = \"Hello World\"\n",
       "soup.p.insert(0,tag)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;&lt;b&gt;Hello World&lt;/b&gt;&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - insert() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The insert() method in Beautiful Soup add an element at the given position in a the list of children of a Tag element. The insert() method in Beautiful Soup behaves similar to insert() on a Python list object.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "insert(position, child)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>position</b>  The position at which the new PageElement should be inserted.</p></li>\n",
       "<li><p><b>child</b>  A PageElement to be inserted.</p></li>\n",
       "</ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The insert() method doesn't return any new object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the following example, a new string is added to the &lt;b&gt; tag at position 1. The resultant parsed document shows the result. </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Excellent &lt;/b&gt;&lt;u&gt;from TutorialsPoint&lt;/u&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.b\n",
       "\n",
       "tag.insert(1, \"Tutorial \")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   Excellent\n",
       "   Tutorial\n",
       "&lt;/b&gt;\n",
       "&lt;u&gt;\n",
       "   from TutorialsPoint\n",
       "&lt;/u&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the following example, the insert() method is used to successively insert strings from a list to a &lt;p&gt; tag in HTML markup.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;p&gt;Excellent Tutorials from TutorialsPoint&lt;/p&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "langs = ['Python', 'Java', 'C']\n",
       "i=0\n",
       "for lang in langs:\n",
       "   i+=1\n",
       "   tag = soup.new_tag('p')\n",
       "   tag.string = lang\n",
       "   soup.p.insert(i, tag)\n",
       "\n",
       "\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;\n",
       "   Excellent Tutorials from TutorialsPoint\n",
       "   &lt;p&gt;\n",
       "   Python\n",
       "   &lt;/p&gt;\n",
       "   &lt;p&gt;\n",
       "      Java\n",
       "   &lt;/p&gt;\n",
       "   &lt;p&gt;\n",
       "      C\n",
       "   &lt;/p&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - insert_before() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The insert_before() method in Beautiful soup inserts tags or strings immediately before something else in the parse tree. The inserted element becomes the immediate predecessor of this one. The inserted element can be a tag or a string.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "insert_before(*args)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>args</b>  One or more elements, may be tag or a string.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>This insert_before() method doesn't return any new object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>The following example inserts a text \"Here is an\" before \"Excellent in the given HTML markup string.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;b&gt;Excellent&lt;/b&gt; Python Tutorial &lt;u&gt;from TutorialsPoint&lt;/u&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.b\n",
       "\n",
       "tag.insert_before(\"Here is an \")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Here is an\n",
       "&lt;b&gt;\n",
       "   Excellent\n",
       "&lt;/b&gt;\n",
       "   Python Tutorial\n",
       "&lt;u&gt;\n",
       "   from TutorialsPoint\n",
       "&lt;/u&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>You can also insert a tag before another tag. Take a look at this example.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;P&gt;Excellent &lt;b&gt;Tutorial&lt;/b&gt; from TutorialsPoint&lt;/u&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.b\n",
       "tag1 = soup.new_tag('b')\n",
       "tag1.string = \"Python \"\n",
       "tag.insert_before(tag1)\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;\n",
       "   Excellent\n",
       "   &lt;b&gt;\n",
       "      Python\n",
       "   &lt;/b&gt;\n",
       "   &lt;b&gt;\n",
       "      Tutorial\n",
       "   &lt;/b&gt;\n",
       "   from TutorialsPoint\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The following code passes more than one strings to be inserted before the &lt;b&gt; tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "markup = '&lt;p&gt;There are &lt;b&gt;Tutorials&lt;/b&gt; &lt;u&gt;from TutorialsPoint&lt;/u&gt;&lt;/p&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.b\n",
       "\n",
       "tag.insert_before(\"many \", 'excellent ')\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;\n",
       "   There are\n",
       "   many\n",
       "   excellent\n",
       "   &lt;b&gt;\n",
       "      Tutorials\n",
       "   &lt;/b&gt;\n",
       "   &lt;u&gt;\n",
       "      from TutorialsPoint\n",
       "   &lt;/u&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - insert_after() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The insert_after() method in Beautiful soup inserts tags or strings immediately after something else in the parse tree. The inserted element becomes the immediate successor of this one. The inserted element can be a tag or a string.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "insert_after(*args)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>args</b>  One or more elements, may be tag or a string.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>This insert_after() method doesn't return any new object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>Following code inserts a string \"Python\" after the first &lt;b&gt; tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "markup = '&lt;p&gt;An &lt;b&gt;Excellent&lt;/b&gt; Tutorial &lt;u&gt;from TutorialsPoint&lt;/u&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.b\n",
       "\n",
       "tag.insert_after(\"Python \")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;\n",
       "   An\n",
       "   &lt;b&gt;\n",
       "      Excellent\n",
       "   &lt;/b&gt;\n",
       "   Python\n",
       "   Tutorial\n",
       "   &lt;u&gt;\n",
       "      from TutorialsPoint\n",
       "   &lt;/u&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>You can also insert a tag before another tag. Take a look at this example.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;P&gt;Excellent &lt;b&gt;Tutorial&lt;/b&gt; from TutorialsPoint&lt;/p&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.b\n",
       "tag1 = soup.new_tag('b')\n",
       "tag1.string = \"on Python \"\n",
       "tag.insert_after(tag1)\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;\n",
       "   Excellent\n",
       "   &lt;b&gt;\n",
       "      Tutorial\n",
       "   &lt;/b&gt;\n",
       "   &lt;b&gt;\n",
       "      on Python\n",
       "   &lt;/b&gt;\n",
       "   from TutorialsPoint\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Multiple tags or strings can be inserted after a certain tags.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup, NavigableString\n",
       "\n",
       "markup = '&lt;P&gt;Excellent &lt;b&gt;Tutorials&lt;/b&gt; from TutorialsPoint&lt;/p&gt;'\n",
       "soup = BeautifulSoup(markup, 'html.parser')\n",
       "tag = soup.p\n",
       "tag1 = soup.new_tag('i')\n",
       "tag1.string = 'and Java'\n",
       "tag.insert_after(\"on Python\", tag1)\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;\n",
       "   Excellent\n",
       "   &lt;b&gt;\n",
       "      Tutorials\n",
       "   &lt;/b&gt;\n",
       "   from TutorialsPoint\n",
       "&lt;/p&gt;\n",
       "on Python\n",
       "&lt;i&gt;\n",
       "   and Java\n",
       "&lt;/i&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - clear() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The clear() method in Beautiful Soup library removes the inner content of a tag, keeping the tag intact. If there are any child elements, extract() method is called on them. If decompose argument is set to True, then decompose() method is called instead of extract().</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "clear(decompose=False)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>decompose</b>  If this is True, decompose() (a more destructive method) will be called instead of extract()</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The clear() method doesn't return any object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>As clear() method is called on the soup object that represents the entire document, all the content is removed, leaving the document blank.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "soup.clear()\n",
       "print(soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the following example, we find all the &lt;p&gt; tags and call clear() method on each of them.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tags = soup.find_all('p')\n",
       "for tag in tags:\n",
       "   tag.clear() \n",
       "\n",
       "print(soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<p>Contents of each &lt;p&gt; .. &lt;/p&gt; will be removed, the tags will be retained.</p>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt;&lt;/p&gt;\n",
       "&lt;p&gt;&lt;/p&gt;\n",
       "&lt;p&gt;&lt;/p&gt;\n",
       "&lt;p&gt;&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Here we clear the contents of &lt;body&gt; tags with decompose argument set to Tue.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tags = soup.find('body')\n",
       "ret = tags.clear(decompose=True)\n",
       "\n",
       "print(soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - extract() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The extract() method in Beautiful Soup library is used to remove a tag or a string from the document tree. The extract() method returns the object that has been removed. It is similar to how a pop() method in Python list works.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "extract(index)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>Index</b>  The position of the element to be removed. None by default.</p></li>\n",
       "</ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The extract() method returns the element that has been removed from the document tree.</p>\n",
       "<h3>Example 1</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;div&gt;\n",
       "      &lt;p&gt;Hello Python&lt;/p&gt;\n",
       "   &lt;/div&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup=BeautifulSoup(html, 'html.parser')\n",
       "                \n",
       "tag1 = soup.find(\"div\")\n",
       "tag2 = tag1.find(\"p\")\n",
       "ret = tag2.extract()\n",
       "print ('Extracted:',ret)\n",
       "print ('original:',soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Extracted: &lt;p&gt;Hello Python&lt;/p&gt;\n",
       "original:\n",
       "&lt;div&gt;\n",
       "&lt;/div&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>Consider the following HTML markup </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt; Bawds jog, flick quartz, vex nymphs./p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>Here is the code </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "fp = open('index.html')\n",
       "soup = BeautifulSoup(fp, 'html.parser')\n",
       "tags = soup.find_all()\n",
       "for tag in tags:\n",
       "   obj = tag.extract()\n",
       "   print (\"Extracted:\",obj)\n",
       "\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Extracted: &lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "&lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "&lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "&lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "Extracted: &lt;body&gt;\n",
       "&lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "&lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "&lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "&lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "Extracted: &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "Extracted: &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "Extracted: &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "Extracted: &lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>You can also use extract() method along with find_next(), find_previous() methods and next_element, previous_element properties.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;div&gt;\n",
       "&lt;p&gt;&lt;b&gt;Hello&lt;/b&gt;&lt;b&gt;Python&lt;/b&gt;&lt;/p&gt;\n",
       "&lt;/div&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup=BeautifulSoup(html, 'html.parser')\n",
       "                \n",
       "tag1 = soup.find(\"b\")\n",
       "ret = tag1.next_element.extract()\n",
       "print ('Extracted:',ret)\n",
       "print ('original:',soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "Extracted: Hello\n",
       "original:\n",
       "&lt;div&gt;\n",
       "&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;b&gt;Python&lt;/b&gt;&lt;/p&gt;\n",
       "&lt;/div&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - decompose() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The decompose() method destroys current element along with its children, thus the element is removed from the tree, wiping it out and everything beneath it. You can check whether an element has been decomposed, by the `decomposed` property. It returns True if destroyed, false otherwise.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "decompose()\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<p>No parameters are defined for this method.</p>\n",
       "<h3>Return Type</h3>\n",
       "<p>The method doesn't return any object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>When we call descompose() method on the BeautifulSoup object itself, the entire content will be destroyed.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "soup.decompose()\n",
       "print (\"decomposed:\",soup.decomposed)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "decomposed: True\n",
       "document: Traceback (most recent call last):\n",
       "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~\n",
       "TypeError: can only concatenate str (not \"NoneType\") to str\n",
       "</pre>\n",
       "<p>Since the soup object is decomposed, it returns True, however, you get TypeError as shown above.</p>\n",
       "<h3>Example 2</h3>\n",
       "<p>The code below makes use of decompose() method to remove all the occurrences of &lt;p&gt; tags in the HTML string used.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "p_all = soup.find_all('p')\n",
       "[p.decompose() for p in p_all]\n",
       "\n",
       "print (\"document:\",soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<p>Rest of the HTML document after removing all &lt;p&gt; tags will be printed.</p>\n",
       "<pre class=\"result notranslate\">\n",
       "document: \n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Here, we find the &lt;body&gt; tag from the HTML document tree and decompose the previous element which happens to be the &lt;title&gt; tag. The resultant document tree omits the &lt;title&gt; tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;TutorialsPoint&lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      Hello World\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tag = soup.body\n",
       "tag.find_previous().decompose()\n",
       "\n",
       "print (\"document:\",soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "document: \n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "Hello World\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - replace_with() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>Beautiful Soup's replace_with() method replaces a tag or string in an element with the provided tag or string.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "replace_with(tag/string)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<p>The method accepts a tag object or a string as argument.</p>\n",
       "<h3>Return Type</h3>\n",
       "<p>The replace_method doesn't return a new object.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In this example, the &lt;p&gt; tag is replaced by &lt;b&gt; with the use of replace_with() method.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tag1 = soup.find('p')\n",
       "txt = tag1.string\n",
       "tag2 = soup.new_tag('b')\n",
       "tag2.string = txt\n",
       "tag1.replace_with(tag2)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;b&gt;The quick, brown fox jumps over a lazy dog.&lt;/b&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>You can simply replace the inner text of a tag with another string by calling replace_with() method on the tag.string object.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tag1 = soup.find('p')\n",
       "tag1.string.replace_with(\"DJs flock by when MTV ax quiz prog.\")\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The tag object to be used for replacement can be obtained by any of the find() methods. Here, we replace the text of the tag next to &lt;p&gt; tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, &lt;b&gt;brown&lt;/b&gt; fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tag1 = soup.find('p')\n",
       "tag1.find_next('b').string.replace_with('black')\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt;The quick, &lt;b&gt;black&lt;/b&gt; fox jumps over a lazy dog.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - wrap() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The wrap() method in Beautiful Soup encloses the element inside another element. You can wrap an existing tag element with another, or wrap the tag's string with a tag.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "wrap(tag)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<p>The tag to be wrapped with.</p>\n",
       "<h3>Return Type</h3>\n",
       "<p>The method returns a new wrapper with the given tag.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In this example, the &lt;b&gt; tag is wrapped in &lt;div&gt; tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, &lt;b&gt;brown&lt;/b&gt; fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tag1 = soup.find('b')\n",
       "newtag = soup.new_tag('div')\n",
       "tag1.wrap(newtag)\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "&lt;p&gt;The quick, &lt;div&gt;&lt;b&gt;brown&lt;/b&gt;&lt;/div&gt; fox jumps over a lazy dog.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>We wrap the string inside the &lt;p&gt; tag with a wrapper tag.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;tutorialspoint.com&lt;/p&gt;\", 'html.parser')\n",
       "soup.p.string.wrap(soup.new_tag(\"b\"))\n",
       "\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;&lt;b&gt;tutorialspoint.com&lt;/b&gt;&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - unwrap() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The unwrap() method is the opposite of wrap() method. It It replaces a tag with whatever's inside that tag. It removes the tag from an element and returns it.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "unwrap()\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<p>The method doesn't require any parameter.</p>\n",
       "<h3>Return Type</h3>\n",
       "<p>The unwrap() method returns the tag that has been removed.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the following example, the &lt;b&gt; tag from the html string is removed.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;The quick, &lt;b&gt;brown&lt;/b&gt; fox jumps over a lazy dog.&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tag1 = soup.find('b')\n",
       "newtag = tag1.unwrap()\n",
       "\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>The code below prints the returned value of unwrap() method.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;The quick, &lt;b&gt;brown&lt;/b&gt; fox jumps over a lazy dog.&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "tag1 = soup.find('b')\n",
       "newtag = tag1.unwrap()\n",
       "\n",
       "print (newtag)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;&lt;/b&gt;\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The unwrap() method is useful for good for stripping out markup, as the following code shows </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "      &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "      &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "      &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "#print (soup.unwrap())\n",
       "for tag in soup.find_all():\n",
       "   tag.unwrap()\n",
       "print (soup)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "The quick, brown fox jumps over a lazy dog.\n",
       "DJs flock by when MTV ax quiz prog.\n",
       "Junk MTV quiz graced by fox whelps.\n",
       "Bawds jog, flick quartz, vex nymphs.\n",
       "</pre>\n",
       "<h1>Beautiful Soup - smooth() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>After calling a bunch of methods that modify the parse tree, you may end up with two or more NavigableString objects next to each other. The smooth() method smooths out this element's children by consolidating consecutive strings. This makes pretty-printed output look more natural following a lot of operations that modified the tree.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "smooth()\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<p>This method has no parameters.</p>\n",
       "<h3>Return Type</h3>\n",
       "<p>This method returns the given tag after smoothing.</p>\n",
       "<h3>Example 1</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html ='''&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    &lt;title&gt;TutorislsPoint/title&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "Some Text\n",
       "    &lt;div&gt;&lt;/div&gt;\n",
       "    &lt;p&gt;&lt;/p&gt;\n",
       "    &lt;div&gt;Some more text&lt;/div&gt;\n",
       "    &lt;b&gt;&lt;/b&gt;\n",
       "    &lt;i&gt;&lt;/i&gt; # COMMENT\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;'''\n",
       "\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "soup.find('body').sm\n",
       "for item in soup.find_all():\n",
       "   if not item.get_text(strip=True):\n",
       "      p = item.parent\n",
       "      item.replace_with('')\n",
       "      p.smooth()\n",
       "\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;title&gt;\n",
       "         TutorislsPoint/title&gt;\n",
       "      &lt;/title&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      Some Text\n",
       "      &lt;div&gt;\n",
       "         Some more text\n",
       "      &lt;/div&gt;\n",
       "      # COMMENT\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"&lt;p&gt;Hello&lt;/p&gt;\", 'html.parser')\n",
       "soup.p.append(\", World\")\n",
       "\n",
       "soup.smooth()\n",
       "print (soup.p.contents)\n",
       "\n",
       "print(soup.p.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "['Hello, World']\n",
       "&lt;p&gt;\n",
       "   Hello, World\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - prettify() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>To get a nicely formatted Unicode string, use Beautiful Soup's prettify() method. It formats the Beautiful Soup parse tree so that there each tag is on its own separate line with indentation. It allows to you to easily visualize the structure of the Beautiful Soup parse tree.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "prettify(encoding, formatter)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>encoding</b>  The eventual encoding of the string. If this is None, a Unicode string will be returned.</p></li>\n",
       "<li><p>A Formatter object, or a string naming one of the standard formatters.</p></li>\n",
       "</ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The prettify() method returns a Unicode string (if encoding==None) or a bytestring (otherwise).</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>Consider the following HTML string.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;p&gt;The quick, &lt;b&gt;brown fox&lt;/b&gt; jumps over a lazy dog.&lt;/p&gt;\n",
       "</pre>\n",
       "<p>Using the prettify() method we can better understand its structure </p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;p&gt;The quick, &lt;b&gt;brown fox&lt;/b&gt; jumps over a lazy dog.&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"lxml\")\n",
       "print (soup.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;\n",
       "         The quick,\n",
       "      &lt;b&gt;\n",
       "         brown fox\n",
       "      &lt;/b&gt;\n",
       "         jumps over a lazy dog.\n",
       "      &lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>You can call prettify() on on any of the Tag objects in the document.</p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "print (soup.b.prettify())\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "&lt;b&gt;\n",
       "   brown fox\n",
       "&lt;/b&gt;\n",
       "</pre>\n",
       "<p>The prettify() method is for understanding the structure of the document. However, it should not be used to reformat it, as it adds whitespace (in the form of newlines), and changes the meaning of an HTML document.</p>\n",
       "<p>He prettify() method can optionally be provided formatter argument to specify the formatting to be used.</p>\n",
       "<p>There are following possible values for the formatter.</p>\n",
       "<p><b>formatter=\"minimal\"</b>  This is the default. Strings will only be processed enough to ensure that Beautiful Soup generates valid HTML/XML.</p>\n",
       "<p><b>formatter=\"html\"</b>  Beautiful Soup will convert Unicode characters to HTML entities whenever possible.</p>\n",
       "<p><b>formatter=\"html5\"</b>  it's similar to formatter=\"html\", but Beautiful Soup will omit the closing slash in HTML void tags like \"br\".</p>\n",
       "<p><b>formatter=None</b>  Beautiful Soup will not modify strings at all on output. This is the fastest option, but it may lead to Beautiful Soup generating invalid HTML/XML.</p>\n",
       "<h3>Example 3</h3>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "french = \"&lt;p&gt;Il a dit &lt;&lt;Sacr bleu!&gt;&gt;&lt;/p&gt;\"\n",
       "soup = BeautifulSoup(french, 'html.parser')\n",
       "print (\"minimal: \")\n",
       "print(soup.prettify(formatter=\"minimal\"))\n",
       "print (\"html: \")\n",
       "print(soup.prettify(formatter=\"html\"))\n",
       "print (\"None: \")\n",
       "print(soup.prettify(formatter=None))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "minimal: \n",
       "&lt;p&gt;\n",
       " Il a dit &lt;\n",
       " &lt;sacr bleu!=\"\"&gt;\n",
       "  &gt;\n",
       " &lt;/sacr&gt;\n",
       "&lt;/p&gt;\n",
       "html: \n",
       "&lt;p&gt;\n",
       " Il a dit &lt;\n",
       " &lt;sacr bleu!=\"\"&gt;\n",
       "  &gt;\n",
       " &lt;/sacr&gt;\n",
       "&lt;/p&gt;\n",
       "None: \n",
       "&lt;p&gt;\n",
       " Il a dit &lt;\n",
       " &lt;sacr bleu!=\"\"&gt;\n",
       "  &gt;\n",
       " &lt;/sacr&gt;\n",
       "&lt;/p&gt;\n",
       "</pre>\n",
       "<h1>Beautiful Soup - encode() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The encode() method in Beautiful Soup renders a bytestring representation of the given PageElement and its contents.</p>\n",
       "<p>The prettify() method, which allows to you to easily visualize the structure of the Beautiful Soup parse tree, has the encoding argument. The encode() method plays the same role as the encoding in prettify() method has.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "encode(encoding, indent_level, formatter, errors)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>encoding</b>  The destination encoding.</p></li>\n",
       "<li><p><b>indent_level</b>  Each line of the rendering will be</p></li>\n",
       "<li><p>indented this many levels. Used internally in recursive calls while pretty-printing.</p></li>\n",
       "<li><p><b>formatter</b>  A Formatter object, or a string naming one of the standard formatters.</p></li>\n",
       "<li><p><b>errors</b>  An error handling strategy.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The encode() method returns a byte string representation of the tag and its contents.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>The encoding parameter is utf-8 by default. Following code shows the encoded byte string representation of the soup object.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"Hello World!\", 'html.parser')\n",
       "print (soup.encode('utf-8'))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "b'Hello \\xe2\\x80\\x9cWorld!\\xe2\\x80\\x9d'\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>The formatter object has the following predefined values </p>\n",
       "<p><b>formatter=\"minimal\"</b>  This is the default. Strings will only be processed enough to ensure that Beautiful Soup generates valid HTML/XML.</p>\n",
       "<p><b>formatter=\"html\"</b>  Beautiful Soup will convert Unicode characters to HTML entities whenever possible.</p>\n",
       "<p><b>formatter=\"html5\"</b>  it's similar to formatter=\"html\", but Beautiful Soup will omit the closing slash in HTML void tags like \"br\".</p>\n",
       "<p><b>formatter=None</b>  Beautiful Soup will not modify strings at all on output. This is the fastest option, but it may lead to Beautiful Soup generating invalid HTML/XML.</p>\n",
       "<p>In the following example, different formatter values are used as argument for encode() method.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "french = \"&lt;p&gt;Il a dit &lt;&lt;Sacr bleu!&gt;&gt;&lt;/p&gt;\"\n",
       "soup = BeautifulSoup(french, 'html.parser')\n",
       "print (\"minimal: \")\n",
       "print(soup.p.encode(formatter=\"minimal\"))\n",
       "print (\"html: \")\n",
       "print(soup.p.encode(formatter=\"html\"))\n",
       "print (\"None: \")\n",
       "print(soup.p.encode(formatter=None))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "minimal: \n",
       "b'&lt;p&gt;Il a dit &lt;&lt;Sacr\\xc3\\xa9 bleu!&gt;&gt;&lt;/p&gt;'\n",
       "html:\n",
       "b'&lt;p&gt;Il a dit &lt;&lt;Sacr bleu!&gt;&gt;&lt;/p&gt;'\n",
       "None:\n",
       "b'&lt;p&gt;Il a dit &lt;&lt;Sacr\\xc3\\xa9 bleu!&gt;&gt;&lt;/p&gt;'\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>The following example uses Latin-1 as the encoding parameter.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "markup = '''\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "      &lt;meta content=\"text/html; charset=ISO-Latin-1\" http-equiv=\"Content-type\" /&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;p&gt;Sacr`e bleu!&lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(markup, 'lxml')\n",
       "print(soup.p.encode(\"latin-1\"))\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "b'&lt;p&gt;Sacr`e bleu!&lt;/p&gt;'\n",
       "</pre>\n",
       "<h1>Beautiful Soup - decode() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The decode() method in Beautiful Soup returns a string or Unicode representation of the parse tree as an HTML or XML document. The method decodes the bytes using the codec registered for encoding. Its function is opposite to that of encode() method. You call encode() to get a bytestring, and decode() to get Unicode. Let us study decode() method with some examples.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "decode(pretty_print, encoding, formatter, errors)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>pretty_print</b>  If this is True, indentation will be used to make the document more readable.</p></li>\n",
       "<li><p><b>encoding</b>  The encoding of the final document. If this is None, the document will be a Unicode string.</p></li>\n",
       "<li><p><b>formatter</b>  A Formatter object, or a string naming one of the standard formatters.</p></li>\n",
       "<li><p><b>errors</b>  The error handling scheme to use for the handling of decoding errors. Values are  'strict', 'ignore' and 'replace'.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The decode() method returns a Unicode String.</p>\n",
       "<h2>Example</h2>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(\"Hello World!\", 'html.parser')\n",
       "enc = soup.encode('utf-8')\n",
       "print (enc)\n",
       "dec = enc.decode()\n",
       "print (dec)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "b'Hello \\xe2\\x80\\x9cWorld!\\xe2\\x80\\x9d'\n",
       "Hello \"World!\"\n",
       "</pre>\n",
       "<h1>Beautiful Soup - get_text() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The get_text() method returns only the human-readable text from the entire HTML document or a given tag. All the child strings are concatenated by the given separator which is a null string by default.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "get_text(separator, strip)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>separator</b>  The child strings will be concatenated using this parameter. By default it is \"\".\n",
       "<li><p><b>strip</b>  The strings will be stripped before concatenation.</p></li>\n",
       "</p></li></ul>\n",
       "<h3>Return Type</h3>\n",
       "<p>The get_Text() method returns a string.</p>\n",
       "<h3>Example 1</h3>\n",
       "<p>In the example below, the get_text() method removes all the HTML tags.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "&lt;html&gt;\n",
       "&lt;body&gt;\n",
       "   &lt;p&gt; The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;p&gt; DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "   &lt;p&gt; Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "   &lt;p&gt; Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "text = soup.get_text()\n",
       "print(text)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "The quick, brown fox jumps over a lazy dog.\n",
       "DJs flock by when MTV ax quiz prog.\n",
       "Junk MTV quiz graced by fox whelps.\n",
       "Bawds jog, flick quartz, vex nymphs.\n",
       "</pre>\n",
       "<h3>Example 2</h3>\n",
       "<p>In the following example, we specify the separator argument of get_text() method as '#'.</p>\n",
       "<pre class=\"demo-code notranslate language-python\" data-lang=\"python3\">\n",
       "html = '''\n",
       "   &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "   &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "   &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "text = soup.get_text(separator='#')\n",
       "print(text)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "#The quick, brown fox jumps over a lazy dog.#\n",
       "#DJs flock by when MTV ax quiz prog.#\n",
       "#Junk MTV quiz graced by fox whelps.#\n",
       "#Bawds jog, flick quartz, vex nymphs.#\n",
       "</pre>\n",
       "<h3>Example 3</h3>\n",
       "<p>Let us check the effect of strip parameter when it is set to True. By default it is False.</p>\n",
       "<pre class=\"demo-code notranslate language-html\" data-lang=\"html\">\n",
       "html = '''\n",
       "   &lt;p&gt;The quick, brown fox jumps over a lazy dog.&lt;/p&gt;\n",
       "   &lt;p&gt;DJs flock by when MTV ax quiz prog.&lt;/p&gt;\n",
       "   &lt;p&gt;Junk MTV quiz graced by fox whelps.&lt;/p&gt;\n",
       "   &lt;p&gt;Bawds jog, flick quartz, vex nymphs.&lt;/p&gt;\n",
       "'''\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "soup = BeautifulSoup(html, \"html.parser\")\n",
       "text = soup.get_text(strip=True)\n",
       "print(text)\n",
       "</pre>\n",
       "<h3>Output</h3>\n",
       "<pre class=\"result notranslate\">\n",
       "The quick, brown fox jumps over a lazy dog.DJs flock by when MTV ax quiz prog.Junk MTV quiz graced by fox whelps.Bawds jog, flick quartz, vex nymphs.\n",
       "</pre>\n",
       "<h1>Beautiful Soup - diagnose() Method</h1>\n",
       "<h3>Method Description</h3>\n",
       "<p>The diagnose() method in Beautiful Soup is a diagnostic suite for isolating common problems. If you're facing difficulty in understanding what Beautiful Soup is doing to a document, pass the document as argument to the diagnose() function. A report showing you how different parsers handle the document, and tell you if you're missing a parser.</p>\n",
       "<h3>Syntax</h3>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "diagnose(data)\n",
       "</pre>\n",
       "<h3>Parameters</h3>\n",
       "<ul class=\"list\">\n",
       "<li><p><b>data</b>  the document string.</p></li>\n",
       "</ul>\n",
       "<h3>Return Value</h3>\n",
       "<p>The diagnose() method prints the result of parsing the given document according all the available parsers.</p>\n",
       "<h2>Example</h2>\n",
       "<p>Let us take this simple document for our exercise </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "&lt;h1&gt;Hello World\n",
       "&lt;b&gt;Welcome&lt;/b&gt;\n",
       "&lt;P&gt;&lt;b&gt;Beautiful Soup&lt;/a&gt; &lt;i&gt;Tutorial&lt;/i&gt;&lt;p&gt;\n",
       "</pre>\n",
       "<p>The following code runs the diagnostics on the above HTML script </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "markup = '''\n",
       "&lt;h1&gt;Hello World\n",
       "&lt;b&gt;Welcome&lt;/b&gt;\n",
       "&lt;P&gt;&lt;b&gt;Beautiful Soup&lt;/a&gt; &lt;i&gt;Tutorial&lt;/i&gt;&lt;p&gt;\n",
       "'''\n",
       "\n",
       "from bs4.diagnose import diagnose\n",
       "\n",
       "diagnose(markup)\n",
       "</pre>\n",
       "<p>The diagonose() output starts with a message showing what all parsers are available </p>\n",
       "<pre class=\"just-code notranslate language-python\" data-lang=\"python3\">\n",
       "Diagnostic running on Beautiful Soup 4.12.2\n",
       "Python version 3.11.2 (tags/v3.11.2:878ead1, Feb  7 2023, 16:38:35) [MSC v.1934 64 bit (AMD64)]\n",
       "Found lxml version 4.9.2.0\n",
       "Found html5lib version 1.1\n",
       "</pre>\n",
       "<p>If the document to be diagnosed is a perfect HTML document, the result for all parsers is just about similar. However, in our example, there are many errors.</p>\n",
       "<p>To begin the built-in html.parser is take up. The report will be as follows </p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "Trying to parse your markup with html.parser\n",
       "Here's what html.parser did with the markup:\n",
       "   &lt;h1&gt;\n",
       "      Hello World\n",
       "   &lt;b&gt;\n",
       "      Welcome\n",
       "   &lt;/b&gt;\n",
       "   &lt;p&gt;\n",
       "      &lt;b&gt;\n",
       "         Beautiful Soup\n",
       "         &lt;i&gt;\n",
       "            Tutorial\n",
       "         &lt;/i&gt;\n",
       "         &lt;p&gt;\n",
       "         &lt;/p&gt;\n",
       "      &lt;/b&gt;\n",
       "   &lt;/p&gt;\n",
       "&lt;/h1&gt;\n",
       "</pre>\n",
       "<p>You can see that Python's built-in parser doesn't insert the &lt;html&gt; and &lt;body&gt; tags. The unclosed &lt;h1&gt; tag is provided with matching &lt;h1&gt; at the end.</p>\n",
       "<p>Both the html5lib and lxml parsers complete the document by wrapping it in &lt;html&gt;, &lt;head&gt; and &lt;body&gt; tags.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "Trying to parse your markup with html5lib\n",
       "Here's what html5lib did with the markup:\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h1&gt;\n",
       "         Hello World\n",
       "         &lt;b&gt;\n",
       "            Welcome\n",
       "         &lt;/b&gt;\n",
       "         &lt;p&gt;\n",
       "            &lt;b&gt;\n",
       "               Beautiful Soup\n",
       "               &lt;i&gt;\n",
       "                  Tutorial\n",
       "               &lt;/i&gt;\n",
       "            &lt;/b&gt;\n",
       "         &lt;/p&gt;\n",
       "         &lt;p&gt;\n",
       "            &lt;b&gt;\n",
       "            &lt;/b&gt;\n",
       "         &lt;/p&gt;\n",
       "      &lt;/h1&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>With lxml parser, note where the closing &lt;/h1&gt; is inserted. Also the incomplete &lt;b&gt; tag is rectified, and the dangling &lt;/a&gt; is removed.</p>\n",
       "<pre class=\"just-code notranslate language-html\" data-lang=\"html\">\n",
       "Trying to parse your markup with lxml\n",
       "Here's what lxml did with the markup:\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;h1&gt;\n",
       "         Hello World\n",
       "         &lt;b&gt;\n",
       "            Welcome\n",
       "         &lt;/b&gt;\n",
       "      &lt;/h1&gt;\n",
       "      &lt;p&gt;\n",
       "         &lt;b&gt;\n",
       "            Beautiful Soup\n",
       "            &lt;i&gt;\n",
       "               Tutorial\n",
       "            &lt;/i&gt;\n",
       "         &lt;/b&gt;\n",
       "      &lt;/p&gt;\n",
       "      &lt;p&gt;\n",
       "      &lt;/p&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The diagnose() method parses the document as XML document also, which probably is superfluous in our case.</p>\n",
       "<pre class=\"just-code notranslate language-xml\" data-lang=\"xml\">\n",
       "Trying to parse your markup with lxml-xml\n",
       "Here's what lxml-xml did with the markup:\n",
       "&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n",
       "&lt;h1&gt;\n",
       "   Hello World\n",
       "   &lt;b&gt;\n",
       "      Welcome\n",
       "   &lt;/b&gt;\n",
       "   &lt;P&gt;\n",
       "      &lt;b&gt;\n",
       "         Beautiful Soup\n",
       "      &lt;/b&gt;\n",
       "      &lt;i&gt;\n",
       "         Tutorial\n",
       "      &lt;/i&gt;\n",
       "   &lt;p/&gt;\n",
       "   &lt;/P&gt;\n",
       "&lt;/h1&gt;\n",
       "</pre>\n",
       "<p>Let us give the diagnose() method a XML document instead of HTML document.</p>\n",
       "<pre class=\"just-code notranslate language-xml\" data-lang=\"xml\">\n",
       "&lt;?xml version=\"1.0\" ?&gt;\n",
       "   &lt;books&gt;\n",
       "      &lt;book&gt;\n",
       "         &lt;title&gt;Python&lt;/title&gt;\n",
       "         &lt;author&gt;TutorialsPoint&lt;/author&gt;\n",
       "         &lt;price&gt;400&lt;/price&gt;\n",
       "      &lt;/book&gt;\n",
       "   &lt;/books&gt;\n",
       "</pre>\n",
       "<p>Now if we run the diagnostics, even if it's a XML, the html parsers are applied.</p>\n",
       "<pre class=\"result notranslate\">\n",
       "Trying to parse your markup with html.parser\n",
       "\n",
       "Warning (from warnings module):\n",
       "  File \"C:\\Users\\mlath\\OneDrive\\Documents\\Feb23 onwards\\BeautifulSoup\\Lib\\site-packages\\bs4\\builder\\__init__.py\", line 545\n",
       "    warnings.warn(\n",
       "XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
       "</pre>\n",
       "<p>With html.parser, a warning message is displayed. With html5lib, the fist line which contains XML version information is commented and rest of the document is parsed as if it is a HTML document.</p>\n",
       "<pre class=\"just-code notranslate language-xml\" data-lang=\"xml\">\n",
       "Trying to parse your markup with html5lib\n",
       "Here's what html5lib did with the markup:\n",
       "&lt;!--?xml version=\"1.0\" ?--&gt;\n",
       "&lt;html&gt;\n",
       "   &lt;head&gt;\n",
       "   &lt;/head&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;books&gt;\n",
       "         &lt;book&gt;\n",
       "            &lt;title&gt;\n",
       "               Python\n",
       "            &lt;/title&gt;\n",
       "            &lt;author&gt;\n",
       "               TutorialsPoint\n",
       "            &lt;/author&gt;\n",
       "            &lt;price&gt;\n",
       "               400\n",
       "            &lt;/price&gt;\n",
       "         &lt;/book&gt;\n",
       "      &lt;/books&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The lxml html parser doesn't insert the comment, but parses it as HTML.</p>\n",
       "<pre class=\"just-code notranslate language-xml\" data-lang=\"xml\">\n",
       "Trying to parse your markup with lxml\n",
       "Here's what lxml did with the markup:\n",
       "&lt;?xml version=\"1.0\" ?&gt;\n",
       "&lt;html&gt;\n",
       "   &lt;body&gt;\n",
       "      &lt;books&gt;\n",
       "         &lt;book&gt;\n",
       "            &lt;title&gt;\n",
       "               Python\n",
       "            &lt;/title&gt;\n",
       "            &lt;author&gt;\n",
       "               TutorialsPoint\n",
       "            &lt;/author&gt;\n",
       "            &lt;price&gt;\n",
       "               400\n",
       "            &lt;/price&gt;\n",
       "         &lt;/book&gt;\n",
       "      &lt;/books&gt;\n",
       "   &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "</pre>\n",
       "<p>The lxml-xml parser parses the document as XML.</p>\n",
       "<pre class=\"just-code notranslate language-xml\" data-lang=\"xml\">\n",
       "Trying to parse your markup with lxml-xml\n",
       "Here's what lxml-xml did with the markup:\n",
       "&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n",
       "&lt;?xml version=\"1.0\" ?&gt;\n",
       "   &lt;books&gt;\n",
       "      &lt;book&gt;\n",
       "         &lt;title&gt;\n",
       "            Python\n",
       "         &lt;/title&gt;\n",
       "         &lt;author&gt;\n",
       "            TutorialsPoint\n",
       "         &lt;/author&gt;\n",
       "         &lt;price&gt;\n",
       "            400\n",
       "         &lt;/price&gt;\n",
       "      &lt;/book&gt;\n",
       "   &lt;/books&gt;\n",
       "</pre>\n",
       "<p>The diagnostics report may prove to be useful in finding errors in HTML/XML documents.</p>\n",
       "<div class=\"library-page-bottom-nav\">\n",
       "<div class=\"button button--blue\" id=\"print-page\">\n",
       "<svg fill=\"white\" height=\"1em\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M112 160V64c0-8.8 7.2-16 16-16H357.5c4.2 0 8.3 1.7 11.3 4.7l26.5 26.5c3 3 4.7 7.1 4.7 11.3V160h48V90.5c0-17-6.7-33.3-18.7-45.3L402.7 18.7C390.7 6.7 374.5 0 357.5 0H128C92.7 0 64 28.7 64 64v96h48zm16 208H384v96H128V368zm-16-48c-17.7 0-32 14.3-32 32H48V256c0-8.8 7.2-16 16-16H448c8.8 0 16 7.2 16 16v96H432c0-17.7-14.3-32-32-32H112zm320 80h48c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64V368c0 17.7 14.3 32 32 32H80v80c0 17.7 14.3 32 32 32H400c17.7 0 32-14.3 32-32V400z\"></path></svg>\n",
       "      Print Page\n",
       "   </div>\n",
       "<div class=\"flex-group\">\n",
       "<a href=\"/beautiful_soup/beautiful_soup_diagnose_method.htm\">\n",
       "<div class=\"button button--neutral\">\n",
       "<svg fill=\"none\" height=\"16\" viewbox=\"0 0 10 16\" width=\"10\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M1.03117 8.48836C0.64065 8.09783 0.64065 7.46467 1.03117 7.07414L7.39514 0.710183C7.78566 0.319658 8.41883 0.319658 8.80935 0.710183C9.19987 1.10071 9.19987 1.73387 8.80935 2.1244L3.15249 7.78125L8.80935 13.4381C9.19987 13.8286 9.19987 14.4618 8.80935 14.8523C8.41882 15.2428 7.78566 15.2428 7.39513 14.8523L1.03117 8.48836ZM3.12109 8.78125L1.73828 8.78125L1.73828 6.78125L3.12109 6.78125L3.12109 8.78125Z\" fill=\"black\"></path></svg>\n",
       "      Previous\n",
       "   </div>\n",
       "</a>\n",
       "<a href=\"/beautiful_soup/beautiful_soup_useful_resources.htm\">\n",
       "<div class=\"button\">Next\n",
       "   <svg fill=\"none\" height=\"16\" viewbox=\"0 0 10 16\" width=\"10\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M8.87117 8.48836C9.26169 8.09783 9.26169 7.46467 8.87117 7.07414L2.50721 0.710183C2.11668 0.319658 1.48352 0.319658 1.09299 0.710183C0.70247 1.10071 0.70247 1.73387 1.09299 2.1244L6.74985 7.78125L1.093 13.4381C0.702471 13.8286 0.702471 14.4618 1.093 14.8523C1.48352 15.2428 2.11668 15.2428 2.50721 14.8523L8.87117 8.48836ZM6.78125 8.78125L8.16406 8.78125L8.16406 6.78125L6.78125 6.78125L6.78125 8.78125Z\" fill=\"white\"></path></svg>\n",
       "</div>\n",
       "</a>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"bottom-library-ads mt\" style=\"margin:5px;\">\n",
       "<div class=\"google-bottom-ads\" id=\"google-bottom-ads\" style=\"height:450px;\">\n",
       "<div>Advertisements</div>\n",
       "<div>\n",
       "<div id=\"ezoic-pub-ad-placeholder-131\"></div>\n",
       "<div id=\"ezoic-pub-ad-placeholder-135\"></div>\n",
       "<script>\n",
       "               ezstandalone.cmd.push(function() {\n",
       "                  var width = window.innerWidth;\n",
       "                  if( width <= 768 ){\n",
       "                     ezstandalone.showAds(135);\n",
       "                     document.getElementById(\"ezoic-pub-ad-placeholder-131\").remove();\n",
       "                     document.getElementById(\"google-right-ads\").remove();\n",
       "                  }else{\n",
       "                     ezstandalone.showAds(131);\n",
       "                     document.getElementById(\"ezoic-pub-ad-placeholder-135\").remove();\n",
       "                  }\n",
       "               });\n",
       "            </script>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div>\n",
       "<div class=\"data-sticky\" id=\"google-right-ads\">\n",
       "<div class=\"google-right-ad\" style=\"margin: 0px auto !important;margin-top:5px;min-height:280px!important\">\n",
       "<div id=\"ezoic-pub-ad-placeholder-127\"></div>\n",
       "<script>\n",
       "            ezstandalone.cmd.push(function() {\n",
       "               ezstandalone.showAds(127);\n",
       "            });\n",
       "         </script>\n",
       "</div>\n",
       "<div class=\"google-right-ad\" style=\"margin-top:16px;min-height:280px!important\">\n",
       "<div id=\"ezoic-pub-ad-placeholder-128\"></div>\n",
       "<script>\n",
       "            ezstandalone.cmd.push(function() {\n",
       "               ezstandalone.showAds(128);\n",
       "            });\n",
       "         </script>\n",
       "</div>\n",
       "<div class=\"google-right-ad\" style=\"margin-top:16px;margin-bottom:15px;min-height:600px!important\">\n",
       "<div id=\"ezoic-pub-ad-placeholder-129\"></div>\n",
       "<script>\n",
       "         ezstandalone.cmd.push(function() {\n",
       "              ezstandalone.showAds(129);\n",
       "         });\n",
       "         </script>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</main>\n",
       "<footer class=\"footer bg-neutral-800\">\n",
       "<div class=\"container\">\n",
       "<div>\n",
       "<h5>TOP TUTORIALS</h5>\n",
       "<ul>\n",
       "<li><a href=\"/python/index.htm\" title=\"Python Tutorial\">Python Tutorial</a></li>\n",
       "<li><a href=\"/java/index.htm\" title=\"Java Tutorial\">Java Tutorial</a></li>\n",
       "<li><a href=\"/cplusplus/index.htm\" title=\"C++ Tutorial\">C++ Tutorial</a></li>\n",
       "<li><a href=\"/cprogramming/index.htm\" title=\"C Programming Tutorial\">C Programming Tutorial</a></li>\n",
       "<li><a href=\"/csharp/index.htm\" title=\"C# Tutorial\">C# Tutorial</a></li>\n",
       "<li><a href=\"/php/index.htm\" title=\"PHP Tutorial\">PHP Tutorial</a></li>\n",
       "<li><a href=\"/r/index.htm\" title=\"R Tutorial\">R Tutorial</a></li>\n",
       "<li><a href=\"/html/index.htm\" title=\"HTML Tutorial\">HTML Tutorial</a></li>\n",
       "<li><a href=\"/css/index.htm\" title=\"CSS Tutorial\">CSS Tutorial</a></li>\n",
       "<li><a href=\"/javascript/index.htm\" title=\"JavaScript Tutorial\">JavaScript Tutorial</a></li>\n",
       "<li><a href=\"/sql/index.htm\" title=\"SQL Tutorial\">SQL Tutorial</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div>\n",
       "<h5>TRENDING TECHNOLOGIES</h5>\n",
       "<ul>\n",
       "<li><a href=\"/cloud_computing/index.htm\" title=\"Cloud Computing Tutorial\">Cloud Computing Tutorial</a></li>\n",
       "<li><a href=\"/amazon_web_services/index.htm\" title=\"Amazon Web Services Tutorial\">Amazon Web Services Tutorial</a></li>\n",
       "<li><a href=\"/microsoft_azure/index.htm\" title=\"Microsoft Azure Tutorial\">Microsoft Azure Tutorial</a></li>\n",
       "<li><a href=\"/git/index.htm\" title=\"Git Tutorial\">Git Tutorial</a></li>\n",
       "<li> <a href=\"/ethical_hacking/index.htm\" title=\"Ethical Hacking Tutorial\">Ethical Hacking Tutorial</a></li>\n",
       "<li><a href=\"/docker/index.htm\" title=\"Docker Tutorial\">Docker Tutorial</a></li>\n",
       "<li><a href=\"/kubernetes/index.htm\" title=\"Kubernetes Tutorial\">Kubernetes Tutorial</a></li>\n",
       "<li><a href=\"/data_structures_algorithms/index.htm\" title=\"DSA Tutorial\">DSA Tutorial</a></li>\n",
       "<li><a href=\"/spring_boot/index.htm\" title=\"Spring Boot Tutorial\">Spring Boot Tutorial</a></li>\n",
       "<li><a href=\"/sdlc/index.htm\" title=\"SDLC Tutorial\">SDLC Tutorial</a></li>\n",
       "<li><a href=\"/unix/index.htm\" title=\"Unix Tutorial\">Unix Tutorial</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div>\n",
       "<h5>CERTIFICATIONS</h5>\n",
       "<ul>\n",
       "<li><a href=\"/certification/business-analytics-certification-2023/index.asp\" title=\"Business Analytics Certification\">Business Analytics Certification</a></li>\n",
       "<li><a href=\"/certification/java-prime-pack/index.asp\" title=\"Java &amp; Spring Boot Advanced Certification\">Java &amp; Spring Boot Advanced Certification</a></li>\n",
       "<li><a href=\"/certification/data-science-advanced-certification/index.asp\" title=\"Data Science Advanced Certification\">Data Science Advanced Certification</a></li>\n",
       "<li><a href=\"/certification/cloud-computing-and-devops-advanced-certification/index.asp\" title=\"Cloud Computing And DevOps\">Cloud Computing And DevOps</a></li>\n",
       "<li><a href=\"/certification/advanced-certification-in-business-analytics/index.asp\" title=\"Advanced Certification In Business Analytics\">Advanced Certification In Business Analytics</a></li>\n",
       "<li><a href=\"/certification/artificial-intelligence-and-machine-learning-certification/index.asp\" title=\"Artificial Intelligence And Machine Learning\">Artificial Intelligence And Machine Learning</a></li>\n",
       "<li><a href=\"/certification/devops-certification/index.asp\" title=\"DevOps Certification\">DevOps Certification</a></li>\n",
       "<li><a href=\"/certification/game-development-prime-pack/index.asp\" title=\"Game Development Certification\">Game Development Certification</a></li>\n",
       "<li><a href=\"/certification/frontend-developer-certification/index.asp\" title=\"Front-End Developer Certification\">Front-End Developer Certification</a></li>\n",
       "<li><a href=\"/certification/aws-prime-pack/index.asp\" title=\"AWS Certification Training\">AWS Certification Training</a></li>\n",
       "<li><a href=\"/certification/complete-python-prime-pack/index.asp\" title=\"Python Programming Certification\">Python Programming Certification</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div>\n",
       "<h5>COMPILERS &amp; EDITORS</h5>\n",
       "<ul>\n",
       "<li><a href=\"/online_java_compiler.php\" title=\"Online Java Compiler\">Online Java Compiler</a></li>\n",
       "<li><a href=\"/online_python_compiler.php\" title=\"Online Python Compiler\">Online Python Compiler</a></li>\n",
       "<li><a href=\"/execute_golang_online.php\" title=\"Online Go Compiler\">Online Go Compiler</a></li>\n",
       "<li><a href=\"/compile_c_online.php\" title=\"Online C Compiler\">Online C Compiler</a></li>\n",
       "<li><a href=\"/compile_cpp_online.php\" title=\"Online C++ Compiler\">Online C++ Compiler</a></li>\n",
       "<li><a href=\"/online_csharp_compiler.php\" title=\"Online C# Compiler\">Online C# Compiler</a></li>\n",
       "<li><a href=\"/execute_php_online.php\" title=\"Online PHP Compiler\">Online PHP Compiler</a></li>\n",
       "<li><a href=\"/execute_matlab_online.php\" title=\"Online MATLAB Compiler\">Online MATLAB Compiler</a></li>\n",
       "<li><a href=\"/execute_bash_online.php\" title=\"Online Bash Compiler\">Online Bash Compiler</a></li>\n",
       "<li><a href=\"/execute_sql_online.php\" title=\"Online SQL Compiler\">Online SQL Compiler</a></li>\n",
       "<li><a href=\"/online_html_editor.php\" title=\"Online Html Editor\">Online Html Editor</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</div>\n",
       "<ul class=\"footer__list container\">\n",
       "<li><a href=\"/about/index.htm\" title=\"ABOUT US\">ABOUT US</a> | </li>\n",
       "<li><a href=\"/about/about_team.htm\" title=\"OUR TEAM\">OUR TEAM</a> | </li>\n",
       "<li><a href=\"/about/about_careers.htm\" title=\"CAREERS\">CAREERS</a> | </li>\n",
       "<li><a href=\"/job_search.php\" title=\"JOBS\">JOBS</a> | </li>\n",
       "<li><a href=\"/about/contact_us.htm\" title=\"CONTACT US\">CONTACT US</a> | </li>\n",
       "<li><a href=\"/about/about_terms_of_use.htm\" title=\"TERMS OF USE\">TERMS OF USE</a> | </li>\n",
       "<li><a href=\"/about/about_privacy.htm\" title=\"PRIVACY POLICY\">PRIVACY POLICY</a> | </li>\n",
       "<li><a href=\"/about/return_refund_policy.htm\" title=\"REFUND POLICY\">REFUND POLICY</a> | </li>\n",
       "<li><a href=\"/about/about_cookies.htm\" title=\"COOKIES POLICY\">COOKIES POLICY</a> | </li>\n",
       "<li><a href=\"/about/faq.htm\" title=\"FAQ'S\">FAQ'S</a></li>\n",
       "</ul>\n",
       "<div class=\"footer__socials container\">\n",
       "<img alt=\"tutorials point logo\" class=\"footer__logo\" src=\"https://www.tutorialspoint.com/static/images/logo-footer.svg\"/>\n",
       "<div>\n",
       "<a href=\"https://www.facebook.com/tutorialspointindia\" rel=\"nofollow\" target=\"_blank\" title=\"Follow us on Facebook\"><i class=\"fab fa-2x fa-facebook\"></i></a>\n",
       "<a href=\"https://twitter.com/tutorialspoint\" rel=\"nofollow\" target=\"_blank\" title=\"Follow us on Twitter\"><i class=\"fab fa-2x fa-x-twitter\"></i></a>\n",
       "<a href=\"https://www.youtube.com/channel/UCVLbzhxVTiTLiVKeGV7WEBg\" rel=\"nofollow\" target=\"_blank\" title=\"Follow us on Youtube\"><i class=\"fab fa-2x fa-youtube\"></i></a>\n",
       "<a href=\"https://www.linkedin.com/company/tutorialspoint/\" rel=\"nofollow\" target=\"_blank\" title=\"Follow us on LinkedIn\"><i class=\"fab fa-2x fa-linkedin\"></i></a>\n",
       "<a href=\"https://www.instagram.com/tutorialspoint_/\" rel=\"nofollow\" target=\"_blank\" title=\"Follow us on Instagram\"><i class=\"fab fa-2x fa-instagram\"></i></a>\n",
       "</div>\n",
       "<div class=\"flex-group\">\n",
       "<button class=\"button-reset\"><a href=\"https://play.google.com/store/apps/details?id=com.tutorialspoint.onlineviewer\" rel=\"nofollow\" target=\"_blank\" title=\"Download Android App\"><img alt=\"Download Android App\" src=\"https://www.tutorialspoint.com/static/images/googleplay.svg\"/></a></button>\n",
       "<button class=\"button-reset\"><a href=\"https://itunes.apple.com/us/app/tutorials-point/id914891263?ls=1&amp;mt=8\" rel=\"nofollow\" target=\"_blank\" title=\"Download IOS App\"><img alt=\"Download IOS App\" src=\"https://www.tutorialspoint.com/static/images/appstore.svg\"/></a></button>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"footer__legal-wrapper\">\n",
       "<div class=\"footer__legal ff-nunito\">\n",
       "<p>\n",
       "<p class=\"\">Tutorials Point is a leading Ed Tech company striving to provide the best learning material on technical and non-technical subjects.</p>\n",
       "</p>\n",
       "<p class=\"footer__copyright\"> Copyright 2024. All Rights Reserved.</p>\n",
       "</div>\n",
       "</div>\n",
       "</footer>\n",
       "<script src=\"/static/js/lib-script.js?v12.39\"></script>\n",
       "<script async=\"\" defer=\"\" src=\"https://accounts.google.com/gsi/client\"></script>\n",
       "<script>\n",
       "function addParagraphs(ind) {\n",
       "   let techLinks =[[\"Python\",\"JavaScript\",\"Spring Boot\",\"Java\",\"Linux/Unix\",\"C#\",\"Data Science\",\"MySQL\",\"Artificial Intelligence\",\"SQL\"],\n",
       "    [\"https://www.tutorialspoint.com/certification/complete-python-prime-pack/index.asp?utm_source=tutorialspoint&utm_medium=python_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/javascript-prime-pack/index.asp?utm_source=tutorialspoint&utm_medium=javascript_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/ultimate-guide-to-java-and-spring-boot-for-2022/index.asp?utm_source=tutorialspoint&utm_medium=java_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/ultimate-guide-to-java-and-spring-boot-for-2022/index.asp?utm_source=tutorialspoint&utm_medium=spring_boot_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/linux-system-administrator-certification/index.asp?utm_source=tutorialspoint&utm_medium=unix_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/chash-and-net-prime-pack/index.asp?utm_source=tutorialspoint&utm_medium=csharp_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/data-science-prime-pack/index.asp?utm_source=tutorialspoint&utm_medium=data_science_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/mysql-technologies-pack/index.asp?utm_source=tutorialspoint&utm_medium=mysql_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/artificial-intelligence-and-machine-learning-certification/index.asp?utm_source=tutorialspoint&utm_medium=artificial_intelligence_tutorial_3p&utm_campaign=internal\",\n",
       "   \"https://www.tutorialspoint.com/certification/mysql-technologies-pack/index.asp?utm_source=tutorialspoint&utm_medium=sql_tutorial_3p&utm_campaign=internal\"]]\n",
       "   var p2 = '';\n",
       "   if(ind>=0){\n",
       "      p2 = p2 + '<a style=\"text-decoration:none;\" href=\"' + techLinks[1][ind] +'\" target=\"_blank\" ><p class=\"prmt_ad\">Learn <strong>'+ techLinks[0][ind] + '</strong> in-depth with real-world projects through our <strong>' + techLinks[0][ind] + ' certification course</strong>. Enroll and become a certified expert to boost your career.</p></a>';\n",
       "   }\n",
       "   else{\n",
       "      p2 = p2 + '<a href=\"https://www.tutorialspoint.com/latest/courses?utm_source=tutorialspoint&utm_medium=tutorials_3p&utm_campaign=internal\" style=\"text-decoration:none;\" target=\"_blank\"><p class=\"prmt_ad\">Explore our <strong>latest online courses</strong> and learn new skills at your own pace. Enroll and become a certified expert to boost your career.</p></a>';\n",
       "   }\n",
       "   $(p2).insertBefore($('.tutorial-content h2').eq(2));\n",
       "}\n",
       "$(document).ready(function() {\n",
       "   var url= window.location.href.toLowerCase();\n",
       "   if(url.indexOf('python') > -1){\n",
       "      addParagraphs(0);\n",
       "   }\n",
       "   else if(url.indexOf('javascript') > -1){\n",
       "      addParagraphs(1);\n",
       "   }\n",
       "   else if(url.indexOf('spring_boot') > -1){\n",
       "    addParagraphs(2);\n",
       "   }\n",
       "   else if(url.indexOf('java') > -1){\n",
       "      addParagraphs(3);\n",
       "   }\n",
       "   else if((url.indexOf('unix') > -1)||(url.indexOf('linux') > -1)){\n",
       "      addParagraphs(4);\n",
       "   }\n",
       "   else if((url.indexOf('csharp') > -1)||(url.indexOf('chash') > -1)){\n",
       "      addParagraphs(5);\n",
       "   }\n",
       "   else if(url.indexOf('data_science') > -1){\n",
       "      addParagraphs(6);\n",
       "   }\n",
       "   else if(url.indexOf('mysql') > -1){\n",
       "      addParagraphs(7);\n",
       "   }\n",
       "   else if((url.indexOf('artificial_intelligence') > -1)||(url.indexOf('artificial-intelligence') > -1)){\n",
       "      addParagraphs(8);\n",
       "   }\n",
       "   else if(url.indexOf('sql') > -1){\n",
       "      addParagraphs(9);\n",
       "   }\n",
       "   else{\n",
       "      addParagraphs(-1);\n",
       "   }\n",
       "});\n",
       "</script>\n",
       "<script>\n",
       "if(getCookie('user_id') == '' || getCookie('user_id') == null){\n",
       "   window.onload = function() {\n",
       "\tinitializeGoogleOneTap();\n",
       "   };\n",
       "}\n",
       "</script>\n",
       "<script src=\"https://www.tutorialspoint.com/fontawesome/js/all.min.js?v2.9\"></script>\n",
       "<script data-cfasync=\"false\" src=\"https://the.gatekeeperconsent.com/cmp.min.js\"></script>\n",
       "<script async=\"\" src=\"/static/js/ezoic-ad-inserter.js?v4.2\"></script>\n",
       "<script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=G-EX9ZP4VY84\"></script>\n",
       "<script>\n",
       "     window.dataLayer = window.dataLayer || [];\n",
       "     function gtag(){dataLayer.push(arguments);}\n",
       "     gtag('js', new Date());\n",
       "     gtag('config', 'G-EX9ZP4VY84');\n",
       "</script>\n",
       "<!-- New Facebook Pixel Code -->\n",
       "<script>\n",
       "   !function(f,b,e,v,n,t,s)\n",
       "   {if(f.fbq)return;n=f.fbq=function(){n.callMethod?\n",
       "   n.callMethod.apply(n,arguments):n.queue.push(arguments)};\n",
       "   if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';\n",
       "   n.queue=[];t=b.createElement(e);t.async=!0;\n",
       "   t.src=v;s=b.getElementsByTagName(e)[0];\n",
       "   s.parentNode.insertBefore(t,s)}(window,document,'script',\n",
       "   'https://connect.facebook.net/en_US/fbevents.js');\n",
       "   fbq('init', '854536859149047');\n",
       "   fbq('track', 'PageView');\n",
       "</script>\n",
       "<!-- End facebook Pixel Code -->\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.title.string if soup.title else 'No Title'\n",
    "content = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beautiful Soup - Quick Guide'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\n\\nBeautiful Soup - Quick Guide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Home\\n\\n\\n Library\\n\\n\\nCoding Ground\\n\\n\\n Jobs\\n\\n\\nWhiteboard\\n\\n\\nTools\\n\\n\\nArticles\\n\\n\\nWrite & Earn\\n\\n\\n Shorts\\n\\n\\n Courses\\n\\n\\n Certifications\\n\\n\\n\\n\\n Menu \\n Categories \\n\\n Login\\n\\n\\nSwitch theme\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCategory\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAI, ML, and Data Science\\nProgramming Languages\\nWeb Development Languages\\nDevOps\\nDatabases\\nComputer Science Subjects\\nPython Technologies\\nSoftware Testing\\nCyber Security\\n All Categories \\n\\n\\n\\n\\n\\n\\n Back\\n      \\n\\nArtificial Intelligence\\nMachine Learning\\nML With Python\\nData Science\\nStatistics\\n\\n\\nNLP\\nNeural Networks\\nTensorFlow\\nPyTorch\\nMatplotlib\\n\\n\\nNumPy\\nPandas\\nSciPy\\nBig Data Analytics\\nSee all\\n\\n\\n\\n\\n\\n Back\\n      \\n\\nPython\\nJava\\nC++\\nC\\nPHP\\nGo\\n\\n\\nKotlin\\nR\\nASP.Net\\nC#.Net\\nVB.Net\\nScala\\n\\n\\nSwift\\nPerl\\nRuby\\nRust\\nLua\\nSee all\\n\\n\\n\\n\\n\\n Back\\n      \\n\\nHTML\\nCSS\\nJavaScript\\njQuery\\nReactJs\\nNodeJs\\n\\n\\nWordpress\\nAngularJs\\nPHP\\nDjango\\nJSON\\nCodeigniter\\n\\n\\nTypeScript\\nAjax\\nBootstrap\\nSass\\nAppML\\nSee all\\n\\n\\n\\n\\n\\n Back\\n      \\n\\nGIT\\nAWS\\nDocker\\nKubernetes\\nAzure\\nGitlab\\n\\n\\nJira\\nGerrit\\nAnsible\\nBugzilla\\nChef\\nSaltStack\\n\\n\\nOpenShift  \\nPuppet\\nUNIX\\nLinux Admin\\nUbuntu\\nSee all\\n\\n\\n\\n\\n\\n Back\\n      \\n\\nDBMS\\nSQL\\nPL/SQL\\nMySQL\\nTinyDB\\n\\n\\nSQL Server\\nMongoDB\\nPostgreSQL\\nSQLite\\nRedis\\n\\n\\nPHP MyAdmin\\nMariaDB\\nCouchDB\\nDB2\\nSee all \\n\\n\\n\\n\\n\\n Back\\n      \\n\\nComputer Fundamentals\\nOperating System\\nDBMS\\nDSA\\nComputer Networks\\nSoftware Engineering\\n\\n\\nComputer Graphics\\nData Mining\\nDigital Marketing\\nSEO\\nDigital Circuits\\nDiscrete Mathematics\\n\\n\\nCryptography\\nCloud Computing\\nCompiler Design\\nEmbedded Systems\\nMicroprocessors\\nSee all \\n\\n\\n\\n\\n\\n Back\\n      \\n\\nPython\\nNumPy\\nPandas\\nMatplotlib\\n\\n\\nDjango\\nPyQt\\nPyCharm\\nPillow\\n\\n\\nOpenCV\\nSeaborn\\nML with Python\\nSciPy\\nSee all \\n\\n\\n\\n\\n\\n Back\\n      \\n\\nSoftware Testing\\nJira\\nSelenium\\nTestRail\\n\\n\\nPostman\\nCucumber\\nCypress\\n\\n\\nWatir\\nAgile\\njMeter\\n\\n\\n\\n\\n\\n Back\\n      \\n\\nBlockchain\\nInformation Security\\n\\n\\nComputer Security\\nInternet Security\\n\\n\\nNetwork Security\\nWireless Security\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLibrary\\nCourses\\nCertifications\\nLogin\\n\\n\\n\\nMenu\\n\\n\\n\\n\\n\\n\\nShow search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSQL\\nHTML\\nCSS\\nJavascript\\nPython\\nJava\\nC\\nC++\\nPHP\\nScala\\nC#\\nTailwind CSS\\nNode.js\\nMySQL\\nMongoDB\\nPL/SQL\\nSwift\\nBootstrap\\nR\\nMachine Learning\\nBlockchain\\nAngular\\nReact Native\\nComputer Fundamentals\\nCompiler Design\\nOperating System\\nData Structure and Algorithms\\nComputer Network\\nDBMS\\nExcel\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBeautiful Soup Tutorial\\nBeautiful Soup - Home\\nBeautiful Soup - Overview\\nBeautiful Soup - Web Scraping\\nBeautiful Soup - Installation\\nBeautiful Soup - Souping the Page\\nBeautiful Soup - Kinds of objects\\nBeautiful Soup - Inspect Data Source\\nBeautiful Soup - Scrape HTML Content\\nBeautiful Soup - Navigating by Tags\\nBeautiful Soup - Find Elements by ID\\nBeautiful Soup - Find Elements by Class\\nBeautiful Soup - Find Elements by Attribute\\nBeautiful Soup - Searching the Tree\\nBeautiful Soup - Modifying the Tree\\nBeautiful Soup - Parsing a Section of a Document\\nBeautiful Soup - Find all Children of an Element\\nBeautiful Soup - Find Element using CSS Selectors\\nBeautiful Soup - Find all Comments\\nBeautiful Soup - Scraping List from HTML\\nBeautiful Soup - Scraping Paragraphs from HTML\\nBeautifulSoup - Scraping Link from HTML\\nBeautiful Soup - Get all HTML Tags\\nBeautiful Soup - Get Text Inside Tag\\nBeautiful Soup - Find all Headings\\nBeautiful Soup - Extract Title Tag\\nBeautiful Soup - Extract Email IDs\\nBeautiful Soup - Scrape Nested Tags\\nBeautiful Soup - Parsing Tables\\nBeautiful Soup - Selecting nth Child\\nBeautiful Soup - Search by text inside a Tag\\nBeautiful Soup - Remove HTML Tags\\nBeautiful Soup - Remove all Styles\\nBeautiful Soup - Remove all Scripts\\nBeautiful Soup - Remove Empty Tags\\nBeautiful Soup - Remove Child Elements\\nBeautiful Soup -  find vs find_all\\nBeautiful Soup - Specifying the Parser\\nBeautiful Soup - Comparing Objects\\nBeautiful Soup - Copying Objects\\nBeautiful Soup - Get Tag Position\\nBeautiful Soup - Encoding\\nBeautiful Soup - Output Formatting\\nBeautiful Soup - Pretty Printing\\n\\nBeautiful Soup - NavigableString Class\\nBeautiful Soup - Convert Object to String\\nBeautiful Soup - Convert HTML to Text\\nBeautiful Soup - Parsing XML\\nBeautiful Soup - Error Handling\\nBeautiful Soup - Trouble Shooting\\nBeautiful Soup - Porting Old Code\\nBeautiful Soup - Functions Reference\\nBeautiful Soup - contents Property\\nBeautiful Soup - children Property\\nBeautiful Soup - string Property\\nBeautiful Soup - strings Property\\nBeautiful Soup - stripped_strings Property\\nBeautiful Soup - descendants Property\\nBeautiful Soup - parent Property\\nBeautiful Soup - parents Property\\nBeautiful Soup - next_sibling Property\\nBeautiful Soup - previous_sibling Property\\nBeautiful Soup - next_siblings Property\\nBeautiful Soup - previous_siblings Property\\nBeautiful Soup - next_element Property\\nBeautiful Soup - previous_element Property\\nBeautiful Soup - next_elements Property\\nBeautiful Soup - previous_elements Property\\nBeautiful Soup - find Method\\nBeautiful Soup - find_all Method\\nBeautiful Soup - find_parents Method\\nBeautiful Soup - find_parent Method\\nBeautiful Soup - find_next_siblings Method\\nBeautiful Soup - find_next_sibling Method\\nBeautiful Soup - find_previous_siblings Method\\nBeautiful Soup - find_previous_sibling Method\\nBeautiful Soup - find_all_next Method\\nBeautiful Soup - find_next Method\\nBeautiful Soup - find_all_previous Method\\nBeautiful Soup - find_previous Method\\nBeautiful Soup - select Method\\nBeautiful Soup - append Method\\nBeautiful Soup - extend Method\\nBeautiful Soup - NavigableString Method\\nBeautiful Soup - new_tag Method\\nBeautiful Soup - insert Method\\nBeautiful Soup - insert_before Method\\nBeautiful Soup - insert_after Method\\nBeautiful Soup - clear Method\\nBeautiful Soup - extract Method\\nBeautiful Soup - decompose Method\\nBeautiful Soup - replace_with Method\\nBeautiful Soup - wrap Method\\nBeautiful Soup - unwrap Method\\nBeautiful Soup - smooth Method\\nBeautiful Soup - prettify Method\\nBeautiful Soup - encode Method\\nBeautiful Soup - decode Method\\nBeautiful Soup - get_text Method\\nBeautiful Soup - diagnose Method\\nBeautiful Soup Useful Resources\\nBeautiful Soup - Quick Guide\\nBeautiful Soup - Useful Resources\\nBeautiful Soup - Discussion\\n\\n\\nSelected Reading\\nUPSC IAS Exams Notes\\nDeveloper\\'s Best Practices\\nQuestions and Answers\\nEffective Resume Writing\\nHR Interview Questions\\nComputer Glossary\\nWho is Who\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBeautiful Soup - Quick Guide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Previous\\n   \\n\\n\\n\\nNext\\n   \\n\\n\\n\\n\\n\\nBeautiful Soup - Overview\\nIn today\\'s world, we have tons of unstructured data/information (mostly web data) available freely. Sometimes the freely available data is easy to read and sometimes not. No matter how your data is available, web scraping is very useful tool to transform unstructured data into structured data that is easier to read and analyze. In other words, web scraping is a way to collect, organize and analyze this enormous amount of data. So let us first understand what is web-scraping.\\nIntroduction to Beautiful Soup\\nThe Beautiful Soup is a python library which is named after a Lewis Carroll poem of the same name in \"Alice\\'s Adventures in the Wonderland\". Beautiful Soup is a python package and as the name suggests, parses the unwanted data and helps to organize and format the messy web data by fixing bad HTML and present to us in an easily-traversable XML structures.\\nIn short, Beautiful Soup is a python package which allows us to pull data out of HTML and XML documents.\\nHTML tree Structure\\nBefore we look into the functionality provided by Beautiful Soup, let us first understand the HTML tree structure.\\n\\nThe root element in the document tree is the html, which can have parents, children and siblings and this determines by its position in the tree structure. To move among HTML elements, attributes and text, you have to move among nodes in your tree structure.\\nLet us suppose the webpage is as shown below \\n\\nWhich translates to an html document as follows \\n\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <h1>Tutorialspoint Online Library</h1>\\n      <p><b>It\\'s all Free</b></p>\\n   </body>\\n</html>\\n\\nWhich simply means, for above html document, we have a html tree structure as follows \\n\\nBeautiful Soup - web-scraping\\nScraping is simply a process of extracting (from various means), copying and screening of data.\\nWhen we scrape or extract data or feeds from the web (like from web-pages or websites), it is termed as web-scraping.\\nSo, web scraping (which is also known as web data extraction or web harvesting) is the extraction of data from web. In short, web scraping provides a way to the developers to collect and analyze data from the internet.\\nWhy Web-scraping?\\nWeb-scraping provides one of the great tools to automate most of the things a human does while browsing. Web-scraping is used in an enterprise in a variety of ways \\nData for Research\\nSmart analyst (like researcher or journalist) uses web scrapper instead of manually collecting and cleaning data from the websites.\\nProducts, prices & popularity comparison\\nCurrently there are couple of services which use web scrappers to collect data from numerous online sites and use it to compare products popularity and prices.\\nSEO Monitoring\\nThere are numerous SEO tools such as Ahrefs, Seobility, SEMrush, etc., which are used for competitive analysis and for pulling data from your client\\'s websites.\\nSearch engines\\nThere are some big IT companies whose business solely depends on web scraping.\\nSales and Marketing\\nThe data gathered through web scraping can be used by marketers to analyze different niches and competitors or by the sales specialist for selling content marketing or social media promotion services.\\nWhy Python for Web Scraping?\\nPython is one of the most popular languages for web scraping as it can handle most of the web crawling related tasks very easily. \\nBelow are some of the points on why to choose python for web scraping \\nEase of Use\\nAs most of the developers agree that python is very easy to code. We don\\'t have to use any curly braces \"{ }\" or semi-colons \";\" anywhere, which makes it more readable and easy-to-use while developing web scrapers.\\nHuge Library Support\\nPython provides huge set of libraries for different requirements, so it is appropriate for web scraping as well as for data visualization, machine learning, etc.\\nEasily Explicable Syntax\\nPython is a very readable programming language as python syntax are easy to understand. Python is very expressive and code indentation helps the users to differentiate different blocks or scopes in the code.\\nDynamically-typed language\\nPython is a dynamically-typed language, which means the data assigned to a variable tells, what type of variable it is. It saves lot of time and makes work faster.\\nHuge Community\\nPython community is huge which helps you wherever you stuck while writing code.\\nBeautiful Soup - Installation\\nBeautiful Soup is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.\\nBeautifulSoup package is not a part of Python\\'s standard library, hence it must be installed. Before installing the latest version, let us create a virtual environment, as per Python\\'s recommended method.\\nA virtual environment allows us to create an isolated working copy of python for a specific project without affecting the outside setup.\\nWe shall use venv module in Python\\'s standard library to create virtual environment. PIP is included by default in Python version 3.4 or later.\\nUse the following command to create virtual environment in Windows\\n\\nC:\\\\uses\\\\user\\\\>python -m venv myenv\\n\\nOn Ubuntu Linux, update the APT repo and install venv if required before creating virtual environment\\n\\nmvl@GNVBGL3:~ $ sudo apt update && sudo apt upgrade -y\\nmvl@GNVBGL3:~ $ sudo apt install python3-venv\\n\\nThen use the following command to create a virtual environment\\n\\nmvl@GNVBGL3:~ $ sudo python3 -m venv myenv\\n\\nYou need to activate the virtual environment. On Windows use the command\\n\\nC:\\\\uses\\\\user\\\\>cd myenv\\nC:\\\\uses\\\\user\\\\myenv>scripts\\\\activate\\n(myenv) C:\\\\Users\\\\users\\\\user\\\\myenv>\\n\\nOn Ubuntu Linux, use following command to activate the virtual environment\\n\\nmvl@GNVBGL3:~$ cd myenv\\nmvl@GNVBGL3:~/myenv$ source bin/activate\\n(myenv) mvl@GNVBGL3:~/myenv$\\n\\nName of the virtual environment appears in the parenthesis. Now that it is activated, we can now install BeautifulSoup in it.\\n\\n(myenv) mvl@GNVBGL3:~/myenv$ pip3 install beautifulsoup4\\nCollecting beautifulsoup4\\n  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\\n      \\n143.0/143.0 KB 325.2 kB/s eta 0:00:00\\nCollecting soupsieve>1.2\\n  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\\nInstalling collected packages: soupsieve, beautifulsoup4\\nSuccessfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1 \\n\\nNote that the latest version of Beautifulsoup4 is 4.12.2 and requires Python 3.8 or later.\\nIf you don\\'t have easy_install or pip installed, you can download the Beautiful Soup 4 source tarball and install it with setup.py.\\n\\n(myenv) mvl@GNVBGL3:~/myenv$ python setup.py install \\n\\nTo check if Beautifulsoup is properly install, enter following commands in Python terminal \\n\\n>>> import bs4\\n>>> bs4.__version__\\n\\'4.12.2\\'\\n\\nIf the installation hasn\\'t been successful, you will get ModuleNotFoundError.\\nYou will also need to install requests library. It is a HTTP library for Python.\\n\\npip3 install requests\\n\\nInstalling a Parser\\nBy default, Beautiful Soup supports the HTML parser included in Python\\'s standard library, however it also supports many external third party python parsers like lxml parser or html5lib parser. \\nTo install lxml or html5lib parser, use the command:\\n\\npip3 install lxml\\npip3 install html5lib\\n\\nThese parsers have their advantages and disadvantages as shown below \\nParser: Python\\'s html.parser\\nUsage  BeautifulSoup(markup, \"html.parser\")\\nAdvantages\\n\\nBatteries included\\nDecent speed\\nLenient (As of Python 3.2)\\n\\nDisadvantages\\n\\nNot as fast as lxml, less lenient than html5lib.\\n\\nParser: lxml\\'s HTML parser\\nUsage  BeautifulSoup(markup, \"lxml\")\\nAdvantages\\n\\nVery fast\\nLenient\\n\\nDisadvantages\\n\\nExternal C dependency\\n\\nParser: lxml\\'s XML parser\\nUsage  BeautifulSoup(markup, \"lxml-xml\") Or BeautifulSoup(markup, \"xml\")\\nAdvantages\\n\\nVery fast\\nThe only currently supported XML parser\\n\\nDisadvantages\\n\\nExternal C dependency\\n\\nParser: html5lib\\nUsage  BeautifulSoup(markup, \"html5lib\")\\nAdvantages\\n\\nExtremely lenient\\nParses pages the same way a web browser does\\nCreates valid HTML5\\n\\nDisadvantages\\n\\nVery slow\\nExternal Python dependency\\n\\nBeautiful Soup - Souping the Page\\nIt is time to test our Beautiful Soup package in one of the html pages (taking web page - https://www.tutorialspoint.com/index.htm, you can choose any-other web page you want) and extract some information from it.\\nIn the below code, we are trying to extract the title from the webpage \\nExample\\n\\nfrom bs4 import BeautifulSoup\\nimport requests\\n\\n\\nurl = \"https://www.tutorialspoint.com/index.htm\"\\nreq = requests.get(url)\\n\\nsoup = BeautifulSoup(req.content, \"html.parser\")\\n\\nprint(soup.title)\\n\\nOutput\\n\\n<title>Online Courses and eBooks Library<title>\\n\\nOne common task is to extract all the URLs within a webpage. For that we just need to add the below line of code \\n\\nfor link in soup.find_all(\\'a\\'):\\n   print(link.get(\\'href\\'))\\n\\nOutput\\nShown below is the partial output of the above loop \\n\\nhttps://www.tutorialspoint.com/index.htm\\nhttps://www.tutorialspoint.com/codingground.htm\\nhttps://www.tutorialspoint.com/about/about_careers.htm\\nhttps://www.tutorialspoint.com/whiteboard.htm\\nhttps://www.tutorialspoint.com/online_dev_tools.htm\\nhttps://www.tutorialspoint.com/business/index.asp\\nhttps://www.tutorialspoint.com/market/teach_with_us.jsp\\nhttps://www.facebook.com/tutorialspointindia\\nhttps://www.instagram.com/tutorialspoint_/\\nhttps://twitter.com/tutorialspoint\\nhttps://www.youtube.com/channel/UCVLbzhxVTiTLiVKeGV7WEBg\\nhttps://www.tutorialspoint.com/categories/development\\nhttps://www.tutorialspoint.com/categories/it_and_software\\nhttps://www.tutorialspoint.com/categories/data_science_and_ai_ml\\nhttps://www.tutorialspoint.com/categories/cyber_security\\nhttps://www.tutorialspoint.com/categories/marketing\\nhttps://www.tutorialspoint.com/categories/office_productivity\\nhttps://www.tutorialspoint.com/categories/business\\nhttps://www.tutorialspoint.com/categories/lifestyle\\nhttps://www.tutorialspoint.com/latest/prime-packs\\nhttps://www.tutorialspoint.com/market/index.asp\\nhttps://www.tutorialspoint.com/latest/ebooks\\n\\n\\n\\nTo parse a web page stored locally in the current working directory, obtain the file object pointing to the html file, and use it as argument to the BeautifulSoup() constructor.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nwith open(\"index.html\") as fp:\\n    soup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nprint(soup)\\n\\nOutput\\n\\n<html>\\n<head>\\n<title>Hello World</title>\\n</head>\\n<body>\\n<h1 style=\"text-align:center;\">Hello World</h1>\\n</body>\\n</html>\\n\\nYou can also use a string that contains HTML script as constructor\\'s argument as follows \\n\\nfrom bs4 import BeautifulSoup\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <head>\\n      <title>Hello World</title>\\n   </head>\\n   <body>\\n      <h1 style=\"text-align:center;\">Hello World</h1>\\n   </body>\\n</html>\\n\\'\\'\\'\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\nprint(soup)\\n\\nBeautiful Soup uses the best available parser to parse the document. It will use an HTML parser unless specified otherwise.\\nBeautiful Soup - Kinds of objects\\nWhen we pass a html document or string to a beautifulsoup constructor, beautifulsoup basically converts a complex html page into different python objects. Below we are going to discuss four major kinds of objects defined in bs4 package.\\n\\nTag\\nNavigableString\\nBeautifulSoup\\nComments\\n\\nTag Object\\nA HTML tag is used to define various types of content. A tag object in BeautifulSoup corresponds to an HTML or XML tag in the actual page or document.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\\'<b class=\"boldest\">TutorialsPoint</b>\\', \\'lxml\\')\\ntag = soup.html\\nprint (type(tag))\\n\\nOutput\\n\\n<class \\'bs4.element.Tag\\'>\\n\\nTags contain lot of attributes and methods and two important features of a tag are its name and attributes.\\nName (tag.name)\\nEvery tag contains a name and can be accessed through \\'.name\\' as suffix. tag.name will return the type of tag it is.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\\'<b class=\"boldest\">TutorialsPoint</b>\\', \\'lxml\\')\\ntag = soup.html\\nprint (tag.name)\\n\\nOutput\\n\\nhtml\\n\\nHowever, if we change the tag name, same will be reflected in the HTML markup generated by the BeautifulSoup.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\\'<b class=\"boldest\">TutorialsPoint</b>\\', \\'lxml\\')\\ntag = soup.html\\ntag.name = \"strong\"\\nprint (tag)\\n\\nOutput\\n\\n<strong><body><b class=\"boldest\">TutorialsPoint</b></body></strong>\\n\\nAttributes (tag.attrs)\\nA tag object can have any number of attributes. In the above example, the tag <b class=\"boldest\"> has an attribute \\'class\\' whose value is \"boldest\". Anything that is NOT tag, is basically an attribute and must contain a value. A dictionary of attributes and their values is returned by \"attrs\". You can access the attributes either through accessing the keys too.\\nIn the example below, the string argument for Beautifulsoup() constructor contains HTML input tag. The attributes of input tag are returned by \"attr\".\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\\'<input type=\"text\" name=\"name\" value=\"Raju\">\\', \\'lxml\\')\\ntag = soup.input\\n\\nprint (tag.attrs)\\n\\nOutput\\n\\n{\\'type\\': \\'text\\', \\'name\\': \\'name\\', \\'value\\': \\'Raju\\'}\\n\\nWe can do all kind of modifications to our tag\\'s attributes (add/remove/modify), using dictionary operators or methods.\\nIn the following example, the value tag is updated. The updated HTML string shows changes.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\\'<input type=\"text\" name=\"name\" value=\"Raju\">\\', \\'lxml\\')\\ntag = soup.input\\n\\nprint (tag.attrs)\\ntag[\\'value\\']=\\'Ravi\\'\\nprint (soup)\\n\\nOutput\\n\\n<html><body><input name=\"name\" type=\"text\" value=\"Ravi\"/></body></html>\\n\\nWe add a new id tag, and delete the value tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\\'<input type=\"text\" name=\"name\" value=\"Raju\">\\', \\'lxml\\')\\ntag = soup.input\\n\\ntag[\\'id\\']=\\'nm\\'\\ndel tag[\\'value\\']\\nprint (soup)\\n\\nOutput\\n\\n<html><body><input id=\"nm\" name=\"name\" type=\"text\"/></body></html>\\n\\nMulti-valued attributes\\nSome of the HTML5 attributes can have multiple values. Most commonly used is the class-attribute which can have multiple CSS-values. Others include \\'rel\\', \\'rev\\', \\'headers\\', \\'accesskey\\' and \\'accept-charset\\'. The multi-valued attributes in beautiful soup are shown as list.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\ncss_soup = BeautifulSoup(\\'<p class=\"body\"></p>\\', \\'lxml\\')\\nprint (\"css_soup.p[\\'class\\']:\", css_soup.p[\\'class\\'])\\n\\ncss_soup = BeautifulSoup(\\'<p class=\"body bold\"></p>\\', \\'lxml\\')\\nprint (\"css_soup.p[\\'class\\']:\", css_soup.p[\\'class\\'])\\n\\nOutput\\n\\ncss_soup.p[\\'class\\']: [\\'body\\']\\ncss_soup.p[\\'class\\']: [\\'body\\', \\'bold\\']\\n\\nHowever, if any attribute contains more than one value but it is not multi-valued attributes by any-version of HTML standard, beautiful soup will leave the attribute alone \\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nid_soup = BeautifulSoup(\\'<p id=\"body bold\"></p>\\', \\'lxml\\')\\nprint (\"id_soup.p[\\'id\\']:\", id_soup.p[\\'id\\'])\\nprint (\"type(id_soup.p[\\'id\\']):\", type(id_soup.p[\\'id\\']))\\n\\nOutput\\n\\nid_soup.p[\\'id\\']: body bold\\ntype(id_soup.p[\\'id\\']): <class \\'str\\'>\\n\\nNavigableString object\\nUsually, a certain string is placed in opening and closing tag of a certain type. The HTML engine of the browser applies the intended effect on the string while rendering the element. For example , in <b>Hello World</b>, you find a string in the middle of <b> and </b> tags so that it is rendered in bold.\\nThe NavigableString object represents the contents of a tag. It is an object of bs4.element.NavigableString class. To access the contents, use \".string\" with tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(\"<h2 id=\\'message\\'>Hello, Tutorialspoint!</h2>\", \\'html.parser\\')\\n\\nprint (soup.string)\\n\\nprint (type(soup.string))\\n\\nOutput\\n\\nHello, Tutorialspoint!\\n<class \\'bs4.element.NavigableString\\'>\\n\\nA NavigableString object is similar to a Python Unicode string. some of its features support Navigating the tree and Searching the tree. A NavigableString can be converted to a  Unicode string with str() function.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(\"<h2 id=\\'message\\'>Hello, Tutorialspoint!</h2>\",\\'html.parser\\')\\n\\ntag = soup.h2\\nstring = str(tag.string)\\nprint (string)\\n\\nOutput\\n\\nHello, Tutorialspoint!\\n\\nJust as a Python string, which is immutable, the NavigableString also can\\'t be modified in place. However, use replace_with() to replace the inner string of a tag with another.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(\"<h2 id=\\'message\\'>Hello, Tutorialspoint!</h2>\",\\'html.parser\\')\\n\\ntag = soup.h2\\ntag.string.replace_with(\"OnLine Tutorials Library\")\\nprint (tag.string)\\n\\nOutput\\n\\nOnLine Tutorials Library\\n\\nBeautifulSoup object\\nThe BeautifulSoup object represents the entire parsed object. However, it can be considered to be similar to Tag object. It is the object created when we try to scrape a web resource. Because it is similar to a Tag object, it supports the functionality required to parse and search the document tree.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nprint (soup)\\nprint (soup.name)\\nprint (\\'type:\\',type(soup))\\n\\nOutput\\n\\n<html>\\n<head>\\n<title>TutorialsPoint</title>\\n</head>\\n<body>\\n<h2>Departmentwise Employees</h2>\\n<ul>\\n<li>Accounts</li>\\n<ul>\\n<li>Anand</li>\\n<li>Mahesh</li>\\n</ul>\\n<li>HR</li>\\n<ul>\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ul>\\n</ul>\\n</body>\\n</html>\\n[document]\\ntype: <class \\'bs4.BeautifulSoup\\'>\\n\\nThe name property of BeautifulSoup object always returns [document].\\nTwo parsed documents can be combined if you pass a BeautifulSoup object as an argument to a certain function such as replace_with().\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nobj1 = BeautifulSoup(\"<book><title>Python</title></book>\", features=\"xml\")\\nobj2 = BeautifulSoup(\"<b>Beautiful Soup parser</b>\", \"lxml\")\\n\\nobj2.find(\\'b\\').replace_with(obj1)\\nprint (obj2)\\n\\nOutput\\n\\n<html><body><book><title>Python</title></book></body></html>\\n\\nComment object\\nAny text written between <!-- and --> in HTML as well as XML document is treated as comment. BeautifulSoup can detect such commented text as a Comment object.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nmarkup = \"<b><!--This is a comment text in HTML--></b>\"\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ncomment = soup.b.string\\nprint (comment, type(comment))\\n\\nOutput\\n\\nThis is a comment text in HTML <class \\'bs4.element.Comment\\'>\\n\\nThe Comment object is a special type of NavigableString object. The prettify() method displays the comment text with special formatting \\nExample\\n\\nprint (soup.b.prettify())\\n\\nOutput\\n\\n<b>\\n   <!--This is a comment text in HTML-->\\n</b>\\n\\nBeautiful Soup - Inspect Data Source\\nIn order to scrape a web page with BeautifulSoup and Python, your first step for any web scraping project should be to explore the website that you want to scrape. So, first visit the website to understand the site structure before you start extracting the information that\\'s relevant for you.\\nLet us visit TutorialsPoint\\'s Python Tutorial home page. Open  https://www.tutorialspoint.com/python3/index.htm in your browser.\\nUse Developer tools can help you understand the structure of a website. All modern browsers come with developer tools installed. \\nIf using Chrome browser, open the Developer Tools from the top-right menu button () and selecting More Tools  Developer Tools.\\n\\nWith Developer tools, you can explore the site\\'s document object model (DOM) to better understand your source. Select the Elements tab in developer tools. You\\'ll see a structure with clickable HTML elements.\\nThe Tutorial page shows the table of contents in the left sidebar. Right click on any chapter and choose Inspect option.\\n\\nFor the Elements tab, locate the tag that corresponds to the TOC list, as shown in the figure below \\n\\nRight click on the HTML element, copy the HTML element, and paste it in any editor.\\n\\nThe HTML script of the <ul>..</ul> element is now obtained.\\n\\n<ul class=\"toc chapters\">\\n   <li class=\"heading\">Python 3 Basic Tutorial</li>\\n   <li class=\"current-chapter\"><a href=\"/python3/index.htm\">Python 3 - Home</a></li>\\n   <li><a href=\"/python3/python3_whatisnew.htm\">What is New in Python 3</a></li>\\n   <li><a href=\"/python3/python_overview.htm\">Python 3 - Overview</a></li>\\n   <li><a href=\"/python3/python_environment.htm\">Python 3 - Environment Setup</a></li>\\n   <li><a href=\"/python3/python_basic_syntax.htm\">Python 3 - Basic Syntax</a></li>\\n   <li><a href=\"/python3/python_variable_types.htm\">Python 3 - Variable Types</a></li>\\n   <li><a href=\"/python3/python_basic_operators.htm\">Python 3 - Basic Operators</a></li>\\n   <li><a href=\"/python3/python_decision_making.htm\">Python 3 - Decision Making</a></li>\\n   <li><a href=\"/python3/python_loops.htm\">Python 3 - Loops</a></li>\\n   <li><a href=\"/python3/python_numbers.htm\">Python 3 - Numbers</a></li>\\n   <li><a href=\"/python3/python_strings.htm\">Python 3 - Strings</a></li>\\n   <li><a href=\"/python3/python_lists.htm\">Python 3 - Lists</a></li>\\n   <li><a href=\"/python3/python_tuples.htm\">Python 3 - Tuples</a></li>\\n   <li><a href=\"/python3/python_dictionary.htm\">Python 3 - Dictionary</a></li>\\n   <li><a href=\"/python3/python_date_time.htm\">Python 3 - Date & Time</a></li>\\n   <li><a href=\"/python3/python_functions.htm\">Python 3 - Functions</a></li>\\n   <li><a href=\"/python3/python_modules.htm\">Python 3 - Modules</a></li>\\n   <li><a href=\"/python3/python_files_io.htm\">Python 3 - Files I/O</a></li>\\n   <li><a href=\"/python3/python_exceptions.htm\">Python 3 - Exceptions</a></li>\\n</ul>\\n\\nWe can now load this script in a BeautifulSoup object to parse the document tree.\\nBeautiful Soup - Scrape HTML Content\\nThe process of extracting data from websites is called Web scraping. A web page may have urls, Email addresses, images or any other content, which we can be stored in a file or database. Searching a website manually is cumbersome process. There are different web scaping tools that automate the process. \\nWeb scraping is is sometimes prohibited by the use of \\'robots.txt\\' file. Some popular sites provide APIs to access their data in a structured way. Unethical web scraping may result in getting your IP blocked.\\nPython is widely used for web scraping. Python standard library has urllib package, which can be used to extract data from HTML pages. Since urllib module is bundled with the standard library, it need not be installed.\\nThe urllib package is an HTTP client for python programming language. The urllib.request module is usefule when we want to open and read URLs. Other module in urllib package are \\n\\nurllib.error defines the exceptions and errors raised by the urllib.request command.\\nurllib.parse is used for parsing URLs.\\nurllib.robotparser is used for parsing robots.txt files.\\n\\nUse the urlopen() function in urllib module to read the content of a web page from a website.\\n\\nimport urllib.request\\nresponse =  urllib.request.urlopen(\\'http://python.org/\\') \\nhtml = response.read()\\n\\nYou can also use the requests library for this purpose. You need to install it before using.\\npip3 install requests\\nIn the below code, the homepage of http://www.tutorialspoint.com is scraped \\n\\nfrom bs4 import BeautifulSoup\\nimport requests\\n\\n\\nurl = \"https://www.tutorialspoint.com/index.htm\"\\nreq = requests.get(url)\\n\\nThe content obtained by either of the above two methods are then parsed with Beautiful Soup.\\nBeautiful Soup - Navigating by Tags\\nOne of the important pieces of element in any piece of HTML document are tags, which may contain other tags/strings (tag\\'s children). Beautiful Soup provides different ways to navigate and iterate over\\'s tag\\'s children.\\nEasiest way to search a parse tree is to search the tag by its name.\\nsoup.head\\nThe soup.head function returns the contents put inside the <head> .. </head> element of a HTML page.\\n\\nConsider the following HTML page to be scraped:\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n      <script>\\n         document.write(\"Welcome to TutorialsPoint\");\\n      </script>\\n   </head>\\n   <body>\\n      <h1>Tutorialspoint Online Library</h1>\\n      <p><b>It\\'s all Free</b></p>\\n   </body>\\n</html>\\n\\nFollowing code extracts the contents of <head> element\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nwith open(\"index.html\") as fp:\\n   soup = BeautifulSoup(fp, \\'html.parser\\')\\nprint(soup.head)\\n\\nOutput\\n\\n<head>\\n<title>TutorialsPoint</title>\\n<script>\\ndocument.write(\"Welcome to TutorialsPoint\");\\n</script>\\n</head>\\n\\nsoup.body\\nSimilarly, to return the contents of body part of HTML page, use soup.body\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nwith open(\"index.html\") as fp:\\n   soup = BeautifulSoup(fp, \\'html.parser\\')\\nprint (soup.body)\\n\\nOutput\\n\\n<body>\\n<h1>Tutorialspoint Online Library</h1>\\n<p><b>It\\'s all Free</b></p>\\n</body>\\n\\nYou can also extract specific tag (like first <h1> tag) in the <body> tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nwith open(\"index.html\") as fp:\\n   soup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nprint(soup.body.h1)\\n\\nOutput\\n\\n<h1>Tutorialspoint Online Library</h1>\\n\\nsoup.p\\nOur HTML file contains a <p> tag. We can extract the contents of this tag\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nwith open(\"index.html\") as fp:\\n   soup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nprint(soup.p)\\n\\nOutput\\n\\n<p><b>It\\'s all Free</b></p>\\n\\nTag.contents\\nA Tag object may have one or more PageElements. The Tag object\\'s contents property returns a list of all elements included in it.\\nLet us find the elements in <head> tag of our index.html file.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nwith open(\"index.html\") as fp:\\n   soup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.head\\nprint (tag.contents)\\n\\nOutput\\n\\n[\\'\\\\n\\',\\n<title>TutorialsPoint</title>,\\n\\'\\\\n\\',\\n<script>\\ndocument.write(\"Welcome to TutorialsPoint\");\\n</script>,\\n\\'\\\\n\\']\\n\\nTag.children\\nThe structure of tags in a HTML script is hierarchical. The elements are nested one inside the other. For example, the top level <HTML> tag includes <HEAD> and <BODY> tags, each may have other tags in it.\\nThe Tag object has a children property that returns a list iterator object containing the enclosed PageElements.\\nTo demonstrate the children property, we shall use the following HTML script (index.html). In the <body> section, there are two <ul> list elements, one nested in another. In other words, the body tag has top level list elements, and each list element has another list under it.\\n\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <h2>Departmentwise Employees</h2>\\n      <ul>\\n      <li>Accounts</li>\\n         <ul>\\n         <li>Anand</li>\\n         <li>Mahesh</li>\\n         </ul>\\n      <li>HR</li>\\n         <ul>\\n         <li>Rani</li>\\n         <li>Ankita</li>\\n         </ul>\\n      </ul>\\n   </body>\\n</html>\\n\\nThe following Python code gives a list of all the children elements of top level <ul> tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nwith open(\"index.html\") as fp:\\n   soup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.ul\\nprint (list(tag.children))\\n\\nOutput\\n\\n[\\'\\\\n\\', <li>Accounts</li>, \\'\\\\n\\', <ul>\\n<li>Anand</li>\\n<li>Mahesh</li>\\n</ul>, \\'\\\\n\\', <li>HR</li>, \\'\\\\n\\', <ul>\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ul>, \\'\\\\n\\']\\n\\nSince the .children property returns a list_iterator, we can use a for loop to traverse the hierarchy.\\nExample\\n\\nfor child in tag.children:\\n   print (child)\\n\\nOutput\\n\\n<li>Accounts</li>\\n\\n<ul>\\n<li>Anand</li>\\n<li>Mahesh</li>\\n</ul>\\n\\n<li>HR</li>\\n\\n<ul>\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ul>\\n\\nTag.find_all()\\nThis method returns a result set of contents of all the tags matching with the argument tag provided.\\nLet us consider the following HTML page(index.html) for this \\n\\n<html>\\n   <body>\\n      <h1>Tutorialspoint Online Library</h1>\\n      <p><b>It\\'s all Free</b></p>\\n      <a class=\"prog\" href=\"https://www.tutorialspoint.com/java/java_overview.htm\" id=\"link1\">Java</a>\\n      <a class=\"prog\" href=\"https://www.tutorialspoint.com/cprogramming/index.htm\" id=\"link2\">C</a>\\n      <a class=\"prog\" href=\"https://www.tutorialspoint.com/python/index.htm\" id=\"link3\">Python</a>\\n      <a class=\"prog\" href=\"https://www.tutorialspoint.com/javascript/javascript_overview.htm\" id=\"link4\">JavaScript</a>\\n      <a class=\"prog\" href=\"https://www.tutorialspoint.com/ruby/index.htm\" id=\"link5\">C</a>\\n   </body>\\n</html>\\n\\nThe following code lists all the elements with <a> tag\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nwith open(\"index.html\") as fp:\\n   soup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nresult = soup.find_all(\"a\")\\nprint (result)\\n\\nOutput\\n\\n[\\n   <a class=\"prog\" href=\"https://www.tutorialspoint.com/java/java_overview.htm\" id=\"link1\">Java</a>,\\n   <a class=\"prog\" href=\"https://www.tutorialspoint.com/cprogramming/index.htm\" id=\"link2\">C</a>,\\n   <a class=\"prog\" href=\"https://www.tutorialspoint.com/python/index.htm\" id=\"link3\">Python</a>,\\n   <a class=\"prog\" href=\"https://www.tutorialspoint.com/javascript/javascript_overview.htm\" id=\"link4\">JavaScript</a>,\\n   <a class=\"prog\" href=\"https://www.tutorialspoint.com/ruby/index.htm\" id=\"link5\">C</a>\\n]\\n\\nBeautiful Soup - Find Elements by ID\\nIn an HTML document, usually each element is assigned a unique ID. This enables the value of an element to be extracted by a front-end code such as JavaScript function.\\nWith BeautifulSoup, you can find the contents of a given element by its ID. There are two methods by which this can be achieved - find() as well as find_all(), and select()\\nUsing find() method\\nThe find() method of BeautifulSoup object searches for first element that satisfies the given criteria as an argument.\\nLet us use the following HTML script (as index.html) for the purpose\\n\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <form>\\n         <input type = \\'text\\' id = \\'nm\\' name = \\'name\\'>\\n         <input type = \\'text\\' id = \\'age\\' name = \\'age\\'>\\n         <input type = \\'text\\' id = \\'marks\\' name = \\'marks\\'>\\n      </form>\\n   </body>\\n</html>\\n\\nThe following Python code finds the element with its id as nm\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.find(id = \\'nm\\')\\nprint (obj)\\n\\nOutput\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nUsing find_all()\\nThe find_all() method also accepts a filter argument. It returns a list of all the elements with the given id. In a certain HTML document, usually a single element with a particular id. Hence, using find() instead of find_all() is preferrable to search for a given id.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.find_all(id = \\'nm\\')\\nprint (obj)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>]\\n\\nNote that the find_all() method returns a list. The find_all() method also has a limit parameter. Setting limit=1 to find_all() is equivalent to find()\\n\\nobj = soup.find_all(id = \\'nm\\', limit=1)\\n\\nUsing select() method\\nThe select() method in BeautifulSoup class accepts CSS selector as an argument. The # symbol is the CSS selector for id. It followed by the value of required id is passed to select() method. It works as the find_all() method.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.select(\"#nm\")\\nprint (obj)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>]\\n\\nUsing select_one()\\nLike the find_all() method, the select() method also returns a list. There is also a select_one() method to return the first tag of the given argument.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.select_one(\"#nm\")\\nprint (obj)\\n\\nOutput\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nBeautiful Soup - Find Elements by Class\\nCSS (cascaded Style sheets) is a tool for designing the appearance of HTML elements. CSS rules control the different aspects of HTML element such as size, color, alignment etc.. Applying styles is more effective than defining HTML element attributes. You can apply styling rules to each HTML element. Instead of applying style to each element individually, CSS classes are used to apply similar styling to groups of HTML elements to achieve uniform web page appearance. In BeautifulSoup, it is possible to find tags styled with CSS class. In this chapter, we shall use the following methods to search for elements for a specified CSS class \\n\\nfind_all() and find() methods\\nselect() and select_one() methods\\n\\nClass in CSS\\nA class in CSS is a collection of attributes specifying the different features related to appearance, such as font type, size and color, background color, alignment etc. Name of the class is prefixed with a dot (.) while declaring it.\\n\\n.class {  \\n   css declarations;  \\n}\\n\\nA CSS class may be defined inline, or in a separate css file which needs to be included in the HTML script. A typical example of a CSS class could be as follows \\n\\n.blue-text {\\n   color: blue;\\n   font-weight: bold;\\n}\\n\\nYou can search for HTML elements defined with a certain class style with the help of following BeautifulSoup methods.\\nFor the purpose of this chapter, we shall use the following HTML page \\n\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <h2 class=\"heading\">Departmentwise Employees</h2>\\n      <ul>\\n         <li class=\"mainmenu\">Accounts</li>\\n         <ul>\\n            <li class=\"submenu\">Anand</li>\\n            <li class=\"submenu\">Mahesh</li>\\n         </ul>\\n         <li class=\"mainmenu\">HR</li>\\n         <ul>\\n            <li class=\"submenu\">Rani</li>\\n            <li class=\"submenu\">Ankita</li>\\n         </ul>\\n      </ul>\\n   </body>\\n</html>\\n\\nUsing find() and find_all()\\nTo search for elements with a certain CSS class used in a tag, use attrs property of Tag object as follows \\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.find_all(attrs={\"class\": \"mainmenu\"})\\nprint (obj)\\n\\nOutput\\n\\n[<li class=\"mainmenu\">Accounts</li>, <li class=\"mainmenu\">HR</li>]\\n\\nThe result is a list of all the elements with mainmenu class\\nTo fetch the list of elements with any of the CSS classes mentioned in in attrs property, change the find_all() statement to \\n\\nobj = soup.find_all(attrs={\"class\": [\"mainmenu\", \"submenu\"]})\\n\\nThis results into a list of all the elements with any of CSS classes used above.\\n\\n[\\n   <li class=\"mainmenu\">Accounts</li>, \\n   <li class=\"submenu\">Anand</li>, \\n   <li class=\"submenu\">Mahesh</li>, \\n   <li class=\"mainmenu\">HR</li>, \\n   <li class=\"submenu\">Rani</li>, \\n   <li class=\"submenu\">Ankita</li>\\n] \\n\\nUsing select() and select_one()\\nYou can also use select() method with the CSS selector as the argument. The (.) symbol followed by the name of the class is used as the CSS selector.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.select(\".heading\")\\nprint (obj)\\n\\nOutput\\n\\n[<h2 class=\"heading\">Departmentwise Employees</h2>]\\n\\nThe select_one() method returns the first element found with the given class.\\n\\nobj = soup.select_one(\".submenu\")\\n\\nBeautiful Soup - Find Elements by Attribute\\nBoth find() and find_all() methods are meant to find one or all the tags in the document as per the arguments passed to these methods. You can pass attrs parameter to these functions. The value of attrs must be a dictionary with one or more tag attributes and their values.\\nFor the purpose of checking the behaviour of these methods, we shall use the following HTML document (index.html)\\n\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <form>\\n         <input type = \\'text\\' id = \\'nm\\' name = \\'name\\'>\\n         <input type = \\'text\\' id = \\'age\\' name = \\'age\\'>\\n         <input type = \\'text\\' id = \\'marks\\' name = \\'marks\\'>\\n      </form>\\n   </body>\\n</html>\\n\\nUsing find_all()\\nThe following program returns a list of all the tags having input type=\"text\" attribute.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.find_all(attrs={\"type\":\\'text\\'})\\nprint (obj)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>, <input id=\"age\" name=\"age\" type=\"text\"/>, <input id=\"marks\" name=\"marks\" type=\"text\"/>]\\n\\nUsing find()\\nThe find() method returns the first tag in the parsed document that has the given attributes.\\n\\nobj = soup.find(attrs={\"name\":\\'marks\\'})\\n\\nUsing select()\\nThe select() method can be called by passing the attributes to be compared against. The attributes must be put in a list object. It returns a list of all tags that have the given attribute.\\nIn the following code, the select() method returns all the tags with type attribute.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.select(\"[type]\")\\nprint (obj)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>, <input id=\"age\" name=\"age\" type=\"text\"/>, <input id=\"marks\" name=\"marks\" type=\"text\"/>]\\n\\nUsing select_one()\\nThe select_one() is method is similar, except that it returns the first tag satisfying the given filter.\\n\\nobj = soup.select_one(\"[name=\\'marks\\']\")\\n\\nOutput\\n\\n<input id=\"marks\" name=\"marks\" type=\"text\"/>\\n\\nBeautiful Soup - Searching the Tree\\nIn this chapter, we shall discuss different methods in Beautiful Soup for navigating the HTML document tree in different directions - going up and down, sideways, and back and forth.\\nWe shall use the following HTML string in all the examples in this chapter \\n\\nhtml = \"\"\"\\n<html><head><title>TutorialsPoint</title></head>\\n   <body>\\n      <p class=\"title\"><b>Online Tutorials Library</b></p>\\n\\n      <p class=\"story\">TutorialsPoint has an excellent collection of tutorials on:\\n      <a href=\"https://tutorialspoint.com/Python\" class=\"lang\" id=\"link1\">Python</a>,\\n      <a href=\"https://tutorialspoint.com/Java\" class=\"lang\" id=\"link2\">Java</a> and\\n      <a href=\"https://tutorialspoint.com/PHP\" class=\"lang\" id=\"link3\">PHP</a>;\\n      Enhance your Programming skills.</p>\\n\\n      <p class=\"tutorial\">...</p>\\n\"\"\"\\n\\nThe name of required tag lets you navigate the parse tree. For example soup.head fetches you the <head> element \\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\nprint (soup.head.prettify())\\n\\nOutput\\n\\n<head>\\n   <title>\\n      TutorialsPoint\\n   </title>\\n</head>\\n\\nGoing down\\nA tag may contain strings or other tags enclosed in it. The .contents property of Tag object returns a list of all the children elements belonging to it.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag = soup.head \\nprint (list(tag.children))\\n\\nOutput\\n\\n[<title>TutorialsPoint</title>]\\n\\nThe returned object is a list, although in this case, there is only a single child tag enclosed in head element.\\n.children\\nThe .children property also returns a list of all the enclosed elements in a tag. Below, all the elements in body tag are given as a list.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag = soup.body \\nprint (list(tag.children))\\n\\nOutput\\n\\n[\\'\\\\n\\', <p class=\"title\"><b>Online Tutorials Library</b></p>, \\'\\\\n\\', \\n<p class=\"story\">TutorialsPoint has an excellent collection of tutorials on:\\n<a class=\"lang\" href=\"https://tutorialspoint.com/Python\" id=\"link1\">Python</a>,\\n<a class=\"lang\" href=\"https://tutorialspoint.com/Java\" id=\"link2\">Java</a> and\\n<a class=\"lang\" href=\"https://tutorialspoint.com/PHP\" id=\"link3\">PHP</a>;\\nEnhance your Programming skills.</p>, \\'\\\\n\\', <p class=\"tutorial\">...</p>, \\'\\\\n\\']\\n\\nInstead of getting them as a list, you can iterate over a tag\\'s children using the .children generator \\nExample\\n\\ntag = soup.body \\nfor child in tag.children:\\n   print (child)\\n\\nOutput\\n\\n<p class=\"title\"><b>Online Tutorials Library</b></p>\\n<p class=\"story\">TutorialsPoint has an excellent collection of tutorials on:\\n<a class=\"lang\" href=\"https://tutorialspoint.com/Python\" id=\"link1\">Python</a>,\\n<a class=\"lang\" href=\"https://tutorialspoint.com/Java\" id=\"link2\">Java</a> and\\n<a class=\"lang\" href=\"https://tutorialspoint.com/PHP\" id=\"link3\">PHP</a>;\\nEnhance your Programming skills.</p>\\n\\n\\n<p class=\"tutorial\">...</p>\\n\\n.descendents\\nThe .contents and .children attributes only consider a tag\\'s direct children. The .descendants attribute lets you iterate over all of a tag\\'s children, recursively: its direct children, the children of its direct children, and so on.\\nThe BeautifulSoup object is at the top of hierarchy of all the tags. Hence its .descendents property includes all the elements in the HTML string.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\nprint (soup.descendants)\\n\\nThe .descendents attribute returns a generator, which can be iterated with a for loop. Here, we list out the descendents of the head tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.head\\nfor element in tag.descendants:\\n   print (element)\\n\\nOutput\\n\\n<title>TutorialsPoint</title>\\nTutorialsPoint\\n\\nThe head tag contains a title tag, which in turn encloses a NavigableString object TutorialsPoint. The <head> tag has only one child, but it has two descendants: the <title> tag and the <title> tag\\'s child. But the BeautifulSoup object only has one direct child (the <html> tag), but it has many descendants.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntags = list(soup.descendants)\\nprint (len(tags))\\n\\nOutput\\n\\n27\\n\\nGoing Up\\nJust as you navigate the downstream of a document with children and descendents properties, BeautifulSoup offers .parent and .parent properties to navigate the upstream of a tag\\n.parent\\nevery tag and every string has a parent tag that contains it. You can access an element\\'s parent with the parent attribute. In our example, the <head> tag is the parent of the <title> tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag = soup.title\\nprint (tag.parent)\\n\\nOutput\\n\\n<head><title>TutorialsPoint</title></head>\\n\\nSince the title tag contains a string (NavigableString), the parent for the string is title tag itself.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag = soup.title\\nstring = tag.string\\nprint (string.parent)\\n\\nOutput\\n\\n<title>TutorialsPoint</title>\\n\\n.parents\\nYou can iterate over all of an element\\'s parents with .parents. This example uses .parents to travel from an <a> tag buried deep within the document, to the very top of the document. In the following code, we track the parents of the first <a> tag in the example HTML string.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag = soup.a \\nprint (tag.string)\\n\\nfor parent in tag.parents:\\n   print (parent.name)\\n\\nOutput\\n\\nPython\\np\\nbody\\nhtml\\n[document]\\n\\nSideways\\nThe HTML tags appearing at the same indentation level are called siblings. Consider the following HTML snippet\\n\\n<p>\\n   <b>\\n      Hello\\n   </b>\\n   <i>\\n      Python\\n   </i>\\n</p>\\n\\nIn the outer <p> tag, we have <b> and <i> tags at the same indent level, hence they are called siblings. BeautifulSoup makes it possible to navigate between the tags at same level.\\n.next_sibling and .previous_sibling\\nThese attributes respectively return the next tag at the same level, and the previous tag at same level.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p><b>Hello</b><i>Python</i></p>\", \\'html.parser\\')\\n\\ntag1 = soup.b \\nprint (\"next:\",tag1.next_sibling)\\n\\ntag2 = soup.i \\nprint (\"previous:\",tag2.previous_sibling)\\n\\nOutput\\n\\nnext: <i>Python</i>\\nprevious: <b>Hello</b>\\n\\nSince the <b> tag doesn\\'t have a sibling to its left, and <i> tag doesn\\'t have a sibling to its right, it returns Nobe in both cases.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p><b>Hello</b><i>Python</i></p>\", \\'html.parser\\')\\n\\ntag1 = soup.b \\nprint (\"next:\",tag1.previous_sibling)\\n\\ntag2 = soup.i \\nprint (\"previous:\",tag2.next_sibling)\\n\\nOutput\\n\\nnext: None\\nprevious: None\\n\\n.next_siblings and .previous_siblings\\nIf there are two or more siblings to the right or left of a tag, they can be navigated with the help of the .next_siblings and .previous_siblings attributes respectively. Both of them return generator object so that a for loop can be used to iterate.\\nLet us use the following HTML snippet for this purpose \\n\\n<p>\\n   <b>\\n      Excellent\\n   </b>\\n   <i>\\n      Python\\n   </i>\\n   <u>\\n      Tutorial\\n   </u>\\n</p>\\n\\nUse the following code to traverse next and previous sibling tags.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p><b>Excellent</b><i>Python</i><u>Tutorial</u></p>\", \\'html.parser\\')\\n\\ntag1 = soup.b \\nprint (\"next siblings:\")\\nfor tag in tag1.next_siblings:\\n   print (tag)\\nprint (\"previous siblings:\")\\ntag2 = soup.u \\nfor tag in tag2.previous_siblings:\\n   print (tag)\\n\\nOutput\\n\\nnext siblings:\\n<i>Python</i>\\n<u>Tutorial</u>\\nprevious siblings:\\n<i>Python</i>\\n<b>Excellent</b>\\n\\nBack and forth\\nIn Beautiful Soup, the next_element property returns the next string or tag in the parse tree. On the other hand, the previous_element property returns the previous string or tag in the parse tree. Sometimes, the return value of next_element and previous_element attributes is similar to next_sibling and previous_sibling properties.\\n.next_element and .previous_element\\nExample\\n\\nhtml = \"\"\"\\n<html><head><title>TutorialsPoint</title></head>\\n<body>\\n<p class=\"title\"><b>Online Tutorials Library</b></p>\\n\\n<p class=\"story\">TutorialsPoint has an excellent collection of tutorials on:\\n<a href=\"https://tutorialspoint.com/Python\" class=\"lang\" id=\"link1\">Python</a>,\\n<a href=\"https://tutorialspoint.com/Java\" class=\"lang\" id=\"link2\">Java</a> and\\n<a href=\"https://tutorialspoint.com/PHP\" class=\"lang\" id=\"link3\">PHP</a>;\\nEnhance your Programming skills.</p>\\n\\n<p class=\"tutorial\">...</p>\\n\"\"\"\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag = soup.find(\"a\", id=\"link3\")\\nprint (tag.next_element)\\n\\ntag = soup.find(\"a\", id=\"link1\")\\nprint (tag.previous_element)\\n\\nOutput\\n\\nPHP\\nTutorialsPoint has an excellent collection of tutorials on:\\n\\nThe next_element after <a> tag with id = \"link3\" is the string PHP. Similarly, the previous_element returns the string before <a> tag with id = \"link1\".\\n.next_elements and .previous_elements\\nThese attributes of the Tag object return generator respectively of all tags and strings after and before it.\\nNext elements example\\n\\ntag = soup.find(\"a\", id=\"link1\")\\nfor element in tag.next_elements:\\n   print (element)\\n\\nOutput\\n\\nPython\\n,\\n\\n<a class=\"lang\" href=\"https://tutorialspoint.com/Java\" id=\"link2\">Java</a>\\nJava\\n and\\n\\n<a class=\"lang\" href=\"https://tutorialspoint.com/PHP\" id=\"link3\">PHP</a>\\nPHP\\n;\\nEnhance your Programming skills.\\n\\n\\n<p class=\"tutorial\">...</p>\\n...\\n\\nPrevious elements example\\n\\ntag = soup.find(\"body\")\\nfor element in tag.previous_elements:\\n   print (element)\\n\\nOutput\\n\\n<html><head><title>TutorialsPoint</title></head>\\n\\nBeautiful Soup - Modifying the Tree\\nOne of the powerful features of Beautiful Soup library is to be able to be able to manipulate the parsed HTML or XML document and modify its contents.\\nBeautiful Soup library has different functions to perform the following operations \\n\\nAdd contents or a new tag to an existing tag of the document\\nInsert contents before or after an existing tag or string\\nClear the contents of an already existing tag\\nModify the contents of a tag element\\n\\nAdd content\\nYou can add to the content of an existing tag by using append() method on a Tag object. It works like the append() method of Python\\'s list object.\\nIn the following example, the HTML script has a <p> tag. With append(), additional text is appended.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nmarkup = \\'<p>Hello</p>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\nprint (soup)\\ntag = soup.p\\n\\ntag.append(\" World\")\\nprint (soup) \\n\\nOutput\\n\\n<p>Hello</p>\\n<p>Hello World</p>\\n\\nWith the append() method, you can add a new tag at the end of an existing tag. First create a new Tag object with new_tag() method and then pass it to the append() method.\\nExample\\n\\nfrom bs4 import BeautifulSoup, Tag\\n\\nmarkup = \\'<b>Hello</b>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.b \\ntag1 = soup.new_tag(\\'i\\')\\ntag1.string = \\'World\\'\\ntag.append(tag1)\\nprint (soup.prettify()) \\n\\nOutput\\n\\n<b>\\n   Hello\\n   <i>\\n      World\\n   </i>\\n</b>\\n\\nIf you have to add a string to the document, you can append a NavigableString object.\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Hello</b>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.b \\nnew_string = NavigableString(\" World\")\\ntag.append(new_string)\\nprint (soup.prettify())\\n\\nOutput\\n\\n<b>\\n   Hello\\n   World\\n</b>\\n\\nFrom Beautiful Soup version 4.7 onwards, the extend() method has been added to Tag class. It adds all the elements in a list to the tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nmarkup = \\'<b>Hello</b>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.b \\nvals = [\\'World.\\', \\'Welcome to \\', \\'TutorialsPoint\\']\\ntag.extend(vals)\\nprint (soup.prettify())\\n\\nOutput\\n\\n<b>\\n   Hello\\n   World.\\n   Welcome to\\n   TutorialsPoint\\n</b>\\n\\nInsert Contents\\nInstead of adding a new element at the end, you can use insert() method to add an element at the given position in a the list of children of a Tag element. The insert() method in Beautiful Soup behaves similar to insert() on a Python list object.\\nIn the following example, a new string is added to the <b> tag at position 1. The resultant parsed document shows the result.\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Excellent </b><u>from TutorialsPoint</u>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.b\\n\\ntag.insert(1, \"Tutorial \")\\nprint (soup.prettify())\\n\\nOutput\\n\\n<b>\\n   Excellent\\n   Tutorial\\n</b>\\n<u>\\n   from TutorialsPoint\\n</u>\\n\\nBeautiful Soup also has insert_before() and insert_after() methods. Their respective purpose is to insert a tag or a string before or after a given Tag object. The following code shows that a string \"Python Tutorial\" is added after the <b> tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Excellent </b><u>from TutorialsPoint</u>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.b\\n\\ntag.insert_after(\"Python Tutorial\")\\nprint (soup.prettify())\\n\\nOutput\\n\\n<b>\\n   Excellent\\n</b>\\nPython Tutorial\\n<u>\\n   from TutorialsPoint\\n</u>\\n\\nOn the other hand, insert_before() method is used below, to add \"Here is an \" text before the <b> tag.\\n\\ntag.insert_before(\"Here is an \")\\nprint (soup.prettify())\\n\\nOutput\\n\\nHere is an\\n<b>\\n   Excellent\\n</b>\\nPython Tutorial\\n<u>\\n   from TutorialsPoint\\n</u>\\n\\nClear the Contents\\nBeautiful Soup provides more than one ways to remove contents of an element from the document tree. Each of these methods has its unique features.\\nThe clear() method is the most straight-forward. It simply removes the contents of a specified Tag element. Following example shows its usage.\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Excellent </b><u>from TutorialsPoint</u>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.find(\\'u\\')\\n\\ntag.clear()\\nprint (soup.prettify())\\n\\nOutput\\n\\n<b>\\n   Excellent\\n</b>\\n<u>\\n</u>\\n\\nIt can be seen that the clear() method removes the contents, keeping the tag intact.\\nFor the following example, we parse the following HTML document and call clear() metho on all tags.\\n\\n<html>\\n   <body>\\n      <p> The quick, brown fox jumps over a lazy dog.</p>\\n      <p> DJs flock by when MTV ax quiz prog.</p>\\n      <p> Junk MTV quiz graced by fox whelps.</p>\\n      <p> Bawds jog, flick quartz, vex nymphs./p>\\n   </body>\\n</html>\\n\\nHere is the Python code using clear() method\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntags = soup.find_all()\\nfor tag in tags:\\n   tag.clear()\\nprint (soup.prettify())\\n\\nOutput\\n\\n<html>\\n</html>\\n\\nThe extract() method removes either a tag or a string from the document tree, and returns the object that was removed.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntags = soup.find_all()\\nfor tag in tags:\\n   obj = tag.extract()\\n   print (\"Extracted:\",obj)\\n\\nprint (soup)\\n\\nOutput\\n\\nExtracted: <html>\\n<body>\\n<p> The quick, brown fox jumps over a lazy dog.</p>\\n<p> DJs flock by when MTV ax quiz prog.</p>\\n<p> Junk MTV quiz graced by fox whelps.</p>\\n<p> Bawds jog, flick quartz, vex nymphs.</p>\\n</body>\\n</html>\\nExtracted: <body>\\n<p> The quick, brown fox jumps over a lazy dog.</p>\\n<p> DJs flock by when MTV ax quiz prog.</p>\\n<p> Junk MTV quiz graced by fox whelps.</p>\\n<p> Bawds jog, flick quartz, vex nymphs.</p>\\n</body>\\nExtracted: <p> The quick, brown fox jumps over a lazy dog.</p>\\nExtracted: <p> DJs flock by when MTV ax quiz prog.</p>\\nExtracted: <p> Junk MTV quiz graced by fox whelps.</p>\\nExtracted: <p> Bawds jog, flick quartz, vex nymphs.</p>\\n\\nYou can extract either a tag or a string. The following example shows antag being extracted.\\nExample\\n\\nhtml = \\'\\'\\'\\n   <ol id=\"HR\">\\n   <li>Rani</li>\\n   <li>Ankita</li>\\n   </ol>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nobj=soup.find(\\'ol\\')\\nobj.find_next().extract()\\nprint (soup)\\n\\nOutput\\n\\n<ol id=\"HR\">\\n   <li>Ankita</li>\\n</ol>\\n\\nChange the extract() statement to remove inner text of first <li> element.\\nExample\\n\\nobj.find_next().string.extract()\\n\\nOutput\\n\\n<ol id=\"HR\">\\n   <li>Ankita</li>\\n</ol>\\n\\nThere is another method decompose() that removes a tag from the tree, then completely destroys it and its contents \\nExample\\n\\nhtml = \\'\\'\\'\\n   <ol id=\"HR\">\\n      <li>Rani</li>\\n      <li>Ankita</li>\\n   </ol>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag1=soup.find(\\'ol\\')\\ntag2 = soup.find(\\'li\\')\\ntag2.decompose()\\nprint (soup)\\nprint (tag2.decomposed)\\n\\nOutput\\n\\n<ol id=\"HR\">\\n\\n<li>Ankita</li>\\n</ol>\\n\\nThe decomposed property returns True or False - whether an element has been decomposed or not.\\nModify the Contents\\nWe shall look at the replace_with() method that allows contents of a tag to be replaced.\\nJust as a Python string, which is immutable, the NavigableString also can\\'t be modified in place. However, use replace_with() to replace the inner string of a tag with another.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(\"<h2 id=\\'message\\'>Hello, Tutorialspoint!</h2>\",\\'html.parser\\')\\n\\ntag = soup.h2\\ntag.string.replace_with(\"OnLine Tutorials Library\")\\nprint (tag.string)\\n\\nOutput\\n\\nOnLine Tutorials Library\\n\\nHere is another example to show the use of replace_with(). Two parsed documents can be combined if you pass a BeautifulSoup object as an argument to a certain function such as replace_with().2524\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nobj1 = BeautifulSoup(\"<book><title>Python</title></book>\", features=\"xml\")\\nobj2 = BeautifulSoup(\"<b>Beautiful Soup parser</b>\", \"lxml\")\\n\\nobj2.find(\\'b\\').replace_with(obj1)\\nprint (obj2)\\n\\nOutput\\n\\n<html><body><book><title>Python</title></book></body></html>\\n\\nThe wrap() method wraps an element in the tag you specify. It returns the new wrapper.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p>Hello Python</p>\", \\'html.parser\\')\\ntag = soup.p\\nnewtag = soup.new_tag(\\'b\\')\\ntag.string.wrap(newtag)\\n\\nprint (soup)\\n\\nOutput\\n\\n<p><b>Hello Python</b></p>\\n\\nOn the other hand, the unwrap() method replaces a tag with whatever\\'s inside that tag. It\\'s good for stripping out markup.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p>Hello <b>Python</b></p>\", \\'html.parser\\')\\ntag = soup.p\\ntag.b.unwrap()\\n\\nprint (soup)\\n\\nOutput\\n\\n<p>Hello Python</p>\\n\\nBeautiful Soup - Parsing a Section of a Document\\nLet\\'s say you want to use Beautiful Soup look at a document\\'s <a> tags only. Normally you would parse the tree and use find_all() method with the required tag as the argument.\\n\\nsoup = BeautifulSoup(fp, \"html.parser\")\\n\\ntags = soup.find_all(\\'a\\')\\n\\nBut that would be time consuming as well as it will take up more memory unnecessarily. Instead, you can create an object of SoupStrainer class and use it as value of parse_only argument to BeautifulSoup constructor.\\nA SoupStrainer tells BeautifulSoup what parts extract, and the parse tree consists of only these elements. If you narrow down your required information to a specific portion of the HTML, this will speed up your search result.\\n\\nproduct = SoupStrainer(\\'div\\',{\\'id\\': \\'products_list\\'})\\nsoup = BeautifulSoup(html,parse_only=product)\\n\\nAbove lines of code will parse only the titles from a product site, which might be inside a tag field.\\nSimilarly, like above we can use other soupStrainer objects, to parse specific information from an HTML tag. Below are some of the examples \\nExample\\n\\nfrom bs4 import BeautifulSoup, SoupStrainer\\n\\n#Only \"a\" tags\\nonly_a_tags = SoupStrainer(\"a\")\\n\\n#Will parse only the below mentioned \"ids\".\\nparse_only = SoupStrainer(id=[\"first\", \"third\", \"my_unique_id\"])\\nsoup = BeautifulSoup(my_document, \"html.parser\", parse_only=parse_only)\\n\\n#parse only where string length is less than 10\\ndef is_short_string(string):\\n   return len(string) < 10\\n\\nonly_short_strings = SoupStrainer(string=is_short_string)\\n\\nThe SoupStrainer class takes the same arguments as a typical method from Searching the tree: name, attrs, text, and **kwargs.\\nNote that this feature won\\'t work if you\\'re using the html5lib parser, because the whole document will be parsed in that case, no matter what. Hence, you should use either the inbuilt html.parser or lxml parser.\\nYou can also pass a SoupStrainer into any of the methods covered in Searching the tree.\\n\\nfrom bs4 import SoupStrainer\\n\\na_tags = SoupStrainer(\"a\")\\nsoup = BeautifulSoup(html_doc, \\'html.parser\\')\\nsoup.find_all(a_tags)\\n\\nBeautiful Soup - Find all Children of an Element\\nThe structure of tags in a HTML script is hierarchical. The elements are nested one inside the other. For example, the top level <HTML> tag includes <HEAD> and <BODY> tags, each may have other tags in it. The top level element is called as parent. The elements nested inside the parent are its children. With the help of Beautiful Soup, we can find all the children elements of a parent element. In this chapter, we shall find out how to obtain the children of a HTML element.\\nThere are two provisions in BeautifulSoup class to fetch the children elements.\\n\\nThe .children property\\nThe findChildren() method\\n\\nExamples in this chapter use the following HTML script (index.html)\\n\\n<html>\\n<head>\\n<title>TutorialsPoint</title>\\n</head>\\n<body>\\n<h2>Departmentwise Employees</h2>\\n<ul id=\"dept\">\\n<li>Accounts</li>\\n   <ul id=\\'acc\\'>\\n   <li>Anand</li>\\n   <li>Mahesh</li>\\n   </ul>\\n<li>HR</li>\\n   <ul id=\"HR\">\\n   <li>Rani</li>\\n   <li>Ankita</li>\\n   </ul>\\n</ul>\\n</body>\\n</html>\\n\\nUsing .children property\\nThe .children property of a Tag object returns a generator of all the child elements in a recursive manner.\\nThe following Python code gives a list of all the children elements of top level <ul> tag. We first obtain the Tag element corresponding to the <ul> tag, and then read its .children property\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nwith open(\"index.html\") as fp:\\n   soup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.ul\\nprint (list(tag.children))\\n\\nOutput\\n\\n[\\'\\\\n\\', <li>Accounts</li>, \\'\\\\n\\', <ul>\\n<li>Anand</li>\\n<li>Mahesh</li>\\n</ul>, \\'\\\\n\\', <li>HR</li>, \\'\\\\n\\', <ul>\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ul>, \\'\\\\n\\']\\n\\nSince the .children property returns a list_iterator, we can use a for loop to traverse the hierarchy.\\n\\nfor child in tag.children:\\n   print (child)\\n\\nOutput\\n\\n<li>Accounts</li>\\n\\n<ul>\\n<li>Anand</li>\\n<li>Mahesh</li>\\n</ul>\\n\\n<li>HR</li>\\n\\n<ul>\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ul>\\n\\nUsing findChildren() method\\nThe findChildren() method offers a more comprehensive alternative. It returns all the child elements under any top level tag. \\nIn the index.html document, we have two nested unordered lists. The top level <ul> element has id = \"dept\" and the two enclosed lists are having id = \"acc\\' and \"HR\\' respectively.\\nIn the following example, we first instantiate a Tag object pointing to top level <ul> element and extract the list of children under it.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.find(\"ul\", {\"id\": \"dept\"})\\n\\nchildren = tag.findChildren()\\n \\nfor child in children:\\n   print(child)\\n\\nNote that the resultset includes the children under an element in a recursive fashion. Hence, in the following output, you\\'ll find the entire inner list, followed by individual elements in it.\\n\\n<li>Accounts</li>\\n<ul id=\"acc\">\\n<li>Anand</li>\\n<li>Mahesh</li>\\n</ul>\\n<li>Anand</li>\\n<li>Mahesh</li>\\n<li>HR</li>\\n<ul id=\"HR\">\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ul>\\n<li>Rani</li>\\n<li>Ankita</li>\\n\\nLet us extract the children under an inner <ul> element with id=\\'acc\\'. Here is the code \\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.find(\"ul\", {\"id\": \"acc\"})\\n\\nchildren = tag.findChildren()\\n \\nfor child in children:\\n\\tprint(child)\\n\\nWhen the above program is run, you\\'ll obtain the <li>elements under the <ul> with id as acc.\\nOutput\\n\\n<li>Anand</li>\\n<li>Mahesh</li>\\n\\nThus, BeautifulSoup makes it very easy to parse the children elements under any top level HTML element.\\nBeautiful Soup - Find Element using CSS Selectors\\nIn Beautiful Soup library, the select() method is an important tool for scraping the HTML/XML document. Similar to find() and the other find_*() methods, the select() method also helps in locating an element that satisfies a given criteria. However, the find*() methods search for the PageElements according to the Tag name and its attributes, the select() method searches the document tree for the given CSS selector.\\nBeautiful Soup also has select_one() method. Difference in select() and select_one() is that, select() returns a ResultSet of all the elements belonging to the PageElement and characterized by the CSS selector; whereas select_one() returns the first occurrence of the element satisfying the CSS selector based selection criteria.\\nPrior to Beautiful Soup version 4.7, the select() method used to be able to support only the common CSS selectors. With version 4.7, Beautiful Soup was integrated with Soup Sieve CSS selector library. As a result, much more selectors can now be used. In the version 4.12, a .css property has been added in addition to the existing convenience methods, select() and select_one().The parameters for select() method are as follows \\n\\nselect(selector, limit, **kwargs)\\n\\nselector  A string containing a CSS selector.\\nlimit  After finding this number of results, stop looking.\\nkwargs  Keyword arguments to be passed.\\nIf the limit parameter is set to 1, it becomes equivalent to select_one() method. While the select() method returns a ResultSet of Tag objects, the select_one() method returns a single Tag object.\\nSoup Sieve Library\\nSoup Sieve is a CSS selector library. It has been integrated with Beautiful Soup 4, so it is installed along with Beautiful Soup package. It provides ability to select, match, and filter he document tree tags using modern CSS selectors. Soup Sieve currently implements most of the CSS selectors from the CSS level 1 specifications up to CSS level 4, except for some that are not yet implemented.\\nThe Soup Sieve library has different types of CSS selectors. The basic CSS selectors are \\nType selector\\nMatching elements is done by node name. For example \\n\\ntags = soup.select(\\'div\\')\\n\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntags = soup.select(\\'div\\')\\nprint (tags)\\n\\nOutput\\n\\n[<div id=\"Languages\">\\n<p>Java</p> <p>Python</p> <p>C++</p>\\n</div>]\\n\\nUniversal selector (*) \\nIt matches elements of any type. Example \\n\\ntags = soup.select(\\'*\\')\\n\\nID selector\\nIt matches an element based on its id attribute. The symbol # denotes the ID selector. Example \\n\\ntags = soup.select(\"#nm\")\\n\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nhtml = \\'\\'\\'\\n   <form>\\n      <input type = \\'text\\' id = \\'nm\\' name = \\'name\\'>\\n      <input type = \\'text\\' id = \\'age\\' name = \\'age\\'>\\n      <input type = \\'text\\' id = \\'marks\\' name = \\'marks\\'>\\n   </form>\\n\\'\\'\\'\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nobj = soup.select(\"#nm\")\\nprint (obj)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>]\\n\\nClass selector \\nIt matches an element based on the values contained in the class attribute. The . symbol prefixed to the class name is the CSS class selector. Example \\n\\ntags = soup.select(\".submenu\")\\n\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntags = soup.select(\\'div\\')\\nprint (tags)\\n\\nOutput\\n\\n[<div id=\"Languages\">\\n<p>Java</p> <p>Python</p> <p>C++</p>\\n</div>]\\n\\nAttribute Selectors\\nThe attribute selector matches an element based on its attributes.\\n\\nsoup.select(\\'[attr]\\')\\n\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nhtml = \\'\\'\\'\\n   <h1>Tutorialspoint Online Library</h1>\\n   <p><b>It\\'s all Free</b></p>\\n   <a class=\"prog\" href=\"https://www.tutorialspoint.com/java/java_overview.htm\" id=\"link1\">Java</a> \\n   <a class=\"prog\" href=\"https://www.tutorialspoint.com/cprogramming/index.htm\" id=\"link2\">C</a>\\n\\'\\'\\'\\nsoup = BeautifulSoup(html, \\'html5lib\\')\\nprint(soup.select(\\'[href]\\'))\\n\\nOutput\\n\\n[<a class=\"prog\" href=\"https://www.tutorialspoint.com/java/java_overview.htm\" id=\"link1\">Java</a>, <a class=\"prog\" href=\"https://www.tutorialspoint.com/cprogramming/index.htm\" id=\"link2\">C</a>]\\n\\nPseudo Classes\\nCSS specification defines a number of pseudo CSS classes. A pseudo-class is a keyword added to a selector so as to define a special state of the selected elements. It adds an effect to the existing elements. For example, :link selects a link (every <a> and <area> element with an href attribute) that has not yet been visited.\\nThe pseudo-class selectors nth-of-type and nth-child are very widely used.\\n:nth-of-type()\\nThe selector :nth-of-type() matches elements of a given type, based on their position among a group of siblings. The keywords even and odd, and will respectively select elements, from a sub-group of sibling elements.\\nIn the following example, second element of <p> type is selected.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nhtml = \\'\\'\\'\\n<p id=\"0\"></p>\\n<p id=\"1\"></p>\\n<span id=\"2\"></span>\\n<span id=\"3\"></span>\\n\\'\\'\\'\\nsoup = BeautifulSoup(html, \\'html5lib\\')\\nprint(soup.select(\\'p:nth-of-type(2)\\'))\\n\\nOutput\\n\\n[<p id=\"1\"></p>]\\n\\n:nth-child()\\nThis selector matches elements based on their position in a group of siblings. The keywords even and odd will respectively select elements whose position is either even or odd amongst a group of siblings.\\nUsage\\n\\n:nth-child(even)\\n:nth-child(odd)\\n:nth-child(2)\\n\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.div\\n\\nchild = tag.select_one(\\':nth-child(2)\\')\\nprint (child)\\n\\nOutput\\n\\n<p>Python</p>\\n\\nBeautiful Soup - Find all Comments\\nInserting comments in a computer code is supposed to be a good programming practice. Comments are helpful for understanding the logic of the program. They also serve as a documentation. You can put comments in a HTML as well as XML script, just as in a program written in C, Java, Python etc. BeautifulSoup API can be helpful to identify all the comments in a HTML document.\\nIn HTML and XML, the comment text is written between <!-- and --> tags.\\n\\n<!-- Comment Text -->\\n\\nThe BeutifulSoup package, whose internal name is bs4, defines Comment as an important object. The Comment object is a special type of NavigableString object. Hence, the string property of any Tag that is found between <!-- and --> is recognized as a Comment.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nmarkup = \"<b><!--This is a comment text in HTML--></b>\"\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ncomment = soup.b.string\\nprint (comment, type(comment))\\n\\nOutput\\n\\nThis is a comment text in HTML <class \\'bs4.element.Comment\\'>\\n\\nTo search for all the occurrences of comment in a HTML document, we shall use find_all() method. Without any argument, find_all() returns all the elements in the parsed HTML document. You can pass a keyword argument \\'string\\' to find_all() method. We shall assign the return value of a function iscomment() to it.\\n\\ncomments = soup.find_all(string=iscomment)\\n\\nThe iscomment() function verifies if the text in a tag is a comment object or not, with the help of isinstance() function.\\n\\ndef iscomment(elem):\\n   return isinstance(elem, Comment)\\n\\nThe comments variable shall store all the comment text occurrences in the given HTML document. We shall use the following index.html file in the example code \\n\\n<html>\\n   <head>\\n      <!-- Title of document -->\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <!-- Page heading -->\\n      <h2>Departmentwise Employees</h2>\\n      <!-- top level list-->\\n      <ul id=\"dept\">\\n      <li>Accounts</li>\\n         <ul id=\\'acc\\'>\\n         <!-- first inner list -->\\n         <li>Anand</li>\\n         <li>Mahesh</li>\\n         </ul>\\n      <li>HR</li>\\n         <ul id=\"HR\">\\n         <!-- second inner list -->\\n         <li>Rani</li>\\n         <li>Ankita</li>\\n         </ul>\\n      </ul>\\n   </body>\\n</html>\\n\\nThe following Python program scrapes the above HTML document, and finds all the comments in it.\\nExample\\n\\nfrom bs4 import BeautifulSoup, Comment\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ndef iscomment(elem):\\n    return isinstance(elem, Comment)\\n\\ncomments = soup.find_all(string=iscomment)\\nprint (comments)\\n\\nOutput\\n\\n[\\' Title of document \\', \\' Page heading \\', \\' top level list\\', \\' first inner list \\', \\' second inner list \\']\\n\\nThe above output shows a list of all comments. We can also use a for loop over the collection of comments.\\nExample\\n\\ni=0\\nfor comment in comments:\\n   i+=1\\n   print (i,\".\",comment)\\n\\nOutput\\n\\n1 .  Title of document \\n2 .  Page heading\\n3 .  top level list\\n4 .  first inner list\\n5 .  second inner list\\n\\nIn this chapter, we learned how to extract all the comment strings in a HTML document.\\nBeautiful Soup - Scraping List from HTML\\nWeb pages usually contain important data in the formation in the form of ordered or unordered lists. With Beautiful Soup, we can easily extract the HTML list elements, bring the data in Python objects to store in databases for further analysis. In this chapter, we shall use find() and select() methods to scrape the list data from a HTML document.\\nEasiest way to search a parse tree is to search the tag by its name. soup.<tag> fetches the contents of the given tag.\\nHTML provides <ol> and <ul> tags to compose ordered and unordered lists. Like any other tag, we can fetch the contents of these tags.\\nWe shall use the following HTML document \\n\\n<html>\\n   <body>\\n      <h2>Departmentwise Employees</h2>\\n      <ul id=\"dept\">\\n      <li>Accounts</li>\\n         <ul id=\\'acc\\'>\\n         <li>Anand</li>\\n         <li>Mahesh</li>\\n         </ul>\\n      <li>HR</li>\\n         <ol id=\"HR\">\\n         <li>Rani</li>\\n         <li>Ankita</li>\\n         </ol>\\n      </ul>\\n   </body>\\n</html>\\n\\nScraping lists by Tag\\nIn the above HTML document, we have a top-level <ul> list, inside which there\\'s another <ul> tag and another <ol> tag. We first parse the document in soup object and retrieve contents of first <ul> in soup.ul Tag object.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nlst=soup.ul\\n\\nprint (lst)\\n\\nOutput\\n\\n<ul id=\"dept\">\\n<li>Accounts</li>\\n<ul id=\"acc\">\\n<li>Anand</li>\\n<li>Mahesh</li>\\n</ul>\\n<li>HR</li>\\n<ol id=\"HR\">\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ol>\\n</ul>\\n\\nChange value of lst to point to <ol> element to get the inner list.\\n\\nlst=soup.ol\\n\\nOutput\\n\\n<ol id=\"HR\">\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ol>\\n\\nUsing select() method\\nThe select() method is essentially used to obtain data using CSS selector. However, you can also pass a tag to it. Here, we can pass the ol tag to select() method. The select_one() method is also available. It fetches the first occurrence of the given tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nlst=soup.select(\"ol\")\\n\\nprint (lst)\\n\\nOutput\\n\\n[<ol id=\"HR\">\\n<li>Rani</li>\\n<li>Ankita</li>\\n</ol>]\\n\\nUsing find_all() method\\nThe find() and fin_all() methods are more comprehensive. You can pass various types of filters such as tag, attributes or string etc. to these methods. In this case, we want to fetch the contents of a list tag.\\nIn the following code, find_all() method returns a list of all elements in the <ul> tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nlst=soup.find_all(\"ul\")\\n\\nprint (lst)\\n\\nWe can refine the search filter by including the attrs argument. In our HTML document, the <ul> and <ol> tags, we have specified their respective id attributes. So, let us fetch the contents of <ul> element having id=\"acc\".\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nlst=soup.find_all(\"ul\", {\"id\":\"acc\"})\\n\\nprint (lst)\\n\\nOutput\\n\\n[<ul id=\"acc\">\\n<li>Anand</li>\\n<li>Mahesh</li>\\n</ul>]\\n\\nHere\\'s another example. We collect all elements with <li> tag with the inner text starting with \\'A\\'. The find_all() method takes a keyword argument string. It takes the value of the text if the startingwith() function returns True.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\ndef startingwith(ch):\\n   return ch.startswith(\\'A\\')\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nlst=soup.find_all(\\'li\\',string=startingwith)\\n\\nprint (lst)\\n\\nOutput\\n\\n[<li>Accounts</li>, <li>Anand</li>, <li>Ankita</li>]\\n\\nBeautiful Soup - Scraping Paragraphs from HTML\\nOne of the frequently appearing tags in a HTML document is the <p> tag that marks a paragraph text. With Beautiful Soup, you can easily extract paragraph from the parsed document tree. In this chapter, we shall discuss the following ways of scraping paragraphs with the help of BeautifulSoup library.\\n\\nScraping HTML paragraph with <p> tag\\nScraping HTML paragraph with find_all() method\\nScraping HTML paragraph with select() method\\n\\nWe shall use the following HTML document for these exercises \\n\\n<html>\\n   <head>\\n      <title>BeautifulSoup - Scraping Paragraph</title>\\n   </head>\\n   <body>\\n      <p id=\\'para1\\'>The quick, brown fox jumps over a lazy dog.</p>\\n      <h2>Hello</h2>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      \\n      <p>Junk MTV quiz graced by fox whelps.</p>\\n      \\n      <p>Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\nScraping by <p> tag\\nEasiest way to search a parse tree is to search the tag by its name. Hence, the expression soup.p points towards the first <p> tag in the scouped document.\\n\\npara = soup.p\\n\\nTo fetch all the subsequent <p> tags, you can run a loop till the soup object is exhausted of all the <p> tags. The following program displays the prettified output of all the paragraph tags.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\npara = soup.p \\nprint (para.prettify())\\nwhile True:\\n   p = para.find_next(\\'p\\')\\n   if p is None:\\n      break\\n   print (p.prettify())\\n   para=p\\n\\nOutput\\n\\n<p>\\n The quick, brown fox jumps over a lazy dog.\\n</p>\\n\\n<p>\\n DJs flock by when MTV ax quiz prog.\\n</p>\\n\\n<p>\\n Junk MTV quiz graced by fox whelps.\\n</p>\\n\\n<p>\\n Bawds jog, flick quartz, vex nymphs.\\n</p>\\n\\nUsing find_all() method\\nThe find_all() methods is more comprehensive. You can pass various types of filters such as tag, attributes or string etc. to this method. In this case, we want to fetch the contents of a <p> tag.\\nIn the following code, find_all() method returns a list of all elements in the <p> tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nparas = soup.find_all(\\'p\\') \\nfor para in paras:\\n   print (para.prettify())\\n\\nOutput\\n\\n<p>\\n The quick, brown fox jumps over a lazy dog.\\n</p>\\n\\n<p>\\n DJs flock by when MTV ax quiz prog.\\n</p>\\n\\n<p>\\n Junk MTV quiz graced by fox whelps.\\n</p>\\n\\n<p>\\n Bawds jog, flick quartz, vex nymphs.\\n</p>\\n\\nWe can use another approach to find all <p> tags. To begin with, obtain list of all tags using find_all() and check Tag.name of each equals =\\'p\\'.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntags = soup.find_all()\\nparas = [tag.contents for tag in tags if tag.name==\\'p\\']\\nprint (paras)\\n\\nThe find_all() method also has attrs parameter. It is useful when you want to extract the <p> tag with specific attributes. For example, in the given document, the first <p> element has id=\\'para1\\'. To fetch it, we need to modify the tag object as \\n\\nparas = soup.find_all(\\'p\\', attrs={\\'id\\':\\'para1\\'})\\n\\nUsing select() method\\nThe select() method is essentially used to obtain data using CSS selector. However, you can also pass a tag to it. Here, we can pass the <p> tag to select() method. The select_one() method is also available. It fetches the first occurrence of the <p> tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nparas = soup.select(\\'p\\')\\nprint (paras)\\n\\n\\nOutput\\n\\n[\\n<p>The quick, brown fox jumps over a lazy dog.</p>, \\n<p>DJs flock by when MTV ax quiz prog.</p>, \\n<p>Junk MTV quiz graced by fox whelps.</p>, \\n<p>Bawds jog, flick quartz, vex nymphs.</p>\\n]\\n\\nTo filter out <p> tags with a certain id, use a for loop as follows \\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntags = soup.select(\\'p\\')\\nfor tag in tags:\\n   if tag.has_attr(\\'id\\') and tag[\\'id\\']==\\'para1\\':\\n      print (tag.contents)\\n\\nOutput\\n\\n[\\'The quick, brown fox jumps over a lazy dog.\\']\\n\\nBeautifulSoup - Scraping Link from HTML\\nWhile scraping and analysing the content from resources with a website, you are often required to extract all the links that a certain page contains. In this chapter, we shall find out how we can extract links from a HTML document.\\nHTML has the anchor tag <a> to insert a hyperlink. The href attribute of anchor tag lets you to establish the link. It uses the following syntax \\n\\n<a href==\"web page URL\">hypertext</a>\\n\\nWith the find_all() method we can collect all the anchor tags in a document and then print the value of href attribute of each of them.\\nIn the example below, we extract all the links found on Google\\'s home page. We use requests library to collect the HTML contents of https://google.com, parse it in a soup object, and then collect all <a> tags. Finally, we print href attributes.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nimport requests\\n\\nurl = \"https://www.google.com/\"\\nreq = requests.get(url)\\n\\nsoup = BeautifulSoup(req.content, \"html.parser\")\\n\\ntags = soup.find_all(\\'a\\')\\nlinks = [tag[\\'href\\'] for tag in tags]\\nfor link in links:\\n   print (link)\\n\\nHere\\'s the partial output when the above program is run \\nOutput\\n\\nhttps://www.google.co.in/imghp?hl=en&tab=wi\\nhttps://maps.google.co.in/maps?hl=en&tab=wl\\nhttps://play.google.com/?hl=en&tab=w8\\nhttps://www.youtube.com/?tab=w1\\nhttps://news.google.com/?tab=wn\\nhttps://mail.google.com/mail/?tab=wm\\nhttps://drive.google.com/?tab=wo\\nhttps://www.google.co.in/intl/en/about/products?tab=wh\\nhttp://www.google.co.in/history/optout?hl=en\\n/preferences?hl=en\\nhttps://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.com/&ec=GAZAAQ\\n/advanced_search?hl=en-IN&authuser=0\\nhttps://www.google.com/url?q=https://io.google/2023/%3Futm_source%3Dgoogle-hpp%26utm_medium%3Dembedded_marketing%26utm_campaign%3Dhpp_watch_live%26utm_content%3D&source=hpp&id=19035434&ct=3&usg=AOvVaw0qzqTkP5AEv87NM-MUDd_u&sa=X&ved=0ahUKEwiPzpjku-z-AhU1qJUCHVmqDJoQ8IcBCAU\\n\\nHowever, a HTML document may have hyperlinks of different protocol schemes, such as mailto: protocol for link to an email ID, tel: scheme for link to a telephone number, or a link to a local file with file:// URL scheme. In such a case, if we are interested in extracting links with https:// scheme, we can do so by the following example. We have a HTML document that consists of hyperlinks of different types, out of which only ones with https:// prefix are being extracted.\\n\\nhtml = \\'\\'\\'\\n<p><a href=\"https://www.tutorialspoint.com\">Web page link </a></p>\\n<p><a href=\"https://www.example.com\">Web page link </a></p>\\n<p><a href=\"mailto:nowhere@mozilla.org\">Email link</a></p>\\n<p><a href=\"tel:+4733378901\">Telephone link</a></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\nimport requests\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntags = soup.find_all(\\'a\\')\\nlinks = [tag[\\'href\\'] for tag in tags]\\nfor link in links:\\n   if link.startswith(\"https\"):\\n      print (link)\\n\\nOutput\\n\\nhttps://www.tutorialspoint.com\\nhttps://www.example.com\\n\\nBeautiful Soup - Get all HTML Tags\\nTags in HTML are like keywords in a traditional programming language like Python or Java. Tags have a predefined behaviour according to which the its content is rendered by the browser. With Beautiful Soup, it is possible to collect all the tags in a given HTML document.\\nThe simplest way to obtain a list of tags is to parse the web page into a soup object, and call find_all() methods without any argument. It returns a list generator, giving us a list of all the tags.\\nLet us extract the list of all tags in Google\\'s homepage.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nimport requests\\n\\nurl = \"https://www.google.com/\"\\nreq = requests.get(url)\\n\\nsoup = BeautifulSoup(req.content, \"html.parser\")\\n\\ntags = soup.find_all()\\nprint ([tag.name for tag in tags])\\n\\nOutput\\n\\n[\\'html\\', \\'head\\', \\'meta\\', \\'meta\\', \\'title\\', \\'script\\', \\'style\\', \\'style\\', \\'script\\', \\'body\\', \\'script\\', \\'div\\', \\'div\\', \\'nobr\\', \\'b\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'u\\', \\'div\\', \\'nobr\\', \\'span\\', \\'span\\', \\'span\\', \\'a\\', \\'a\\', \\'a\\', \\'div\\', \\'div\\', \\'center\\', \\'br\\', \\'div\\', \\'img\\', \\'br\\', \\'br\\', \\'form\\', \\'table\\', \\'tr\\', \\'td\\', \\'td\\', \\'input\\', \\'input\\', \\'input\\', \\'input\\', \\'input\\', \\'div\\', \\'input\\', \\'br\\', \\'span\\', \\'span\\', \\'input\\', \\'span\\', \\'span\\', \\'input\\', \\'script\\', \\'input\\', \\'td\\', \\'a\\', \\'input\\', \\'script\\', \\'div\\', \\'div\\', \\'br\\', \\'div\\', \\'style\\', \\'div\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'span\\', \\'div\\', \\'div\\', \\'a\\', \\'a\\', \\'a\\', \\'a\\', \\'p\\', \\'a\\', \\'a\\', \\'script\\', \\'script\\', \\'script\\']\\n\\nNaturally, you may get such a list where one certain tag may appear more than once. To obtain a list of unique tags (avoiding the duplication), construct a set from the list of tag objects.\\nChange the print statement in above code to\\nExample\\n\\nprint ({tag.name for tag in tags})\\n\\nOutput\\n\\n{\\'body\\', \\'head\\', \\'p\\', \\'a\\', \\'meta\\', \\'tr\\', \\'nobr\\', \\'script\\', \\'br\\', \\'img\\', \\'b\\', \\'form\\', \\'center\\', \\'span\\', \\'div\\', \\'input\\', \\'u\\', \\'title\\', \\'style\\', \\'td\\', \\'table\\', \\'html\\'}\\n\\nTo obtain tags with some text associated with them, check the string property and print if it is not None\\n\\ntags = soup.find_all()\\nfor tag in tags:\\n   if tag.string is not None:\\n      print (tag.name, tag.string)\\n\\nThere may be some singleton tags without text but with one or more attributes as in the <img> tag. Following loop constructs lists out such tags.\\nIn the following code, the HTML string is not a complete HTML document in the sense that thr <html> and <body> tags are not given. But the html5lib and lxml parsers add these tags on their own while parsing the document tree. Hence, when we extract the tag list, the additional tags will also be seen.\\nExample\\n\\nhtml = \\'\\'\\'\\n<h1 style=\"color:blue;text-align:center;\">This is a heading</h1>\\n<p style=\"color:red;\">This is a paragraph.</p>\\n<p>This is another paragraph</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html5lib\")\\n\\ntags = soup.find_all()\\nprint ({tag.name for tag in tags} )\\n\\nOutput\\n\\n{\\'head\\', \\'html\\', \\'p\\', \\'h1\\', \\'body\\'}\\n\\nBeautiful Soup - Get Text Inside Tag\\nThere are two types of tags in HTML. Many of the tags are in pairs of opening and closing counterparts. The top level <html> tag having a corresponding closing </html> tag is the main example. Others are <body> and </body>, <p> and </p>, <h1> and </h1> and many more. Other tags are self-closing tags - such as <img> and<a>. The self-closing tags don\\'t have a text as most of the tags with opening and closing symbols (such as <b>Hello</b>). In this chapter, we shall have a look at how can we get the text part inside such tags, with the help of Beautiful Soup library.\\nThere are more than one methods/properties available in Beautiful Soup, with which we can fetch the text associated with a tag object.\\n\\n\\nSr.No\\nMethods & Description\\n\\n\\n1\\ntext propertyGet all child strings of a PageElement, concatenated using a separator if specified.\\n\\n\\n2\\nstring propertyConvenience property to string from a child element.\\n\\n\\n3\\nstrings propertyyields string parts from all the child objects under the current PageElement.\\n\\n\\n4\\nstripped_strings propertySame as strings property, with the linebreaks and whitespaces removed.\\n\\n\\n5\\nget_text() methodreturns all child strings of this PageElement, concatenated using a separator if specified.\\n\\n\\nConsider the following HTML document \\n\\n<div id=\"outer\">\\n   <div id=\"inner\">\\n      <p>Hello<b>World</b></p>\\n      <img src=\\'logo.jpg\\'>\\n   </div>\\n</div>\\n\\nIf we retrieve the stripped_string property of each tag in the parsed document tree, we will find that the two div tags and the p tag have two NavigableString objects, Hello and World. The <b> tag embeds world string, while <img> doesn\\'t have a text part.\\nThe following example fetches the text from each of the tags in the given HTML document \\nExample\\n\\nhtml = \"\"\"\\n<div id=\"outer\">\\n   <div id=\"inner\">\\n      <p>Hello<b>World</b></p>\\n      <img src=\\'logo.jpg\\'>\\n   </div>\\n</div>\\n\"\"\"\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nfor tag in soup.find_all():\\n   print (\"Tag: {} attributes: {} \".format(tag.name, tag.attrs))\\n   for txt in tag.stripped_strings:\\n      print (txt)\\n       \\n   print()\\n\\nOutput\\n\\nTag: div attributes: {\\'id\\': \\'outer\\'} \\nHello\\nWorld\\n\\nTag: div attributes: {\\'id\\': \\'inner\\'} \\nHello\\nWorld\\n\\nTag: p attributes: {} \\nHello\\nWorld\\n\\nTag: b attributes: {} \\nWorld\\n\\nTag: img attributes: {\\'src\\': \\'logo.jpg\\'}\\n\\nBeautiful Soup - Find all Headings\\nIn this chapter, we shall explore how to find all heading elements in a HTML document with BeautifulSoup. HTML defines six heading styles from H1 to H6, each with decreasing font size. Suitable tags are used for different page sections, such as main heading, heading for section, topic etc. Let us use the find_all() method in two different ways to extract all the heading elements in a HTML document.\\nWe shall use the following HTML script (saved as index.html) in the code examples in this chapter \\n\\n<html>\\n   <head>\\n      <title>BeautifulSoup - Scraping Headings</title>\\n   </head>\\n   <body>\\n      <h2>Scraping Headings</h2>\\n      <b>The quick, brown fox jumps over a lazy dog.</b>\\n      <h3>Paragraph Heading</h3>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      <h3>List heading</h3>\\n      <ul>\\n         <li>Junk MTV quiz graced by fox whelps.</li>\\n         <li>Bawds jog, flick quartz, vex nymphs.</li>\\n      </ul>\\n   </body>\\n</html>\\n\\nExample 1\\nIn this approach, we collect all the tags in the parsed tree, and check if the name of each tag is found in a list of all heading tags.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nheadings = [\\'h1\\',\\'h2\\',\\'h3\\', \\'h4\\', \\'h5\\', \\'h6\\']\\ntags = soup.find_all()\\nheads = [(tag.name, tag.contents[0]) for tag in tags if tag.name in headings]\\nprint (heads)\\n\\nHere, headings is a list of all heading styles h1 to h6. If the name of a tag is any of these, the tag and its contents are collected in a lists named heads.\\nOutput\\n\\n[(\\'h2\\', \\'Scraping Headings\\'), (\\'h3\\', \\'Paragraph Heading\\'), (\\'h3\\', \\'List heading\\')]\\n\\nExample 2\\nYou can pass a regex expression to the find_all() method. Take a look at the following regex.\\n\\nre.compile(\\'^h[1-6]$\\')\\n\\nThis regex finds all tags that start with h, have a digit after the h, and then end after the digit. Let use this as an argument to find_all() method in the code below \\n\\nfrom bs4 import BeautifulSoup\\nimport re\\n\\nfp = open(\\'index.html\\')\\n\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntags = soup.find_all(re.compile(\\'^h[1-6]$\\'))\\nprint (tags)\\n\\nOutput\\n\\n[<h2>Scraping Headings</h2>, <h3>Paragraph Heading</h3>, <h3>List heading</h3>]\\n\\nBeautiful Soup - Extract Title Tag\\nThe <title> tag is used to provide a text caption to the page that appears in the browser\\'s title bar. It is not a part of the main content of the web page. The title tag is always present inside the <head> tag.\\nWe can extract the contents of title tag by Beautiful Soup. We parse the HTML tree and obtain the title tag object.\\nExample\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <head>\\n      <Title>Python Libraries</title>\\n   </head>\\n   <body>\\n      <p Hello World</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html5lib\")\\n\\ntitle = soup.title\\nprint (title)\\n\\nOutput\\n\\n<title>Python Libraries</title>\\n\\nIn HTML, we can use title attribute with all tags. The title attribute gives additional information about an element. The information is works as a tooltip text when the mouse hovers over the element.\\nWe can extract the text of title attribute of each tag with following code snippet \\nExample\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p title=\\'parsing HTML and XML\\'>Beautiful Soup</p>\\n      <p title=\\'HTTP library\\'>requests</p>\\n      <p title=\\'URL handling\\'>urllib</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html5lib\")\\ntags = soup.find_all()\\nfor tag in tags:\\n   if tag.has_attr(\\'title\\'):\\n      print (tag.attrs[\\'title\\'])\\n\\nOutput\\n\\nparsing HTML and XML\\nHTTP library\\nURL handling\\n\\nBeautiful Soup - Extract Email IDs\\nTo Extract Email addresses from a web page is an important application a web scraping library such as BeautifulSoup. In any web page, the Email IDs usually appear in the href attribute of anchor <a> tag. The Email ID is written using mailto URL scheme. Many a times, the Email Address may be present in page content as a normal text (without any hyperlink). In this chapter, we shall use BeautifulSoup library to fetch Email IDs from HTML page, with simple techniques.\\nA typical usage of Email ID in href attribute is as below \\n\\n<a href = \"mailto:xyz@abc.com\">test link</a>\\n\\nIn the first example, we shall consider the following HTML document for extracting the Email IDs from the hyperlinks \\n\\n<html>\\n   <head>\\n      <title>BeautifulSoup - Scraping Email IDs</title>\\n   </head>\\n   <body>\\n      <h2>Contact Us</h2>\\n      <ul>\\n      <li><a href = \"mailto:sales@company.com\">Sales Enquiries</a></li>\\n      <li><a href = \"mailto:careers@company.com\">Careers</a></li>\\n      <li><a href = \"mailto:partner@company.com\">Partner with us</a></li>\\n      </ul>\\n   </body>\\n</html>\\n\\nHere\\'s the Python code that finds the Email Ids.  We collect all the <a> tags in the document, and check if the tag has href attribute. If true, the part of its value after 6th character is the email Id.\\n\\nfrom bs4 import BeautifulSoup\\nimport re\\nfp = open(\"contact.html\")\\nsoup = BeautifulSoup(fp, \"html.parser\")\\ntags = soup.find_all(\"a\")\\nfor tag in tags:\\n   if tag.has_attr(\"href\") and tag[\\'href\\'][:7]==\\'mailto:\\':\\n      print (tag[\\'href\\'][7:])\\n\\nFor the given HTML document, the Email IDs will be extracted as follows \\n\\nsales@company.com\\ncareers@company.com\\npartner@company.com\\n\\nIn the second example, we assume that the Email IDs appear anywhere in the text. To extract them, we use the regex searching mechanism. Regex is a complex character pattern. Python\\'s re module helps in processing the regex (Regular Expression) patterns. The following regex pattern is used for searching the email address \\n\\npat = r\\'[\\\\w.+-]+@[\\\\w-]+\\\\.[\\\\w.-]+\\'\\n\\nFor this exercise, we shall use the following HTML document, having Email IDs in <li>tags.\\n\\n<html>\\n   <head>\\n      <title>BeautifulSoup - Scraping Email IDs</title>\\n   </head>\\n   <body>\\n      <h2>Contact Us</h2>\\n      <ul>\\n      <li>Sales Enquiries: sales@company.com</a></li>\\n      <li>Careers: careers@company.com</a></li>\\n      <li>Partner with us: partner@company.com</a></li>\\n      </ul>\\n   </body>\\n</html>\\n\\nUsing the email regex, we\\'ll find the appearance of the pattern in each <li> tag string. Here is the Python code \\nExample\\n\\nfrom bs4 import BeautifulSoup\\nimport re\\n\\ndef isemail(s):\\n   pat = r\\'[\\\\w.+-]+@[\\\\w-]+\\\\.[\\\\w.-]+\\'\\n   grp=re.findall(pat,s)\\n   return (grp)\\n\\nfp = open(\"contact.html\")\\nsoup = BeautifulSoup(fp, \"html.parser\")\\ntags = soup.find_all(\\'li\\')\\n\\nfor tag in tags:\\n   emails = isemail(tag.string)\\n   if emails:\\n      print (emails)\\n\\nOutput\\n\\n[\\'sales@company.com\\']\\n[\\'careers@company.com\\']\\n[\\'partner@company.com\\']\\n\\nUsing the simple techniques described above, we can use BeautifulSoup to extract Email IDs from web pages.\\nBeautiful Soup - Scrape Nested Tags\\nThe arrangement of tags or elements in a HTML document is hierarchical nature. The tags are nested upto multiple levels. For example, the <head> and <body> tags are nested inside <html> tag. Similarly, one or more <li> tags may be inside a <ul> tag.  In this chapter, we shall find out how to scrape a tag that has one or more children tags nested in it.\\nLet us consider the following HTML document \\n\\n<div id=\"outer\">\\n   <div id=\"inner\">\\n      <p>Hello<b>World</b></p>\\n      <img src=\\'logo.jpg\\'>\\n   </div>\\n</div>\\n\\nIn this case, the two <div> tags and a <p> tag has one or more child elements nested inside. Whereas, the <img> and <b> tag donot have any children tags.\\nThe findChildren() method returns a ResultSet of all the children under a tag. So, if a tag doesn\\'t have any children, the ResultSet will be an empty list like []. \\nTaking this as a cue, the following code finds out the tags under each tag in the document tree and displays the list.\\nExample\\n\\nhtml = \"\"\"\\n   <div id=\"outer\">\\n      <div id=\"inner\">\\n         <p>Hello<b>World</b></p>\\n         <img src=\\'logo.jpg\\'>\\n      </div>\\n   </div>\\n\"\"\"\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nfor tag in soup.find_all():\\n   print (\"Tag: {} attributes: {}\".format(tag.name, tag.attrs))\\n   print (\"Child tags: \", tag.findChildren())\\n   print()\\n\\nOutput\\n\\nTag: div attributes: {\\'id\\': \\'outer\\'}\\nChild tags:  [<div id=\"inner\">\\n<p>Hello<b>World</b></p>\\n<img src=\"logo.jpg\"/>\\n</div>, <p>Hello<b>World</b></p>, <b>World</b>, <img src=\"logo.jpg\"/>]\\n\\nTag: div attributes: {\\'id\\': \\'inner\\'}\\nChild tags:  [<p>Hello<b>World</b></p>, <b>World</b>, <img src=\"logo.jpg\"/>]\\n\\nTag: p attributes: {}\\nChild tags:  [<b>World</b>]\\n\\nTag: b attributes: {}\\nChild tags:  []\\n\\nTag: img attributes: {\\'src\\': \\'logo.jpg\\'}\\nChild tags:  []\\n\\nBeautiful Soup - Parsing Tables\\nIn addition to a textual content, a HTML document may also have a structured data in the form of HTML tables. With Beautiful Soup, we can extract the tabular data in Python objects such as list or dictionary, if required store it in databases or spreadsheets, and perform processing. In this chapter, we shall parse HTML table using Beautiful Soup.\\nAlthough Beautiful Soup doesn\\'t any special function or method for extracting table data, we can achieve it by simple scraping techniques. Just like any table, say in SQL or spreadsheet, HTML table consists of rows and columns.\\nHTML has <table> tag to build a tabular structure. There are one or more nested <tr> tags one each for a row. Each row consists of <td> tags to hold the data in each cell of the row. First row usually is used for column headings, and the headings are placed in <th> tag instead of <td>\\nFollowing HTML script renders a simple table on the browser window \\n\\n<html>\\n   <body>\\n   <h2>Beautiful Soup - Parse Table</h2>\\n      <table border=\"1\">\\n         <tr>\\n            <th>Name</th>\\n            <th>Age</th>\\n            <th>Marks</th>\\n         </tr>\\n         <tr class=\\'data\\'>\\n            <td>Ravi</td>\\n            <td>23</td>\\n            <td>67</td>\\n         </tr>\\n         <tr class=\\'data\\'>\\n            <td>Anil</td>\\n            <td>27</td>\\n            <td>84</td>\\n         </tr>\\n      </table>\\n   </body>\\n</html>\\n\\nNote that, the appearance of data rows is customized with a CSS class data, in order to distinguish it from the header row.\\nWe shall now see how to parse the table data. First, we obtain the document tree in the BeautifulSoup object. Then collect all the column headers in a list.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(markup, \"html.parser\")\\n\\ntbltag = soup.find(\\'table\\')\\nheaders = []\\nheadings = tbltag.find_all(\\'th\\')\\nfor h in headings: headers.append(h.string)\\n\\nThe data row tags with class=\\'data\\' attribute following the header row are then fetched. A dictionary object with column header as key and corresponding value in each cell is formed and appended to a list of dict objects.\\n\\nrows = tbltag.find_all_next(\\'tr\\', {\\'class\\':\\'data\\'})\\ntrows=[]\\nfor i in rows:\\n   row = {}\\n   \\n   data = i.find_all(\\'td\\')\\n   n=0\\n   for j in data: \\n      \\n      row[headers[n]] = j.string\\n      n+=1\\n   trows.append(row)\\n\\nA list of dictionary objects is collected in trows. You can then use it for different purposes such as storing in a SQL table, saving as a JSON or pandas dataframe object.\\nThe complete code is given below \\n\\nmarkup = \"\"\"\\n<html>\\n\\t<body>\\n\\t   <p>Beautiful Soup - Parse Table</p>\\n\\t\\t<table>\\n\\t\\t\\t<tr>\\n\\t\\t\\t\\t<th>Name</th>\\n\\t\\t\\t\\t<th>Age</th>\\n\\t\\t\\t\\t<th>Marks</th>\\n\\t\\t\\t</tr>\\n\\t\\t\\t<tr class=\\'data\\'>\\n\\t\\t\\t\\t<td>Ravi</td>\\n\\t\\t\\t\\t<td>23</td>\\n\\t\\t\\t\\t<td>67</td>\\n\\t\\t\\t</tr>\\n\\t\\t\\t<tr class=\\'data\\'>\\n\\t\\t\\t\\t<td>Anil</td>\\n\\t\\t\\t\\t<td>27</td>\\n\\t\\t\\t\\t<td>84</td>\\n\\t\\t\\t</tr>\\n\\t\\t</table>\\n\\t</body>\\n</html>\\n\"\"\"\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(markup, \"html.parser\")\\n\\ntbltag = soup.find(\\'table\\')\\nheaders = []\\nheadings = tbltag.find_all(\\'th\\')\\nfor h in headings: headers.append(h.string)\\nprint (headers)\\n\\nrows = tbltag.find_all_next(\\'tr\\', {\\'class\\':\\'data\\'})\\ntrows=[]\\nfor i in rows:\\n   row = {}\\n   \\n   data = i.find_all(\\'td\\')\\n   n=0\\n   for j in data: \\n      \\n      row[headers[n]] = j.string\\n      n+=1\\n   trows.append(row)\\n\\nprint (trows)\\n\\nOutput\\n\\n[{\\'Name\\': \\'Ravi\\', \\'Age\\': \\'23\\', \\'Marks\\': \\'67\\'}, {\\'Name\\': \\'Anil\\', \\'Age\\': \\'27\\', \\'Marks\\': \\'84\\'}]\\n\\nBeautiful Soup - Selecting nth Child\\nHTML is characterized by the hierarchical order of tags. For example, the <html> tag encloses <body> tag, inside which there may be a <div> tag further may have <ul> and <li> elements nested respectively. The findChildren() method and .children property both return a ResultSet (list) of all the child tags directly under an element. By traversing the list, you can obtain the child located at a desired position, nth child.\\nThe code below uses the children property of a <div> tag in the HTML document. Since the return type of children property is a list iterator, we shall retrieve a Python list from it. We also need to remove the whitespaces and line breaks from the iterator. Once done, we can fetch the desired child. Here the child element with index 1 of the <div> tag is displayed.\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.div\\nchildren = tag.children\\nchildlist = [child for child in children if child not in [\\'\\\\n\\', \\' \\']]\\nprint (childlist[1])\\n\\nOutput\\n\\n<p>Python</p>\\n\\nTo use findChildren() method instead of children property, change the statement to\\n\\nchildren = tag.findChildren()\\n\\nThere will be no change in the output.\\nA more efficient approach toward locating nth child is with the select() method. The select() method uses CSS selectors to obtain required PageElements from the current element.\\nThe Soup and Tag objects support CSS selectors through their .css property, which is an interface to the CSS selector API. The selector implementation is handled by the Soup Sieve package, which gets installed along with bs4 package.\\nThe Soup Sieve package defines different types of CSS selectors, namely simple, compound and complex CSS selectors that are made up of one or more type selectors, ID selectors, class selectors. These selectors are defined in CSS language.\\nThere are pseudo class selectors as well in Soup Sieve. A CSS pseudo-class is a keyword added to a selector that specifies a special state of the selected element(s). We shall use :nth-child pseudo class selector in this example. Since we need to select a child from <div> tag at 2nd position, we shall pass :nthchild(2) to the select_one() method.\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.div\\n\\nchild = tag.select_one(\\':nth-child(2)\\')\\nprint (child)\\n\\nOutput\\n\\n<p>Python</p>\\n\\nWe get the same result as with the findChildren() method. Note that the child numbering starts with 1 and not 0 as in case of a Python list.\\nBeautiful Soup - Search by text inside a Tag\\nBeautiful Soup provides different means to search for a certain text in the given HTML document. Here, we use the string argument of the find() method for the purpose.\\nIn the following example, we use the find() method to search for the word \\'by\\'\\nExample\\n\\nhtml = \\'\\'\\'\\n   <p> The quick, brown fox jumps over a lazy dog.</p>\\n   <p> DJs flock by when MTV ax quiz prog.</p>\\n   <p> Junk MTV quiz graced by fox whelps.</p>\\n   <p> Bawds jog, flick quartz, vex nymphs./p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\ndef search(tag):\\n   if \\'by\\' in tag.text:\\n      return True\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.find(\\'p\\', string=search)\\nprint (tag)\\n\\nOutput\\n\\n<p> DJs flock by when MTV ax quiz prog.</p>\\nYou can find all occurrences of the word with find_all() method\\ntag = soup.find_all(\\'p\\', string=search)\\nprint (tag)\\n\\nOutput\\n\\n[<p> DJs flock by when MTV ax quiz prog.</p>, <p> Junk MTV quiz graced by fox whelps.</p>]\\n\\nThere may be a situation where the required text may be somewhere in a child tag deep inside the document tree. We need to first locate a tag which has no further elements and then check whether the required text is in it.\\nExample\\n\\nhtml = \\'\\'\\'\\n   <p> The quick, brown fox jumps over a lazy dog.</p>\\n   <p> DJs flock by when MTV ax quiz prog.</p>\\n   <p> Junk MTV quiz graced by fox whelps.</p>\\n   <p> Bawds jog, flick quartz, vex nymphs./p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntags = soup.find_all(lambda tag: len(tag.find_all()) == 0 and \"by\" in tag.text)\\nfor tag in tags:\\n   print (tag)\\n\\nOutput\\n\\n<p> DJs flock by when MTV ax quiz prog.</p>\\n<p> Junk MTV quiz graced by fox whelps.</p>\\n\\nBeautiful Soup - Remove HTML Tags\\nIn this chapter, let us see how we can remove all tags from a HTML document. HTML is a markup language, made up of predefined tags. A tag marks a certain text associated with it so that the browser renders it as per its predefined meaning. For example, the word Hello marked with <b> tag for example <b>Hello</b), is rendered in bold face by the browser.\\nIf we want to filter out the raw text between different tags in a HTML document, we can use any of the two methods - get_text() or extract() in Beautiful Soup library. \\nThe get_text() method collects all the raw text part from the document and returns a string. However, the original document tree is not changed.\\nIn the example below, the get_text() method removes all the HTML tags.\\nExample\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p> The quick, brown fox jumps over a lazy dog.</p>\\n      <p> DJs flock by when MTV ax quiz prog.</p>\\n      <p> Junk MTV quiz graced by fox whelps.</p>\\n      <p> Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntext = soup.get_text()\\nprint(text)\\n\\nOutput\\n\\nThe quick, brown fox jumps over a lazy dog.\\n DJs flock by when MTV ax quiz prog.\\n Junk MTV quiz graced by fox whelps.\\n Bawds jog, flick quartz, vex nymphs.\\n\\nNot that the soup object in the above example still contains the parsed tree of the HTML document.\\nAnother approach is to collect the string enclosed in a Tag object before extracting it from the soup object. In HTML, some tags don\\'t have a string property (we can say that tag.string is None for some tags such as <html> or <body>). So, we concatenate strings from all other tags to obtain the plain text out of the HTML document.\\nFollowing program demonstrates this approach.\\nExample\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      <p>Junk MTV quiz graced by fox whelps.</p>\\n      <p>Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntags = soup.find_all()\\n\\nstring=\\'\\'\\nfor tag in tags:\\n   #print (tag.name, tag.string)\\n   if tag.string != None:\\n      string=string+tag.string+\\'\\\\n\\'\\n   tag.extract()\\nprint (\"Document text after removing tags:\")\\nprint (string)\\nprint (\"Document:\")\\nprint (soup)\\n\\nOutput\\n\\nDocument text after removing tags:\\nThe quick, brown fox jumps over a lazy dog.\\nDJs flock by when MTV ax quiz prog.\\nJunk MTV quiz graced by fox whelps.\\nBawds jog, flick quartz, vex nymphs.\\n\\nDocument:\\n\\nThe clear() method removes the inner string of a tag object but doesn\\'t return it. Similarly the decompose() method destroys the tag as well as all its children elements. Hence, these methods are not suitable to retrieve the plain text from HTML document.\\nBeautiful Soup - Remove all Styles\\nThis chapter explains how to remove all styles from a HTML document. Cascaded style sheets (CSS) are used to control the appearance of different aspects of a HTML document. It includes styling the rendering of text with a specific font, color, alignment, spacing etc. CSS is applied to HTML tags in different ways.\\nOne is to define different styles in a CSS file and include in the HTML script with the <link> tag in the <head> section in the document. For example,\\nExample\\n\\n<html>\\n   <head>\\n      <link rel=\"stylesheet\" href=\"style.css\">\\n   </head>\\n   <body>\\n   . . .\\n   . . .\\n   </body>\\n</html>\\n\\nThe different tags in the body part of the HTML script will use the definitions in mystyle.css file\\nAnother approach is to define the style configuration inside the <head> part of the HTML document itself. Tags in the body part will be rendered by using the definitions provided internally.\\nExample of internal styling \\n\\n<html>\\n<head>\\n   <style>\\n      p {\\n         text-align: center;\\n         color: red;\\n      } \\n   </style>\\n</head>\\n   <body>\\n      <p>para1.</p>\\n      <p id=\"para1\">para2</p>\\n      <p>para3</p>\\n   </body>\\n</html>\\n\\nIn either cases, to remove the styles programmatically, simple remove the head tag from the soup object.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\nsoup.head.extract()\\n\\nThird approach is to define the styles inline by including style attribute in the tag itself. The style attribute may contain one or more style attribute definitions such as color, size etc. For example\\n\\n<body>\\n   <h1 style=\"color:blue;text-align:center;\">This is a heading</h1>\\n   <p style=\"color:red;\">This is a paragraph.</p>\\n</body>\\n\\nTo remove such inline styles from a HTML document, you need to check if attrs dictionary of a tag object has style key defined in it, and if yes delete the same.\\n\\ntags=soup.find_all()\\nfor tag in tags:\\n   if tag.has_attr(\\'style\\'):\\n      del tag.attrs[\\'style\\']\\nprint (soup)\\n\\nThe following code removes the inline styles as well as removes the head tag itself, so that the resultant HTML tree will not have any styles left.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <head>\\n      <link rel=\"stylesheet\" href=\"style.css\">\\n   </head>\\n   <body>\\n      <h1 style=\"color:blue;text-align:center;\">This is a heading</h1>\\n      <p style=\"color:red;\">This is a paragraph.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\nsoup.head.extract()\\n\\ntags=soup.find_all()\\nfor tag in tags:\\n   if tag.has_attr(\\'style\\'):\\n      del tag.attrs[\\'style\\']\\nprint (soup.prettify())\\n\\nOutput\\n\\n<html>\\n <body>\\n  <h1>\\n   This is a heading\\n  </h1>\\n  <p>\\n   This is a paragraph.\\n  </p>\\n </body>\\n</html>\\n\\nBeautiful Soup - Remove all Scripts\\nOne of the often used tags in HTML is the <script> tag. It facilitates embedding a client side script such as JavaScript code in HTML. In this chapter, we will use BeautifulSoup to remove script tags from the HTML document.\\nThe <script> tag has a corresponding </script> tag. In between the two, you may include either a reference to an external JavaScript file, or include JavaScript code inline with the HTML script itself.\\nTo include an external Javascript file, the syntax used is \\n\\n<head>\\n   <script src=\"javascript.js\"></script>\\n</head>\\n\\nYou can then invoke the functions defined in this file from inside HTML.\\nInstead of referring to an external file, you can put JavaScipt code inside the HTML within the <script> and </script> code. If it is put inside the <head> section of the HTML document, then the functionality is available throughout the document tree. On the other hand, if put anywhere in the <body> section, the JavaScript functions are available from that point on.\\n\\n<body>\\n   <p>Hello World</p>\\n   <script>\\n      alert(\"Hello World\")\\n   </script>\\n</body>\\n\\nTo remove all script tags with Beautiful is easy. You have to collect the list of all script tags from the parsed tree and extract them one by one.\\nExample\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <head>\\n      <script src=\"javascript.js\"></scrript>\\n   </head>\\n   <body>\\n      <p>Hello World</p>\\n      <script>\\n      alert(\"Hello World\")\\n      </script>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\n\\nfor tag in soup.find_all(\\'script\\'):\\n   tag.extract()\\n\\nprint (soup)\\n\\nOutput\\n\\n<html>\\n<head>\\n\\n</head>\\n</html>\\n\\nYou can also use the decompose() method instead of extract(), the difference being that  that the latter returns the thing that was removed, whereas the former just destroys it. For a more concise code, you may also use list comprehension syntax to achieve the soup object with script tags removed, as follows \\n\\n[tag.decompose() for tag in soup.find_all(\\'script\\')]\\n\\nBeautiful Soup - Remove Empty Tags\\nIn HTML, many of the tags have an opening and closing tag. Such tags are mostly used for defining the formatting properties, such as <b> and </b>, <h1> and </h1> etc. There are some self-closing tags also which don\\'t have a closing tag and no textual part. For example <img>, <br>, <input> etc. However, while composing HTML, tags such as <p></p> without any text may be inadvertently inserted. We need to remove such empty tags with the help of Beautiful Soup library functions.\\nRemoving textual tags without any text between opening and closing symbols is easy. You can call extract() method on a tag if length of its inner text is 0.\\n\\nfor tag in tags:\\n   if (len(tag.get_text(strip=True)) == 0):\\n      tag.extract()\\n\\nHowever, this would remove tags such as <hr>, <img>, and <input> etc. These are all self-closing or singleton tags. You would not like to close tags that have one or more attributes even if there is no text associated with it. So, you\\'ll have to check if a tag has any attributes and the get_text() returns none.\\nIn the following example, there are both situations where an empty textual tag and some singleton tags are present in the HTML string. The code retains the tags with attributes but removes ones without any text embedded.\\nExample\\n\\nhtml =\\'\\'\\'\\n<html>\\n   <body>\\n      <p>Paragraph</p>\\n      <embed type=\"image/jpg\" src=\"Python logo.jpg\" width=\"300\" height=\"200\">\\n      <hr>\\n      <b></b>\\n      <p>\\n      <a href=\"#\">Link</a>\\n      <ul>\\n      <li>One</li>\\n      </ul>\\n      <input type=\"text\" id=\"fname\" name=\"fname\">\\n      <img src=\"img_orange_flowers.jpg\" alt=\"Flowers\">\\n   </body>\\n\\'\\'\\'\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntags =soup.find_all()\\n\\nfor tag in tags:\\n   if (len(tag.get_text(strip=True)) == 0): \\n      if len(tag.attrs)==0:\\n         tag.extract()\\nprint (soup)\\n\\nOutput\\n\\n<html>\\n<body>\\n<p>Paragraph</p>\\n<embed height=\"200\" src=\"Python logo.jpg\" type=\"image/jpg\" width=\"300\"/>\\n\\n<p>\\n<a href=\"#\">Link</a>\\n<ul>\\n<li>One</li>\\n</ul>\\n<input id=\"fname\" name=\"fname\" type=\"text\"/>\\n<img alt=\"Flowers\" src=\"img_orange_flowers.jpg\"/>\\n</p>\\n</body>\\n</html>\\n\\nNote that the original html code has a <p> tag without its enclosing </p>. The parser automatically inserts the closing tag. The position of the closing tag may change if you change the parser to lxml or html5lib.\\nBeautiful Soup - Remove Child Elements\\nHTML document is a hierarchical arrangement of different tags, where a tag may have one or more tags nested in it at more than one level. How do we remove the child elements of a certain tag? With BeautifulSoup, it is very easy to do it.\\nThere are two main methods in BeautifulSoup library, to remove a certain tag. The decompose() method and extract() method, the difference being that  that the latter returns the thing that was removed, whereas the former just destroys it.\\nHence to remove the child elements, call findChildren() method for a given Tag object, and then extract() or decompose() on each.\\nConsider the following code segment \\n\\nsoup = BeautifulSoup(fp, \"html.parser\")\\nsoup.decompose()\\nprint (soup)\\n\\nThis will  destroy the entire soup object itself, which is the parsed tree of the document. Obviously, we would not like to do that.\\nNow the following code \\n\\nsoup = BeautifulSoup(fp, \"html.parser\")\\ntags = soup.find_all()\\nfor tag in tags:\\n   for t in tag.findChildren():\\n      t.extract() \\n\\nIn the document tree, <html> is the first tag, and all other tags are its children, hence it will remove all the tags except <html> and </html> in the first iteration of the loop itself.\\nMore effective use of this can be done if we want to remove the children of a specific tag. For example, you may want to remove the header row of a HTML table.\\nThe following HTML script ha a table with first <tr> element having headers marked by <th> tag.\\n\\n<html>\\n   <body>\\n      <h2>Beautiful Soup - Remove Child Elements</h2>\\n      <table border=\"1\">\\n         <tr class=\\'header\\'>\\n            <th>Name</th>\\n            <th>Age</th>\\n            <th>Marks</th>\\n         </tr>\\n         <tr>\\n            <td>Ravi</td>\\n            <td>23</td>\\n            <td>67</td>\\n         </tr>\\n         <tr>\\n            <td>Anil</td>\\n            <td>27</td>\\n            <td>84</td>\\n         </tr>\\n      </table>\\n   </body>\\n</html>\\n\\nWe can use the following Python code to remove all the children elements of <tr> tag with <th> cells.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \"html.parser\")\\ntags = soup.find_all(\\'tr\\', {\\'class\\':\\'header\\'})\\n\\nfor tag in tags:\\n   for t in tag.findChildren():\\n      t.extract()\\n\\nprint (soup)\\n\\nOutput\\n\\n<html>\\n<body>\\n<h2>Beautiful Soup - Parse Table</h2>\\n<table border=\"1\">\\n<tr class=\"header\">\\n\\n</tr>\\n<tr>\\n<td>Ravi</td>\\n<td>23</td>\\n<td>67</td>\\n</tr>\\n<tr>\\n<td>Anil</td>\\n<td>27</td>\\n<td>84</td>\\n</tr>\\n</table>\\n</body>\\n</html>\\n\\nIt can be seen that the <th> elements have been removed from the parsed tree\\nBeautiful Soup - find vs find_all\\nBeautiful Soup library includes find() as well as find_all() methods. Both methods are one of the most frequently used methods while parsing HTML or XML documents. From a particular document tree You often need to locate a PageElement of a certain tag type, or having certain attributes, or having a certain CSS style etc. These criteria are given as argument to both find() and find_all() methods. The main point of difference between the two is that while find() locates the very first child element that satisfies the criteria, find_all() method searches for all the children elements of the criteria.\\nThe find() method is defined with following syntax \\nSyntax\\n\\nfind(name, attrs, recursive, string, **kwargs)\\n\\nThe name argument specifies a filter on tag name. With attrs, a filter on tag attribute values can be set up. The recursive argument forces a recursive search if it is True. You can pass variable kwargs as dictionary of filters on attribute values.\\n\\nsoup.find(id = \\'nm\\')\\nsoup.find(attrs={\"name\":\\'marks\\'})\\n\\nThe find_all() method takes all the arguments as for the find() method, in addition there is a limit argument. It is an integer, restricting the search the specified number of occurrences of the given filter criteria. If not set, find_all() searches for the criteria among all the children under the said PageElement.\\n\\nsoup.find_all(\\'input\\')\\nlst=soup.find_all(\\'li\\', limit =2)\\n\\nIf the limit argument for find_all() method is set to 1, it virtually acts as find() method.\\nThe return type of both the methods differs. The find() method returns either a Tag object or a NavigableString object first found. The find_all() method returns a ResultSet consisting of all the PageElements satisfying the filter criteria.\\nHere is an example that demonstrates the difference between find and find_all methods.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nmarkup =open(\"index.html\")\\n\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\nret1 = soup.find(\\'input\\')\\nret2 = soup.find_all (\\'input\\')\\nprint (ret1, \\'Return type of find:\\', type(ret1))\\nprint (ret2)\\nprint (\\'Return tyoe find_all:\\', type(ret2))\\n\\n#set limit =1\\nret3 = soup.find_all (\\'input\\', limit=1)\\nprint (\\'find:\\', ret1)\\nprint (\\'find_all:\\', ret3)\\n\\nOutput\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/> Return type of find: <class \\'bs4.element.Tag\\'>\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>, <input id=\"age\" name=\"age\" type=\"text\"/>, <input id=\"marks\" name=\"marks\" type=\"text\"/>]\\nReturn tyoe find_all: <class \\'bs4.element.ResultSet\\'>\\nfind: <input id=\"nm\" name=\"name\" type=\"text\"/>\\nfind_all: [<input id=\"nm\" name=\"name\" type=\"text\"/>]\\n\\nBeautiful Soup - Specifying the Parser\\nA HTML document tree is parsed into an object of BeautifulSoup class. The constructor of this class needs the mandatory argument as the HTML string or a file object pointing to the html file. The constructor has all other optional arguments, important being features.\\n\\nBeautifulSoup(markup, features)\\n\\nHere markup is a HTML string or file object. The features parameter specifies the parser to be used. It may be a specific parser such as \"lxml\", \"lxml-xml\", \"html.parser\", or \"html5lib; or type of markup to be used (\"html\", \"html5\", \"xml\").\\nIf the features argument is not given, BeautifulSoup chooses the best HTML parser that\\'s installed. Beautiful Soup ranks lxml\\'s parser as being the best, then html5lib\\'s, then Python\\'s built-in parser.\\nYou can specify one of the following \\nThe type of markup you want to parse. Beautiful Soup currently supports are \"html\", \"xml\", and \"html5\".\\nThe name of the parser library to be used. Currently supported options are \"lxml\", \"html5lib\", and \"html.parser\" (Python\\'s built-in HTML parser).\\nTo install lxml or html5lib parser, use the command \\n\\npip3 install lxml\\npip3 install html5lib\\n\\nThese parsers have their advantages and disadvantages as shown below \\nParser: Python\\'s html.parser\\nUsage  BeautifulSoup(markup, \"html.parser\")\\nAdvantages\\n\\nBatteries included\\nDecent speed\\nLenient (As of Python 3.2)\\n\\nDisadvantages\\n\\nNot as fast as lxml, less lenient than html5lib.\\n\\nParser: lxml\\'s HTML parser\\nUsage  BeautifulSoup(markup, \"lxml\")\\nAdvantages\\n\\nVery fast\\nLenient\\n\\n\\nDisadvantages\\n\\nExternal C dependency\\n\\nParser: lxml\\'s XML parser\\nUsage  BeautifulSoup(markup, \"lxml-xml\")  Or BeautifulSoup(markup, \"xml\")\\nAdvantages\\n\\nVery fast\\nThe only currently supported XML parser\\n\\nDisadvantages\\n\\nExternal C dependency\\n\\nParser: html5lib\\nUsage  BeautifulSoup(markup, \"html5lib\")\\nAdvantages\\n\\nExtremely lenient\\nParses pages the same way a web browser does\\nCreates valid HTML5\\n\\nDisadvantages\\n\\nVery slow\\nExternal Python dependency\\n\\nDifferent parsers will create different parse trees from the same document. The biggest differences are between the HTML parsers and the XML parsers. Here\\'s a short document, parsed as HTML \\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<a><b /></a>\", \"html.parser\")\\nprint (soup)\\n\\nOutput\\n\\n<a><b></b></a>\\n\\nAn empty <b /> tag is not valid HTML. Hence the parser turns it into a <b></b> tag pair.\\nThe same document is now parsed as XML. Note that the empty <b /> tag is left alone, and that the document is given an XML declaration instead of being put into an <html> tag.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<a><b /></a>\", \"xml\")\\nprint (soup)\\n\\nOutput\\n\\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<a><b/></a>\\n\\nIn case of a perfectly-formed HTML document, all HTML parsers result in similar parsed tree though one parser will be faster than another.\\nHowever, if HTML document is not perfect, there will be different results by different types of parsers. See how the results differ when \"<a></p>\" is parsed with different parsers \\nlxml parser\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<a></p>\", \"lxml\")\\nprint (soup)\\n\\nOutput\\n\\n<html><body><a></a></body></html>\\n\\nNote that the dangling </p> tag is simply ignored.\\nhtml5lib parser\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<a></p>\", \"html5lib\")\\nprint (soup)\\n\\nOutput\\n\\n<html><head></head><body><a><p></p></a></body></html>\\n\\nThe html5lib pairs it with an opening <p> tag. This parser also adds an empty <head> tag to the document.\\nBuilt-in html parser\\nExample\\n\\nBuilt in from bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<a></p>\", \"html.parser\")\\nprint (soup)\\n\\nOutput\\n\\n<a></a>\\n\\nThis parser also ignores the closing </p> tag. But this parser makes no attempt to create a well-formed HTML document by adding a <body> tag, doesn\\'t even bother to add an <html> tag.\\nThe html5lib parser uses techniques that are part of the HTML5 standard, so it has the best claim on being the \"correct\" way.\\nBeautiful Soup - Comparing Objects\\nAs per the beautiful soup, two navigable string or tag objects are equal if they represent the same HTML/XML markup. \\nNow let us see the below example, where the two <b> tags are treated as equal, even though they live in different parts of the object tree, because they both look like \"<b>Java</b>\".\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nmarkup = \"<p>Learn <i>Python</i>, <b>Java</b>, advanced <i>Python</i> and advanced <b>Java</b>! from Tutorialspoint</p>\"\\nsoup = BeautifulSoup(markup, \"html.parser\")\\nb1 = soup.find(\\'b\\')\\nb2 = b1.find_next(\\'b\\')\\nprint(b1== b2)\\n\\nprint(b1 is b2)\\n\\nOutput\\n\\nTrue\\nFalse\\n\\nIn the following examples, tow NavigableString objects are compared.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nmarkup = \"<p>Learn <i>Python</i>, <b>Java</b>, advanced <i>Python</i> and advanced <b>Java</b>! from Tutorialspoint</p>\"\\nsoup = BeautifulSoup(markup, \"html.parser\")\\ni1 = soup.find(\\'i\\')\\ni2 = i1.find_next(\\'i\\')\\nprint(i1.string== i2.string)\\n\\nprint(i1.string is i2.string)\\n\\nOutput\\n\\nTrue\\nFalse\\n\\nBeautiful Soup - Copying Objects\\nTo create a copy of any tag or NavigableString, use copy() function from the copy module from Python\\'s standard library.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nimport copy\\n\\nmarkup = \"<p>Learn <b>Python, Java</b>, <i>advanced Python and advanced Java</i>! from Tutorialspoint</p>\"\\nsoup = BeautifulSoup(markup, \"html.parser\")\\ni1 = soup.find(\\'i\\')\\nicopy = copy.copy(i1)\\n\\nprint (icopy)\\n\\nOutput\\n\\n<i>advanced Python and advanced Java</i>\\n\\nAlthough the two copies (original and copied one) contain the same markup however, the two do not represent the same object.\\n\\nprint (i1 == icopy)\\nprint (i1 is icopy)\\n\\nOutput\\n\\nTrue\\nFalse\\n\\nThe copied object is completely detached from the original Beautiful Soup object tree, just as if extract() had been called on it.\\n\\nprint (icopy.parent)\\n\\nOutput\\n\\nNone\\n\\nBeautiful Soup - Get Tag Position\\nThe Tag object in Beautiful Soup possesses two useful properties that give the information about its position in the HTML document. They are \\nsourceline  line number at which the tag is found\\nsourcepos  The starting index of the tag in the line in which it is found.\\nThese properties are supported by the html.parser which is Python\\'s in-built parser and html5lib parser. They are not available when you are using lmxl parser.\\nIn the following example, a HTML string is parsed with html.parser and we find the line number and position of <p> tag in the HTML string.\\nExample\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>Web frameworks</p>\\n      <ul>\\n      <li>Django</li>\\n      <li>Flask</li>\\n      </ul>\\n      <p>GUI frameworks</p>\\n      <ol>\\n      <li>Tkinter</li>\\n      <li>PyQt</li>\\n      </ol>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\np_tags = soup.find_all(\\'p\\')\\nfor p in p_tags:\\n   print (p.sourceline, p.sourcepos, p.string)\\n\\nOutput\\n\\n4 0 Web frameworks\\n9 0 GUI frameworks\\n\\nFor html.parser, these numbers represent the position of the initial less-than sign, which is 0 in this example. It is slightly different when html5lib parser is used.\\nExample\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>Web frameworks</p>\\n      <ul>\\n      <li>Django</li>\\n      <li>Flask</li>\\n      </ul>\\n      <p>GUI frameworks</p>\\n      <ol>\\n      <li>Tkinter</li>\\n      <li>PyQt</li>\\n      </ol>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html5lib\\')\\n\\nli_tags = soup.find_all(\\'li\\')\\nfor l in li_tags:\\n   print (l.sourceline, l.sourcepos, l.string)\\n\\nOutput\\n\\n6 3 Django\\n7 3 Flask\\n11 3 Tkinter\\n12 3 PyQt\\n\\nWhen using html5lib, the sourcepos property returns the position of the final greater-than sign.\\nBeautiful Soup - Encoding\\nAll HTML or XML documents are written in some specific encoding like ASCII or UTF-8. However, when you load that HTML/XML document into BeautifulSoup, it has been converted to Unicode.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\nmarkup = \"<p>I will display </p>\"\\nsoup = BeautifulSoup(markup, \"html.parser\")\\nprint (soup.p)\\nprint (soup.p.string)\\n\\nOutput\\n\\n<p>I will display </p>\\nI will display \\n\\nAbove behavior is because BeautifulSoup internally uses the sub-library called Unicode, Dammit to detect a document\\'s encoding and then convert it into Unicode. \\nHowever, not all the time, the Unicode, Dammit guesses correctly. As the document is searched byte-by-byte to guess the encoding, it takes lot of time. You can save some time and avoid mistakes, if you already know the encoding by passing it to the BeautifulSoup constructor as from_encoding.\\nBelow is one example where the BeautifulSoup misidentifies, an ISO-8859-8 document as ISO-8859-7 \\nExample\\n\\nfrom bs4 import BeautifulSoup\\nmarkup = b\"<h1>\\\\xed\\\\xe5\\\\xec\\\\xf9</h1>\"\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\nprint (soup.h1)\\n\\nprint (soup.original_encoding)\\n\\nOutput\\n\\n<h1></h1>\\nISO-8859-7\\n\\nTo resolve above issue, pass it to BeautifulSoup using from_encoding \\nExample\\n\\nfrom bs4 import BeautifulSoup\\nmarkup = b\"<h1>\\\\xed\\\\xe5\\\\xec\\\\xf9</h1>\"\\nsoup = BeautifulSoup(markup, \"html.parser\", from_encoding=\"iso-8859-8\")\\nprint (soup.h1)\\n\\nprint (soup.original_encoding)\\n\\nOutput\\n\\n<h1></h1>\\niso-8859-8\\n\\nAnother new feature added from BeautifulSoup 4.4.0 is, exclude_encoding. It can be used, when you don\\'t know the correct encoding but sure that Unicode, Dammit is showing wrong result.\\n\\nsoup = BeautifulSoup(markup, exclude_encodings=[\"ISO-8859-7\"])\\n\\nOutput encoding\\nThe output from a BeautifulSoup is UTF-8 document, irrespective of the entered document to BeautifulSoup. Below a document, where the polish characters are there in ISO-8859-2 format.\\nExample\\n\\nmarkup = \"\"\"\\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\\n<HTML>\\n   <HEAD>\\n      <META HTTP-EQUIV=\"content-type\" CONTENT=\"text/html; charset=iso-8859-2\">\\n   </HEAD>\\n   <BODY>\\n                    \\n   </BODY>\\n</HTML>\\n\"\"\"\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(markup, \"html.parser\", from_encoding=\"iso-8859-8\")\\nprint (soup.prettify())\\n\\nOutput\\n\\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\\n<html>\\n   <head>\\n      <meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/>\\n   </head>\\n   <body>\\n                       \\n   </body>\\n</html>\\n\\nIn the above example, if you notice, the <meta> tag has been rewritten to reflect the generated document from BeautifulSoup is now in UTF-8 format.\\nIf you don\\'t want the generated output in UTF-8, you can assign the desired encoding in prettify().\\n\\nprint(soup.prettify(\"latin-1\"))\\n\\nOutput\\n\\nb\\'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\\\\n<html>\\\\n <head>\\\\n  <meta content=\"text/html; charset=latin-1\" http-equiv=\"content-type\"/>\\\\n </head>\\\\n <body>\\\\n       \\\\xf3         \\\\xd3   \\\\n </body>\\\\n</html>\\\\n\\'\\n\\nIn the above example, we have encoded the complete document, however you can encode, any particular element in the soup as if they were a python string \\n\\nsoup.p.encode(\"latin-1\")\\nsoup.h1.encode(\"latin-1\")\\n\\nOutput\\n\\nb\\'<p>My first paragraph.</p>\\'\\nb\\'<h1>My First Heading</h1>\\'\\n\\nAny characters that can\\'t be represented in your chosen encoding will be converted into numeric XML entity references. Below is one such example \\n\\nmarkup = u\"<b>\\\\N{SNOWMAN}</b>\"\\nsnowman_soup = BeautifulSoup(markup)\\ntag = snowman_soup.b\\nprint(tag.encode(\"utf-8\"))\\n\\nOutput\\n\\nb\\'<b>\\\\xe2\\\\x98\\\\x83</b>\\'\\n\\nIf you try to encode the above in \"latin-1\" or \"ascii\", it will generate \"&#9731\", indicating there is no representation for that.\\n\\nprint (tag.encode(\"latin-1\"))\\nprint (tag.encode(\"ascii\"))\\n\\nOutput\\n\\nb\\'<b></b>\\'\\nb\\'<b></b>\\'\\n\\nUnicode, Dammit\\nUnicode, Dammit is used mainly when the incoming document is in unknown format (mainly foreign language) and we want to encode in some known format (Unicode) and also we don\\'t need Beautifulsoup to do all this. \\nBeautiful Soup - Output Formatting\\nIf the HTML string given to BeautifulSoup constructor contains any of the HTML entities, they will be converted to Unicode characters. \\nAn HTML entity is a string that begins with an ampersand ( & ) and ends with a semicolon ( ; ). They are used to display reserved characters (which would otherwise be interpreted as HTML code). Some of the examples of HTML entities are \\n\\n\\n<\\nless than\\n&lt;\\n&#60;\\n\\n\\n>\\ngreater than\\n&gt;\\n&#62;\\n\\n\\n&\\nampersand\\n&amp;\\n&#38;\\n\\n\\n\"\\ndouble quote\\n&quot;\\n&#34;\\n\\n\\n\\'\\nsingle quote\\n&apos;\\n&#39;\\n\\n\\n\"\\nLeft Double quote\\n&ldquo;\\n&#8220;\\n\\n\\n\"\\nRight double quote\\n&rdquo;\\n&#8221;\\n\\n\\n\\nPound\\n&pound;\\n&#163;\\n\\n\\n\\nyen\\n&yen;\\n&#165;\\n\\n\\n\\neuro\\n&euro;\\n&#8364;\\n\\n\\n\\ncopyright\\n&copy;\\n&#169;\\n\\n\\nBy default, the only characters that are escaped upon output are bare ampersands and angle brackets. These get turned into \"&amp;\", \"&lt;\", and \"&gt;\"\\nFor others, they\\'ll be converted to Unicode characters.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"Hello World!\", \\'html.parser\\')\\nprint (str(soup))\\n\\nOutput\\n\\nHello \"World!\"\\n\\nIf you then convert the document to a bytestring, the Unicode characters will be encoded as UTF-8. You won\\'t get the HTML entities back \\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"Hello World!\", \\'html.parser\\')\\nprint (soup.encode())\\n\\nOutput\\n\\nb\\'Hello \\\\xe2\\\\x80\\\\x9cWorld!\\\\xe2\\\\x80\\\\x9d\\'\\n\\nTo change this behavior provide a value for the formatter argument to prettify() method. There are following possible values for the formatter.\\nformatter=\"minimal\"  This is the default. Strings will only be processed enough to ensure that Beautiful Soup generates valid HTML/XML\\nformatter=\"html\"  Beautiful Soup will convert Unicode characters to HTML entities whenever possible.\\nformatter=\"html5\"  it\\'s similar to formatter=\"html\", but Beautiful Soup will omit the closing slash in HTML void tags like \"br\"\\nformatter=None  Beautiful Soup will not modify strings at all on output. This is the fastest option, but it may lead to Beautiful Soup generating invalid HTML/XML\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nfrench = \"<p>Il a dit <<Sacr bleu!>></p>\"\\nsoup = BeautifulSoup(french, \\'html.parser\\')\\nprint (\"minimal: \")\\nprint(soup.prettify(formatter=\"minimal\"))\\nprint (\"html: \")\\nprint(soup.prettify(formatter=\"html\"))\\nprint (\"None: \")\\nprint(soup.prettify(formatter=None))\\n\\nOutput\\n\\nminimal: \\n<p>\\n Il a dit <<Sacr bleu!>>\\n</p>\\n\\nhtml:\\n<p>\\n Il a dit <<Sacr bleu!>>\\n</p>\\n\\nNone:\\n<p>\\n Il a dit <<Sacr bleu!>>\\n</p>\\n\\nIn addition, Beautiful Soup library provides formatter classes. You can pass an object of any of these classes as argument to prettify() method.\\nHTMLFormatter class  Used to customize the formatting rules for HTML documents.\\nXMLFormatter class  Used to customize the formatting rules for XML documents.\\nBeautiful Soup - Pretty Printing\\nTo display the entire parsed tree of an HTML document or the contents of a specific tag, you can use the print() function or call str() function as well.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<h1>Hello World</h1>\", \"lxml\")\\nprint (\"Tree:\",soup)\\nprint (\"h1 tag:\",str(soup.h1))\\n\\nOutput\\n\\nTree: <html><body><h1>Hello World</h1></body></html>\\nh1 tag: <h1>Hello World</h1>\\n\\nThe str() function returns a string encoded in UTF-8.\\nTo get a nicely formatted Unicode string, use Beautiful Soup\\'s prettify() method. It formats the Beautiful Soup parse tree so that there each tag is on its own separate line with indentation. It allows to you to easily visualize the structure of the Beautiful Soup parse tree.\\nConsider the following HTML string.\\n\\n<p>The quick, <b>brown fox</b> jumps over a lazy dog.</p>\\n\\nUsing the prettify() method we can better understand its structure \\n\\nhtml = \\'\\'\\'\\n   <p>The quick, <b>brown fox</b> jumps over a lazy dog.</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"lxml\")\\nprint (soup.prettify())\\n\\nOutput\\n\\n<html>\\n <body>\\n  <p>\\n   The quick,\\n   <b>\\n    brown fox\\n   </b>\\n   jumps over a lazy dog.\\n  </p>\\n </body>\\n</html>\\n\\nYou can call prettify() on on any of the Tag objects in the document.\\n\\nprint (soup.b.prettify())\\n\\nOutput\\n\\n<b>\\n brown fox\\n</b>\\n\\nThe prettify() method is for understanding the structure of the document. However, it should not be used to reformat it, as it adds whitespace (in the form of newlines), and changes the meaning of an HTML document.\\nHe prettify() method can optionally be provided formatter argument to specify the formatting to be used.\\nBeautiful Soup - NavigableString Class\\nOne of the main objects prevalent in Beautiful Soup API is the object of NavigableString class. It represents the string or text between the opening and closing counterparts of most of the HTML tags. For example, if <b>Hello</b> is the markup to be parsed, Hello is the NavigableString.\\nNavigableString class is subclassed from the PageElement class in bs4 package, as well as Python\\'s built-in str class. Hence, it inherits the PageElement methods such as find_*(), insert, append, wrap,unwrap methods as well as methods from str class such as upper, lower, find, isalpha etc.\\nThe constructor of this class takes a single argument, a str object.\\nExample\\n\\nfrom bs4 import NavigableString\\nnew_str = NavigableString(\\'world\\')\\n\\nYou can now use this NavigableString object to perform all kinds of operations on the parsed tree, such as append, insert, find etc.\\nIn the following example, we append the newly created NavigableString object to an existing Tab object.\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Hello</b>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.b \\nnew_str = NavigableString(\\'world\\')\\ntag.append(new_str)\\nprint (soup)\\n\\nOutput\\n\\n<b>Helloworld</b>\\n\\nNote that the NavigableString is a PageElement, hence it can be appended to the Soup object also. Check the difference if we do so.\\nExample\\n\\nnew_str = NavigableString(\\'world\\')\\nsoup.append(new_str)\\nprint (soup)\\n\\nOutput\\n\\n<b>Hello</b>world\\n\\nAs we can see, the string appears after the <b> tag.\\nBeautiful Soup offers a new_string() method. Create a new NavigableString associated with this BeautifulSoup object.\\nLet us new_string() method to create a NavigableString object, and add it to the PageElements.\\nExample\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Hello</b>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.b \\n\\nns=soup.new_string(\\' World\\')\\ntag.append(ns)\\nprint (tag)\\nsoup.append(ns)\\nprint (soup)\\n\\nOutput\\n\\n<b>Hello World</b>\\n<b>Hello</b> World\\n\\nWe find an interesting behaviour here. The NavigableString object is added to a tag inside the tree, as well as to the soup object itself. While the tag shows the appended string, but in the soup object, the text World is appended, but it doesn\\'t show in the tag. This is because the new_string() method creates a NavigableString associated with the Soup object.\\nBeautiful Soup - Convert Object to String\\nThe Beautiful Soup API has three main types of objects. The soup object, the Tag object, and the NavigableString object. Let us find out how we can convert each of these object to string. In Python, string is a str object.\\nAssuming that we have a following HTML document\\n\\nhtml = \\'\\'\\'\\n<p>Hello <b>World</b></p>\\n\\'\\'\\'\\n\\nLet us put this string as argument for BeautifulSoup constructor. The soup object is then typecast to string object with Python\\'s builtin str() function.\\nThe parsed tree of this HTML string will be constructed dpending upon which parser you use. The built-in html parser doesn\\'t add the <html> and <body> tags. \\nExample\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nprint (str(soup))\\n\\nOutput\\n\\n<p>Hello <b>World</b></p>\\n\\nOn the other hand, the html5lib parser constructs the tree after inserting the formal tags such as <html> and <body>\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(html, \\'html5lib\\')\\nprint (str(soup))\\n\\nOutput\\n\\n<html><head></head><body><p>Hello <b>World</b></p>\\n</body></html>\\n\\nThe Tag object has a string property that returns a NavigableString object.\\n\\ntag = soup.find(\\'b\\')\\nobj = (tag.string)\\nprint (type(obj),obj)\\n\\nOutput\\n\\nstring <class \\'bs4.element.NavigableString\\'> World\\n\\nThere is also a Text property defined for Tag object. It returns the text contained in the tag, stripping off all the inner tags and attributes.\\nIf the HTML string is \\n\\nhtml = \\'\\'\\'\\n   <p>Hello <div id=\\'id\\'>World</div></p>\\n\\'\\'\\'\\n\\nWe try to obtain the text property of <p> tag\\n\\ntag = soup.find(\\'p\\')\\nobj = (tag.text)\\nprint ( type(obj), obj)\\n\\nOutput\\n\\n<class \\'str\\'> Hello World\\n\\nYou can also use the get_text() method which returns a string representing the text inside the tag. The function is actually a wrapper arounf the text property as it also gets rid of inner tags and attributes, and returns a string\\n\\nobj = tag.get_text()\\nprint (type(obj),obj)\\n\\nOutput\\n\\n<class \\'str\\'> Hello World\\n\\nBeautiful Soup - Convert HTML to Text\\nOne of the important and a frequently required application of a web scraper such as Beautiful Soup library is to extract text from a HTML script. You may need to discard all the tags along with the attributes associated if any with each tag and separate out the raw text in the document. The get_text() method in Beautiful Soup is suitable for this purpose.\\nHere is a basic example demonstrating the usage of get_text() method. You get all the text from HTML document by removing all the HTML tags.\\nExample\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p> The quick, brown fox jumps over a lazy dog.</p>\\n      <p> DJs flock by when MTV ax quiz prog.</p>\\n      <p> Junk MTV quiz graced by fox whelps.</p>\\n      <p> Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntext = soup.get_text()\\nprint(text)\\n\\nOutput\\n\\nThe quick, brown fox jumps over a lazy dog.\\nDJs flock by when MTV ax quiz prog.\\nJunk MTV quiz graced by fox whelps.\\nBawds jog, flick quartz, vex nymphs.\\n\\nThe get_text() method has an optional separator argument. In the following example, we specify the separator argument of get_text() method as \\'#\\'.\\n\\nhtml = \\'\\'\\'\\n   <p>The quick, brown fox jumps over a lazy dog.</p>\\n   <p>DJs flock by when MTV ax quiz prog.</p>\\n   <p>Junk MTV quiz graced by fox whelps.</p>\\n   <p>Bawds jog, flick quartz, vex nymphs.</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntext = soup.get_text(separator=\\'#\\')\\nprint(text)\\n\\nOutput\\n\\n#The quick, brown fox jumps over a lazy dog.#\\n#DJs flock by when MTV ax quiz prog.#\\n#Junk MTV quiz graced by fox whelps.#\\n#Bawds jog, flick quartz, vex nymphs.#\\n\\nThe get_text() method has another argument strip, which can be True or False. Let us check the effect of strip parameter when it is set to True. By default it is False.\\n\\nhtml = \\'\\'\\'\\n   <p>The quick, brown fox jumps over a lazy dog.</p>\\n   <p>DJs flock by when MTV ax quiz prog.</p>\\n   <p>Junk MTV quiz graced by fox whelps.</p>\\n   <p>Bawds jog, flick quartz, vex nymphs.</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntext = soup.get_text(strip=True)\\nprint(text)\\n\\nOutput\\n\\nThe quick, brown fox jumps over a lazy dog.DJs flock by when MTV ax quiz prog.Junk MTV quiz graced by fox whelps.Bawds jog, flick quartz, vex nymphs.\\n\\nBeautiful Soup - Parsing XML\\nBeautifulSoup can also parse a XML document. You need to pass fatures=\\'xml\\' argument to Beautiful() constructor.\\nAssuming that we have the following books.xml in the current working directory \\nExample\\n\\n<?xml version=\"1.0\" ?>\\n<books>\\n   <book>\\n      <title>Python</title>\\n      <author>TutorialsPoint</author>\\n      <price>400</price>\\n   </book>\\n</books> \\n\\nThe following code parses the given XML file \\n\\nfrom bs4 import BeautifulSoup\\nfp = open(\"books.xml\")\\nsoup = BeautifulSoup(fp,  features=\"xml\")\\n\\nprint (soup)\\nprint (\\'type:\\', type(soup)) \\n\\nWhen the above code is executed, you should get the following result \\n\\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<books>\\n<book>\\n<title>Python</title>\\n<author>TutorialsPoint</author>\\n<price>400</price>\\n</book>\\n</books>\\ntype: <class \\'bs4.BeautifulSoup\\'> \\n\\nXML parser Error\\nBy default, BeautifulSoup package parses the documents as HTML, however, it is very easy-to-use and handle ill-formed XML in a very elegant manner using beautifulsoup4.\\nTo parse the document as XML, you need to have lxml parser and you just need to pass the \"xml\" as the second argument to the Beautifulsoup constructor \\n\\nsoup = BeautifulSoup(markup, \"lxml-xml\")\\n\\nor\\n\\nsoup = BeautifulSoup(markup, \"xml\")\\n\\nOne common XML parsing error is \\n\\nAttributeError: \\'NoneType\\' object has no attribute \\'attrib\\'\\n\\nThis might happen in case, some element is missing or not defined while using find() or findall() function.\\nBeautiful Soup - Error Handling\\nWhile trying to parse HTML/XML document with Beautiful Soup, you may encounter errors, not from your script but from the structure of the snippet because the BeautifulSoup API throws an error.\\nBy default, BeautifulSoup package parses the documents as HTML, however, it is very easy-to-use and handle ill-formed XML in a very elegant manner using beautifulsoup4.\\nTo parse the document as XML, you need to have lxml parser and you just need to pass the \"xml\" as the second argument to the Beautifulsoup constructor \\n\\nsoup = BeautifulSoup(markup, \"lxml-xml\")\\n\\nor\\n\\nsoup = BeautifulSoup(markup, \"xml\")\\n\\nOne common XML parsing error is \\n\\nAttributeError: \\'NoneType\\' object has no attribute \\'attrib\\'\\n\\nThis might happen in case, some element is missing or not defined while using find() or findall() function.\\nApart from the above mentioned parsing errors, you may encounter other parsing issues such as environmental issues where your script might work in one operating system but not in another operating system or may work in one virtual environment but not in another virtual environment or may not work outside the virtual environment. All these issues may be because the two environments have different parser libraries available. \\nIt is recommended to know or check your default parser in your current working environment. You can check the current default parser available for the current working environment or else pass explicitly the required parser library as second arguments to the BeautifulSoup constructor.\\nAs the HTML tags and attributes are case-insensitive, all three HTML parsers convert tag and attribute names to lowercase. However, if you want to preserve mixed-case or uppercase tags and attributes, then it is better to parse the document as XML.\\nUnicodeEncodeError\\nLet us look into below code segment \\nExample\\n\\nsoup = BeautifulSoup(response, \"html.parser\")\\n   print (soup)\\n\\nOutput\\n\\nUnicodeEncodeError: \\'charmap\\' codec can\\'t encode character \\'\\\\u011f\\'\\n\\nAbove problem may be because of two main situations. You might be trying to print out a unicode character that your console doesn\\'t know how to display. Second, you are trying to write to a file and you pass in a Unicode character that\\'s not supported by your default encoding.\\nOne way to resolve above problem is to encode the response text/character before making the soup to get the desired result, as follows \\n\\nresponseTxt = response.text.encode(\\'UTF-8\\')\\nKeyError: [attr]\\n\\nIt is caused by accessing tag[\\'attr\\'] when the tag in question doesn\\'t define the attr attribute. Most common errors are: \"KeyError: \\'href\\'\" and \"KeyError: \\'class\\'\". Use tag.get(\\'attr\\') if you are not sure attr is defined.\\n\\nfor item in soup.fetch(\\'a\\'):\\n   try:\\n      if (item[\\'href\\'].startswith(\\'/\\') or \"tutorialspoint\" in item[\\'href\\']):\\n      (...)\\n   except KeyError:\\n      pass # or some other fallback action\\n\\nAttributeError\\nYou may encounter AttributeError as follows \\n\\nAttributeError: \\'list\\' object has no attribute \\'find_all\\'\\n\\nThe above error mainly occurs because you expected find_all() return a single tag or string. However, soup.find_all returns a python list of elements. \\nAll you need to do is to iterate through the list and catch data from those elements.\\nTo avoid the above errors when parsing a result, that result will be bypassed to make sure that a malformed snippet isn\\'t inserted into the databases \\n\\nexcept(AttributeError, KeyError) as er:\\n   pass\\n\\nBeautiful Soup - Trouble Shooting\\nIf you run into problems while trying to parse a HTML/XML document, it is more likely because how the parser in use is interpreting the document. To help you locate and correct the problem, Beautiful Soup API provides a dignose() utility.\\nThe diagnose() method in Beautiful Soup is a diagnostic suite for isolating common problems. If you\\'re facing difficulty in understanding what Beautiful Soup is doing to a document, pass the document as argument to the diagnose() function. A report showing you how different parsers handle the document, and tell you if you\\'re missing a parser.\\nThe diagnose() method is defined in bs4.diagnose module. Its output starts with a message as follows \\nExample\\n\\ndiagnose(markup)\\n\\nOutput\\n\\nDiagnostic running on Beautiful Soup 4.12.2\\nPython version 3.11.2 (tags/v3.11.2:878ead1, Feb  7 2023, 16:38:35) [MSC v.1934 64 bit (AMD64)]\\nFound lxml version 4.9.2.0\\nFound html5lib version 1.1\\nTrying to parse your markup with html.parser\\nHere\\'s what html.parser did with the markup:\\n\\nIf it doesn\\'t find any of these parsers, a corresponding message also appears.\\n\\nI noticed that html5lib is not installed. Installing it may help.\\n\\nIf the HTML document fed to diagnose() method is perfectly formed, the parsed tree by any of the parsers will be identical. However if it is not properly formed, then different parser interprets differently. If you don\\'t get the tree as you anticipate, changing the parser might help.\\nSometimes, you may have chosen HTML parser for a XML document. The HTML parsers add all the HTML tags while parsing the document incorrectly. Looking at the output, you will realize the error and can help in correcting.\\nIf Beautiful Soup raises HTMLParser.HTMLParseError, try and change the parser. \\nparse errors are HTMLParser.HTMLParseError: malformed start tag and HTMLParser.HTMLParseError: bad end tag are both generated by Python\\'s built-in HTML parser library, and the solution is to install lxml or html5lib.\\nIf you encounter SyntaxError: Invalid syntax (on the line ROOT_TAG_NAME = \\'[document]\\'), it is caused by running an old Python 2 version of Beautiful Soup under Python 3, without converting the code.\\nThe ImportError with message No module named HTMLParser is because of an old Python 2 version of Beautiful Soup under Python 3.\\nWhile, ImportError: No module named html.parser - is caused by running the Python 3 version of Beautiful Soup under Python 2.\\nIf you get ImportError: No module named BeautifulSoup - more often than not, it is because of running Beautiful Soup 3 code on a system that doesn\\'t have BS3 installed. Or, by writing Beautiful Soup 4 code without knowing that the package name has changed to bs4.\\nFinally, ImportError: No module named bs4 - is due to the fact that you are trying a Beautiful Soup 4 code on a system that doesn\\'t have BS4 installed.\\nBeautiful Soup - Porting Old Code\\nYou can make the code from earlier version of Beautiful Soup compatible with the lates version by making following change in the import statement \\nExample\\n\\nfrom BeautifulSoup import BeautifulSoup\\n#becomes this:\\n\\nfrom bs4 import BeautifulSoup\\n\\nIf you get the ImportError \"No module named BeautifulSoup\", it means you\\'re trying to run Beautiful Soup 3 code, but you only have Beautiful Soup 4 installed. Similarly, If you get the ImportError \"No module named bs4\", because you\\'re trying to run Beautiful Soup 4 code, but you only have Beautiful Soup 3 installed.\\nBeautiful Soup 3 used Python\\'s SGMLParser, a module that has been removed in Python 3.0. Beautiful Soup 4 uses html.parser by default, but you can also use lxml or html5lib. \\nAlthough BS4 is mostly backwards-compatible with BS3, most of its methods have been deprecated and given new names for PEP 8 compliance. \\nHere are a few examples \\n\\nreplaceWith -> replace_with\\nfindAll -> find_all\\nfindNext -> find_next\\nfindParent -> find_parent\\nfindParents -> find_parents\\nfindPrevious -> find_previous\\ngetText -> get_text\\nnextSibling -> next_sibling\\npreviousSibling -> previous_sibling\\n\\nBeautiful Soup - contents Property\\nMethod Description\\nThe contents property is available with the Soup object as well as Tag object. It returns a list everything that is contained inside the object, all the immediate child elements and text nodes (i.e. Navigable String).\\nSyntax\\n\\nTag.contents\\n\\nReturn value\\nThe contents property returns a list of child elements and strings in the Tag/Soup object,.\\nExample 1\\nContents of a tag object \\n\\nfrom bs4 import BeautifulSoup\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p>\\n      <p>Python</p>\\n      <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.div\\nprint (tag.contents)\\n\\nOutput\\n\\n[\\'\\\\n\\', <p>Java</p>, \\'\\\\n\\', <p>Python</p>, \\'\\\\n\\', <p>C++</p>, \\'\\\\n\\']\\n\\nExample 2\\nContents of the entire document \\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\nprint (soup.contents)\\n\\nOutput\\n\\n[\\'\\\\n\\', <div id=\"Languages\">\\n<p>Java</p> <p>Python</p> <p>C++</p>\\n</div>, \\'\\\\n\\']\\n\\nExample 3\\nNote that a NavigableString object doesn\\'t have contents property. It throws AttributeError if we try to access the same.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.p\\ns=tag.contents[0]\\nprint (s.contents)\\n\\nOutput\\n\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\user\\\\BeautifulSoup\\\\2.py\", line 11, in <module>\\n    print (s.contents)\\n           ^^^^^^^^^^\\n  File \"C:\\\\Users\\\\user\\\\BeautifulSoup\\\\Lib\\\\site-packages\\\\bs4\\\\element.py\", line 984, in __getattr__\\n    raise AttributeError(\\nAttributeError: \\'NavigableString\\' object has no attribute \\'contents\\'\\n\\nBeautiful Soup - children Property\\nMethod Description\\nThe Tag object in Beautiful Soup library has children property. It returns a generator used to iterate over the immediate child elements and text nodes (i.e. Navigable String).\\nSyntax\\n\\nTag.children\\n\\nReturn value\\nThe property returns a generator with which you can iterate over direct children of the PageElement.\\nExample 1\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.div\\nchildren = tag.children\\nfor child in children:\\n   print (child)\\n\\nOutput\\n\\n<p>Java</p>\\n\\n<p>Python</p>\\n\\n<p>C++</p>\\n\\nExample 2\\nThe soup object too bears the children property.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\nchildren = soup.children\\nfor child in children:\\n   print (child)\\n\\nOutput\\n\\n<div id=\"Languages\">\\n<p>Java</p> <p>Python</p> <p>C++</p>\\n</div>\\n\\nExample 3\\nIn the following example, we append NavigableString objects to the <p> Tag and get the list of children.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\nsoup.p.extend([\\'and\\', \\'JavaScript\\'])\\nchildren = soup.p.children\\nfor child in children:\\n    print (child)\\n\\nOutput\\n\\nJava\\nand\\nJavaScript\\n\\nBeautiful Soup - string Property\\nMethod Description\\nIn Beautiful Soup, the soup and Tag object has a convenience property - string property. It returns a single string within a PageElement, Soup or Tag. If this element has a single string child, then a NavigableString corresponding to it is returned. If this element has one child tag,      return value is the \\'string\\' attribute of the child tag, and if element itself is a string, (with no children), then the string property returns None.\\nSyntax\\n\\nTag.string\\n\\nExample 1\\nThe following code has the HTML string with a <div> tag that encloses three <p> elements. We find the string property of first <p> tag.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.p\\n\\nnavstr = tag.string\\nprint (navstr, type(navstr))\\n\\nnav_str = str(navstr)\\nprint (nav_str, type(nav_str))\\n\\nOutput\\n\\nJava <class \\'bs4.element.NavigableString\\'>\\nJava <class \\'str\\'>\\n\\nThe string property returns a NavigableString. It can be cast to a regular Python string with str() function\\nExample 2\\nThe string property of an element with children elements inside, returns None. Check with the <div> tag.\\n\\ntag = soup.div\\n\\nnavstr = tag.string\\nprint (navstr)\\n\\nOutput\\n\\nNone\\n\\nBeautiful Soup - strings Property\\nMethod Description\\nFor any PageElement having more than one children, the inner text of each can be fetched by the strings property. Unlike the string property, strings handles the case when the element contains multiple children. The strings property returns a generator object. It yields a sequence of NavigableStrings corresponding to each of the child elements.\\nSyntax\\n\\nTag.strings\\n\\nExample 1\\nYou can retrieve the value od strings property for soup as well as a tag object. In the following example, the soup object\\'s stings property is checked.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\nprint ([string for string in soup.strings])\\n\\nOutput\\n\\n[\\'\\\\n\\', \\'\\\\n\\', \\'Java\\', \\' \\', \\'Python\\', \\' \\', \\'C++\\', \\'\\\\n\\', \\'\\\\n\\']\\n\\nNote the line breaks and white spaces in the list.We can remove them with stripped_strings property.\\nExample 2\\nWe now obtain a generator object returned by the strings property of <div> tag. With a loop, we print the strings.\\n\\ntag = soup.div\\n\\nnavstrs = tag.strings\\nfor navstr in navstrs:\\n   print (navstr)\\n\\nOutput\\n\\nJava\\n \\nPython\\n \\nC++\\n\\nNote that the line breaks and whiteapces have appeared in the output, which can be removed with stripped_strings property.\\nBeautiful Soup - stripped_strings Property\\nMethod Description\\nThe stripped_strings property of a Tag/Soup object gives the return similar to strings property, except for the fact that the extra line breaks and whitespaces are stripped off. Hence, it can be said that the stripped_strings property results in a generator of NavigableString objects of the inner elements belonging to the object in use.\\nSyntax\\n\\nTag.stripped_strings\\n\\nExample 1\\nIn the example below, the strings of all the elements in the document tree parsed in a BeautifulSoup object are displayed after applying the stripping.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\nprint ([string for string in soup.stripped_strings])\\n\\nOutput\\n\\n[\\'Java\\', \\'Python\\', \\'C++\\']\\n\\nCompared to the output of strings property, you can see that the line breaks and whitespaces are removed.\\nExample 2\\nHere we extract the NavigableStrings of each of the child elements under the <div> tag.\\n\\ntag = soup.div\\n\\nnavstrs = tag.stripped_strings\\nfor navstr in navstrs:\\n   print (navstr)\\n\\nOutput\\n\\nJava\\nPython\\nC++\\n\\nBeautiful Soup - descendants Property\\nMethod Description\\nWith the descendants property of a PageElement object in Beautiful Soup API you can traverse the list of all children under it. This property returns a generator object, with which the children elements can be retrieved in a breadth-first sequence.\\nWhile searching a tree structure, the Breadth-first traversal starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level.\\n\\nSyntax\\n\\ntag.descendants\\n\\nReturn value\\nThe descendants property returns a generator object.\\nExample 1\\nIn the code below, we have a HTML document with nested unordered list tags. We scrape through the children elements parsed in breadth-first manner.\\n\\nhtml = \\'\\'\\'\\n   <ul id=\\'outer\\'>\\n   <li class=\"mainmenu\">Accounts</li>\\n      <ul>\\n      <li class=\"submenu\">Anand</li>\\n      <li class=\"submenu\">Mahesh</li>\\n      </ul>\\n   <li class=\"mainmenu\">HR</li>\\n      <ul>\\n      <li class=\"submenu\">Anil</li>\\n      <li class=\"submenu\">Milind</li>\\n      </ul>\\n   </ul>\\n\\'\\'\\' \\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.find(\\'ul\\', {\\'id\\': \\'outer\\'})\\ntags = soup.descendants\\nfor desc in tags:\\n   print (desc)\\n\\nOutput\\n\\n<ul id=\"outer\">\\n<li class=\"mainmenu\">Accounts</li>\\n<ul>\\n<li class=\"submenu\">Anand</li>\\n<li class=\"submenu\">Mahesh</li>\\n</ul>\\n<li class=\"mainmenu\">HR</li>\\n<ul>\\n<li class=\"submenu\">Anil</li>\\n<li class=\"submenu\">Milind</li>\\n</ul>\\n</ul>\\n\\n<li class=\"mainmenu\">Accounts</li>\\nAccounts\\n<ul>\\n<li class=\"submenu\">Anand</li>\\n<li class=\"submenu\">Mahesh</li>\\n</ul>\\n\\n<li class=\"submenu\">Anand</li>\\nAnand\\n<li class=\"submenu\">Mahesh</li>\\nMahesh\\n\\n<li class=\"mainmenu\">HR</li>\\nHR\\n<ul>\\n<li class=\"submenu\">Anil</li>\\n<li class=\"submenu\">Milind</li>\\n</ul>\\n\\n<li class=\"submenu\">Anil</li>\\nAnil\\n<li class=\"submenu\">Milind</li>\\nMilind\\n\\nExample 2\\nIn the following example, we list out the descendants of <head> tag\\n\\nhtml = \"\"\"\\n<html><head><title>TutorialsPoint</title></head>\\n<body>\\n<p>Hello World</p>\\n\"\"\"\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.head\\nfor element in tag.descendants:\\n   print (element)\\n\\nOutput\\n\\n<title>TutorialsPoint</title>\\nTutorialsPoint\\n\\nBeautiful Soup - parent Property\\nMethod Description\\nThe parent property in BeautifulSoup library returns the immediate parent element of the said PegeElement. The type of the value returned by the parents property is a Tag object. For the BeautifulSoup object, its parent is a document object\\nSyntax\\n\\nElement.parent\\n\\nReturn value\\nThe parent property returns a Tag object. For Soup object, it returns document object\\nExample 1\\nThis example uses .parent property to find the immediate parent element of the first <p> tag in the example HTML string.\\n\\nhtml = \"\"\"\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <p>Hello World</p>\\n\"\"\"\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.p\\nprint (tag.parent.name)\\n\\nOutput\\n\\nbody\\n\\nExample 2\\nIn the following example, we see that the <title> tag is enclosed inside a <head> tag. Hence, the parent property for <title> tag returns the <head> tag.\\n\\nhtml = \"\"\"\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <p>Hello World</p>\\n\"\"\"\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.title\\nprint (tag.parent)\\n\\nOutput\\n\\n<head><title>TutorialsPoint</title></head>\\n\\nExample 3\\nThe behaviour of Python\\'s built-in HTML parser is a little different from html5lib and lxml parsers. The built-in parser doesn\\'t try to build a perfect document out of the string provided. It doesn\\'t add additional parent tags like body or html if they don\\'t exist in the string. On the other hand, html5lib and lxml parsers add these tags to make the document a perfect HTML document.\\n\\nhtml = \"\"\"\\n<p><b>Hello World</b></p>\\n\"\"\"\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nprint (soup.p.parent.name)\\n\\nsoup = BeautifulSoup(html, \\'html5lib\\')\\nprint (soup.p.parent.name)\\n\\nOutput\\n\\n[document]\\nBody\\n\\nAs the HTML parser doesn\\'t add additional tags, the parent of parsed soup is document object. However, when we use html5lib, the parent tag\\'s name property is Body.\\nBeautiful Soup - parents Property\\nMethod Description\\nThe parents property in BeautifulSoup library retrieves all the parent elements of the said PegeElement in a recursive manner. The type of the value returned by the parents property is a generator, with the help of which we can list out the parents in the down-to-up order.\\nSyntax\\n\\nElement.parents\\n\\nReturn value\\nThe parents property returns a generator object.\\nExample 1\\nThis example uses .parents to travel from an <a> tag buried deep within the document, to the very top of the document. In the following code, we track the parents of the first <p> tag in the example HTML string.\\n\\nhtml = \"\"\"\\n<html><head><title>TutorialsPoint</title></head>\\n<body>\\n<p>Hello World</p>\\n\"\"\"\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.p\\nfor element in tag.parents:\\n   print (element.name)\\n\\nOutput\\n\\nbody\\nhtml\\n[document]\\n\\nNote that the parent to the BeautifulSoup object is [document].\\nExample 2\\nIn the following example, we see that the <b> tag is enclosed inside a <p> tag. The two div tags above it have an id attribute. We try to print the only those elements having id attribute. The has_attr() method is used for the purpose.\\n\\nhtml = \"\"\"\\n<div id=\"outer\">\\n<div id=\"inner\">\\n<p>Hello<b>World</b></p>\\n</div>\\n</div>\\n\"\"\"\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.b\\nfor parent in tag.parents:\\n   if parent.has_attr(\"id\"):\\n      print(parent[\"id\"])   \\n\\nOutput\\n\\ninner\\nouter\\n\\nBeautiful Soup - next_sibling Property\\nMethod Description\\nThe HTML tags appearing at the same indentation level are called siblings. The next_sibling property of the PageElement returns next tag at the same level, or under the same parent.\\nSyntax\\n\\nelement.next_sibling\\n\\nReturn type\\nThe next_sibling property returns a PageElement, a Tag or a NavigableString object.\\nExample 1\\nThe index.html wage page consists of a HTML form with three input elements each with a name attribute. In the following example, the next sibling of an input tag with name attribute as nm is located.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.find(\\'input\\', {\\'name\\':\\'age\\'})\\nprint (tag.find_previous())\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.find(\\'input\\', {\\'id\\':\\'nm\\'})\\nsib = tag.next_sibling\\nprint (sib)\\n\\nOutput\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nExample 2\\nIn the next example, we have a HTML document with a couple of tags inside a <p> tag. The next_sibling property returns the tag next to <b> tag in it.\\n\\nfrom bs4 import BeautifulSoup \\n\\nsoup = BeautifulSoup(\"<p><b>Hello</b><i>Python</i></p>\", \\'html.parser\\')\\n\\ntag1 = soup.b \\nprint (\"next:\",tag1.next_sibling)\\n\\nOutput\\n\\nnext: <i>Python</i>\\n\\nExample 3\\nConsider the HTML string in the following document. It has two <p> tags at the same level. The next_sibling of first <p> should give the second <p> tag\\'s contents.\\n\\nhtml = \\'\\'\\'\\n<p><b>Hello</b><i>Python</i></p>\\n<p>TutorialsPoint</p>\\n\\'\\'\\'\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag1 = soup.p\\nprint (\"next:\",tag1.next_sibling)\\n\\nOutput\\n\\nnext:\\n\\nThe blank line after the word next: is unexpected. But that\\'s because of the \\\\n character after the first <p> tag. Change the print statement as shown below to obtain the contents of the next_sibling\\n\\ntag1 = soup.p\\nprint (\"next:\",tag1.next_sibling.next_sibling)\\n\\nOutput\\n\\nnext: <p>TutorialsPoint</p>\\n\\nBeautiful Soup - previous_sibling Property\\nMethod Description\\nThe HTML tags appearing at the same indentation level are called siblings. The previous_sibling property of the PageElement returns a previous tag (a tag appearing before the current tag) at the same level, or under the same parent. This property encapsulates the find_previous_sibling() method.\\nSyntax\\n\\nelement.previous_sibling\\n\\nReturn type\\nThe previous_sibling property returns a PageElement, a Tag or a NavigableString object.\\nExample 1\\nIn the following code, the HTML string consists of two adjacent tags inside a <p> tag. It shows the sibling tag for <b> tag appearing before it.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(\"<p><b>Hello</b><i>Python</i></p>\", \\'html.parser\\')\\ntag = soup.i\\nsibling = tag.previous_sibling\\nprint (sibling)\\n\\nOutput\\n\\n<b>Hello</b>\\n\\nExample 2\\nWe are using the index.html file for parsing. The page contains a HTML form with three input elements. Which element is a previous sibling of input element with its id attribute as age? The following code shows it \\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.find(\\'input\\', {\\'id\\':\\'age\\'})\\nsib = tag.previous_sibling.previous_sibling\\nprint (sib)\\n\\nOutput\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nExample 3\\nFirst we find the <p> tag containing the string \\'Tutorial\\' and then fins a tag previous to it.\\n\\nhtml = \\'\\'\\'\\n<p>Excellent</p><p>Python</p><p>Tutorial</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag = soup.find(\\'p\\', string=\\'Tutorial\\')\\nprint (tag.previous_sibling)\\n\\nOutput\\n\\n<p>Python</p>\\n\\nBeautiful Soup - next_siblings Property\\nMethod Description\\nThe HTML tags appearing at the same indentation level are called siblings. The next_siblings property in Beautiful Soup returns returns a generator object used to iterate over all the subsequent tags and strings under the same parent.\\nSyntax\\n\\nelement.next_siblings\\n\\nReturn type\\nThe next_siblings property returns a generator of sibling PageElements.\\nExample 1\\nIn HTML form code in index.html contains three input elements. Following script uses next_siblings property to collect next siblings of an input element wit id attribute as nm\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.find(\\'input\\', {\\'id\\':\\'nm\\'})\\nsiblings = tag.next_siblings\\nprint (list(siblings))\\n\\nOutput\\n\\n[\\'\\\\n\\', <input id=\"age\" name=\"age\" type=\"text\"/>, \\'\\\\n\\', <input id=\"marks\" name=\"marks\" type=\"text\"/>, \\'\\\\n\\']\\n\\nExample 2\\nLet us use the following HTML snippet for this purpose \\nUse the following code to traverse next siblings tags.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p><b>Excellent</b><i>Python</i><u>Tutorial</u></p>\", \\'html.parser\\')\\n\\ntag1 = soup.b \\nprint (\"next siblings:\")\\nfor tag in tag1.next_siblings:\\n   print (tag)\\n\\nOutput\\n\\nnext siblings:\\n<i>Python</i>\\n<u>Tutorial</u>\\n\\nExample 3\\nNext example shows that the <head> tag has only one next sibling in the form of body tag.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <head>\\n      <title>Hello</title>\\n   </head>\\n   <body>\\n      <p>Excellent</p><p>Python</p><p>Tutorial</p>\\n   </body>\\n   </head>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntags = soup.head.next_siblings\\nprint (\"next siblings:\")\\nfor tag in tags:\\n   print (tag)\\n\\nOutput\\n\\nnext siblings:\\n\\n<body>\\n<p>Excellent</p><p>Python</p><p>Tutorial</p>\\n</body>\\n\\nThe additional lines are because of the linebreaks in the generator.\\nBeautiful Soup - previous_siblings Property\\nMethod Description\\nThe HTML tags appearing at the same indentation level are called siblings. The previous_siblings property in Beautiful Soup returns returns a generator object used to iterate over all the tags and strings before the current tag, under the same parent. This gives he similar output as find_previous_siblings() method.\\nSyntax\\n\\nelement.previous_siblings\\n\\nReturn type\\nThe previous_siblings property returns a generator of sibling PageElements.\\nExample 1\\nThe following example parses the given HTML string that has a few tags embedded inside the outer <p> tag. The previous siblings of the <u> tag are fetched with the help of previous_siblings property.\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(\"<p><b>Excellent</b><i>Python</i><u>Tutorial</u></p>\", \\'html.parser\\')\\n\\ntag1 = soup.u\\nprint (\"previous siblings:\")\\nfor tag in tag1.previous_siblings:\\n   print (tag)\\n\\nOutput\\n\\nprevious siblings:\\n<i>Python</i>\\n<b>Excellent</b>\\n\\nExample 2\\nIn the index.html file used in the following example, there are three input elements in the HTML form. We find out what are the sibling tags previous to the one with id set as marks, and under the <form> tag.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.find(\\'input\\', {\\'id\\':\\'marks\\'})\\nsibs = tag.previous_siblings\\nprint (\"previous siblings:\")\\nfor sib in sibs:\\n   print (sib)\\n\\nOutput\\n\\nprevious siblings:\\n\\n<input id=\"age\" name=\"age\" type=\"text\"/>\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nExample 3\\nThe top level <html> tag always has two sibling tags - head and body. Hence, the <body> tag has only one previous sibling i.e. head, as the following code shows \\n\\nhtml = \\'\\'\\'\\n<html>\\n   <head>\\n      <title>Hello</title>\\n   </head>\\n   <body>\\n      <p>Excellent</p><p>Python</p><p>Tutorial</p>\\n   </body>\\n   </head>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntags = soup.body.previous_siblings\\nprint (\"previous siblings:\")\\nfor tag in tags:\\n   print (tag)\\n\\nOutput\\n\\nprevious siblings:\\n\\n<head>\\n<title>Hello</title>\\n</head>\\n\\nBeautiful Soup - next_element Property\\nMethod Description\\nIn Beautiful Soup library, the next_element property returns the Tag or NavigableString that appears immediately next to the current PageElement, even if it is out of the parent tree. There is also a next property which has similar behaviour\\nSyntax\\n\\nElement.next_element\\n\\nReturn value\\nThe next_element and next properties return a tag or a NavigableString appearing immediately next to the current tag.\\nExample 1\\nIn the document tree parsed from the given HTML string, we find the next_element of the <b> tag\\n\\nhtml = \\'\\'\\'\\n<p><b>Excellent</b><p>Python</p><p id=\\'id1\\'>Tutorial</p></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'lxml\\')\\ntag = soup.b \\nprint (tag)\\nnxt = tag.next_element\\nprint (\"Next:\",nxt)\\n\\nnxt = tag.next_element.next_element\\nprint (\"Next:\",nxt)\\n\\nOutput\\n\\n<b>Excellent</b>\\nNext: Excellent\\nNext: <p>Python</p>\\n\\nThe output is a little strange as the next element for <b>Excellent</b> is shown to be \\'Excellent\\', that is because the inner string is registered as the next element. To obtain the desired result (<p>Python</p>) as the next element, fetch the next_element property of the inner NavigableString object.\\nExample 2\\nThe BeautifulSoup PageElements also support next property which is analogous to next_element property\\n\\nhtml = \\'\\'\\'\\n<p><b>Excellent</b><p>Python</p><p id=\\'id1\\'>Tutorial</p></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(html, \\'lxml\\')\\ntag = soup.b \\nprint (tag)\\nnxt = tag.next\\nprint (\"Next:\",nxt)\\n\\nnxt = tag.next.next\\nprint (\"Next:\",nxt)\\n\\nOutput\\n\\n<b>Excellent</b>\\nNext: Excellent\\nNext: <p>Python</p>\\n\\nExample 3\\nIn the next example, we try to determine the element next to <body> tag. As it is followed by a line break (\\\\n), we need to find the next element of the one next to body tag. It happens to be <h1> tag.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.find(\\'body\\')\\nnxt = tag.next_element.next\\nprint (\"Next:\",nxt)\\n\\nOutput\\n\\nNext: <h1>TutorialsPoint</h1>\\n\\nBeautiful Soup - previous_element Property\\nMethod Description\\nIn Beautiful Soup library, the previous_element property returns the Tag or NavigableString that appears immediately prior to the current PageElement, even if it is out of the parent tree. There is also a previous property which has similar behaviour\\nSyntax\\n\\nElement.previous_element\\n\\nReturn value\\nThe previous_element and previous properties return a tag or a NavigableString appearing immediately before the current tag.\\nExample 1\\nIn the document tree parsed from the given HTML string, we find the previous_element of the <p id=\\'id1\\'> tag\\n\\nhtml = \\'\\'\\'\\n<p><b>Excellent</b><p>Python</p><p id=\\'id1\\'>Tutorial</p></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'lxml\\')\\ntag = soup.find(\\'p\\', id=\\'id1\\')\\nprint (tag)\\npre = tag.previous_element\\nprint (\"Previous:\",pre)\\n\\npre = tag.previous_element.previous_element\\nprint (\"Previous:\",pre)\\n\\nOutput\\n\\n<p id=\"id1\">Tutorial</p>\\nPrevious: Python\\nPrevious: <p>Python</p>\\n\\nThe output is a little strange as the previous element for shown to be \\'Python, that is because the inner string is registered as the previous element. To obtain the desired result (<p>Python</p>) as the previous element, fetch the previous_element property of the inner NavigableString object.\\nExample 2\\nThe BeautifulSoup PageElements also supports previous property which is analogous to previous_element property\\n\\nhtml = \\'\\'\\'\\n<p><b>Excellent</b><p>Python</p><p id=\\'id1\\'>Tutorial</p></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'lxml\\')\\ntag = soup.find(\\'p\\', id=\\'id1\\')\\nprint (tag)\\npre = tag.previous\\nprint (\"Previous:\",pre)\\n\\npre = tag.previous.previous\\nprint (\"Previous:\",pre)\\n\\nOutput\\n\\n<p id=\"id1\">Tutorial</p>\\nPrevious: Python\\nPrevious: <p>Python</p>\\n\\nExample 3\\nIn the next example, we try to determine the element next to <input> tag whose id attribute is \\'age\\'\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html5lib\\')\\n\\ntag = soup.find(\\'input\\', id=\\'age\\')\\npre = tag.previous_element.previous\\nprint (\"Previous:\",pre)\\n\\nOutput\\n\\nPrevious: <input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nBeautiful Soup - next_elements Property\\nMethod Description\\nIn Beautiful Soup library, the next_elements property returns a generator object containing the next strings or tags in the parse tree.\\nSyntax\\n\\nElement.next_elements\\n\\nReturn value\\nThe next_elements property returns a generator.\\nExample 1\\nThe next_elements property returns tags and NavibaleStrings appearing after the <b> tag in the document string below \\n\\nhtml = \\'\\'\\'\\n<p><b>Excellent</b><p>Python</p><p id=\\'id1\\'>Tutorial</p></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.find(\\'b\\')\\n\\nnexts = tag.next_elements\\nprint (\"Next elements:\")\\nfor next in nexts:\\n   print (next)\\n\\nOutput\\n\\nNext elements:\\nExcellent\\nPython\\nPython\\n<p id=\"id1\">Tutorial</p>\\nTutorial\\n\\nExample 2\\nAll the elements appearing after the <p> tag are listed below \\n\\nfrom bs4 import BeautifulSoup\\n\\nhtml = \\'\\'\\'\\n   <p>\\n   <b>Excellent</b><i>Python</i>\\n   </p>\\n   <u>Tutorial</u>\\n\\'\\'\\'\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag1 = soup.find(\\'p\\')\\nprint (\"Next elements:\")\\nprint (list(tag1.next_elements))\\n\\nOutput\\n\\nNext elements:\\n[\\'\\\\n\\', <b>Excellent</b>, \\'Excellent\\', <i>Python</i>, \\'Python\\', \\'\\\\n\\', \\'\\\\n\\', <u>Tutorial</u>, \\'Tutorial\\', \\'\\\\n\\']\\n\\nExample 3\\nThe elements next to the input tag present in the HTML form of index.html are listed below \\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html5lib\\')\\n\\ntag = soup.find(\\'input\\')\\nnexts = soup.previous_elements\\nprint (\"Next elements:\")\\nfor next in nexts:\\n   print (next)\\n\\nOutput\\n\\nNext elements:\\n\\n<input id=\"age\" name=\"age\" type=\"text\"/>\\n\\n<input id=\"marks\" name=\"marks\" type=\"text\"/>\\n\\nBeautiful Soup - previous_elements Property\\nMethod Description\\nIn Beautiful Soup library, the previous_elements property returns a generator object containing the previous strings or tags in the parse tree.\\nSyntax\\n\\nElement.previous_elements\\n\\nReturn value\\nThe previous_elements property returns a generator.\\nExample 1\\nThe previous_elements property returns tags and NavibaleStrings appearing before the <p> tag in the document string below \\n\\nhtml = \\'\\'\\'\\n<p><b>Excellent</b><p>Python</p><p id=\\'id1\\'>Tutorial</p></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.find(\\'p\\', id=\\'id1\\')\\n\\npres = tag.previous_elements\\nprint (\"Previous elements:\")\\nfor pre in pres:\\n   print (pre)\\n\\nOutput\\n\\nPrevious elements:\\nPython\\n<p>Python</p>\\nExcellent\\n<b>Excellent</b>\\n<p><b>Excellent</b><p>Python</p><p id=\"id1\">Tutorial</p></p>\\n\\nExample 2\\nAll the elements appearing before the <u> tag are listed below \\n\\nfrom bs4 import BeautifulSoup\\n\\nhtml = \\'\\'\\'\\n<p>\\n<b>Excellent</b><i>Python</i>\\n</p>\\n<u>Tutorial</u>\\n\\'\\'\\'\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag1 = soup.find(\\'u\\')\\nprint (\"previous elements:\")\\nprint (list(tag1.previous_elements))\\n\\nOutput\\n\\nprevious elements:\\n[\\'\\\\n\\', \\'\\\\n\\', \\'Python\\', <i>Python</i>, \\'Excellent\\', <b>Excellent</b>, \\'\\\\n\\', <p>\\n<b>Excellent</b><i>Python</i>\\n</p>, \\'\\\\n\\']\\n\\nExample 3\\nThe BeautifulSoup object itself doesn\\'t have any previous elements \\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html5lib\\')\\n\\ntag = soup.find(\\'input\\', id=\\'marks\\')\\npres = soup.previous_elements\\nprint (\"Previous elements:\")\\nfor pre in pres:\\n   print (pre.name)\\n\\nOutput\\n\\nPrevious elements:\\n\\nBeautiful Soup - find() Method\\nMethod Description\\nThe find() method in Beautiful Soup looks for the first Element that matches the given criteria in the children of this PageElement and returns it.\\nSyntax\\n\\nSoup.find(name, attrs, recursive, string, **kwargs)\\n\\nParameters\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nrecursive  If this is True, find() a recursive search will be performed. Otherwise, only the direct children will be considered.\\nlimit  Stop looking after specified number of occurrences have been found.\\nkwargs  A dictionary of filters on attribute values.\\nReturn value\\nThe find() method returns Tag object or a NavigableString object\\nExample 1\\nLet us use the following HTML script (as index.html) for the purpose\\n\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <form>\\n      <input type = \\'text\\' id = \\'nm\\' name = \\'name\\'>\\n      <input type = \\'text\\' id = \\'age\\' name = \\'age\\'>\\n      <input type = \\'text\\' id = \\'marks\\' name = \\'marks\\'>\\n      </form>\\n   </body>\\n</html>\\n\\nThe following Python code finds the element with its id as nm\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\nobj = soup.find(id = \\'nm\\')\\nprint (obj)\\n\\nOutput\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nExample 2\\nThe find() method returns the first tag in the parsed document that has the given attributes.\\n\\nobj = soup.find(attrs={\"name\":\\'marks\\'})\\n\\nOutput\\n\\n<input id=\"marks\" name=\"marks\" type=\"text\"/>\\n\\nExample 3\\nIf find() can\\'t find anything, it returns None\\n\\nobj = soup.find(\\'dummy\\')\\nprint (obj)\\n\\nOutput\\n\\nNone\\n\\nBeautiful Soup - find_all() Method\\nMethod Description\\nThe find_all() method in Beautiful Soup looks for the elements that match the given criteria in the children of this PageElement and returns a list of all elements.\\nSyntax\\n\\nSoup.find_all(name, attrs, recursive, string, **kwargs)\\n\\nParameters\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nrecursive  If this is True, find() a recursive search will be performed. Otherwise, only the direct children will be considered.\\nlimit  Stop looking after specified number of occurrences have been found.\\nkwargs  A dictionary of filters on attribute values.\\nReturn type\\nThe find_all() method returns a ResultSet object which is a list generator.\\nExample 1\\nWhen we can pass in a value for name, Beautiful Soup only considers tags with certain names. Text strings will be ignored, as will tags whose names that don\\'t match. In this example we pass title to find_all() method.\\n\\nfrom bs4 import BeautifulSoup\\nhtml = open(\\'index.html\\')\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nobj = soup.find_all(\\'input\\')\\nprint (obj)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>, <input id=\"age\" name=\"age\" type=\"text\"/>, <input id=\"marks\" name=\"marks\" type=\"text\"/>]\\n\\nExample 2\\nWe shall use following HTML script in this example \\n\\n<html>\\n   <body>\\n      <h2>Departmentwise Employees</h2>\\n      <ul id=\"dept\">\\n      <li>Accounts</li>\\n         <ul id=\\'acc\\'>\\n         <li>Anand</li>\\n         <li>Mahesh</li>\\n         </ul>\\n      <li>HR</li>\\n         <ol id=\"HR\">\\n         <li>Rani</li>\\n         <li>Ankita</li>\\n         </ol>\\n      </ul>\\n   </body>\\n</html>\\n\\nWe can pass a string to the name argument of find_all() method. With string you can search for strings instead of tags. You can pass in a string, a regular expression, a list, a function, or the value True.\\nIn this example, a function is passed to name argument. All the name starting with \\'A\\' are returned by find_all() method.\\n\\nfrom bs4 import BeautifulSoup\\n\\ndef startingwith(ch):\\n   return ch.startswith(\\'A\\')\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\nlst=soup.find_all(string=startingwith)\\n\\nprint (lst)\\n\\nOutput\\n\\n[\\'Accounts\\', \\'Anand\\', \\'Ankita\\']\\n\\nExample 3\\nIn this example, we pass limit=2 argument to find_all() method. The method returns first two appearances of <li> tag.\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nlst=soup.find_all(\\'li\\', limit =2)\\n\\nprint (lst)\\n\\nOutput\\n\\n[<li>Accounts</li>, <li>Anand</li>]\\n\\nBeautiful Soup - find_parents() Method\\nMethod Description\\nThe find_parent() method in BeautifulSoup package finds all parents of this Element that matches the given criteria.\\nSyntax\\n\\nfind_parents( name, attrs, limit, **kwargs)\\n\\nParameters\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nlimit  Stop looking after specified number of occurrences have been found.\\nkwargs  A dictionary of filters on attribute values.\\nReturn Type\\nThe find_parents() method returns a ResultSet consisting of all the parent elements in a reverse order.\\nExample 1\\nWe shall use following HTML script in this example \\n\\n<html>\\n   <body>\\n   <h2>Departmentwise Employees</h2>\\n   <ul id=\"dept\">\\n   <li>Accounts</li>\\n      <ul id=\\'acc\\'>\\n      <li>Anand</li>\\n      <li>Mahesh</li>\\n      </ul>\\n   <li>HR</li>\\n      <ol id=\"HR\">\\n      <li>Rani</li>\\n      <li>Ankita</li>\\n      </ol>\\n   </ul>\\n   </body>\\n</html>\\n\\nOutput\\n\\nul\\nbody\\nhtml\\n[document]\\n\\nNote that the name property of BeautifulSoup object always returns [document].\\nExample 2\\nIn this example, the limit argument is passed to find_parents() method to restrict the parent search to two levels up.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nobj=soup.find(\\'li\\')\\nparents=obj.find_parents(limit=2)\\nfor parent in parents:\\n   print (parent.name)\\n\\nOutput\\n\\nul\\nbody\\n\\nBeautiful Soup - find_parent() Method\\nMethod Description\\nThe find_parent() method in BeautifulSoup package finds the closest parent of this PageElement that matches the given criteria.\\nSyntax\\n\\nfind_parent( name, attrs, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Type\\nThe find_parent() method returns Tag object or a NavigableString object.\\nExample 1\\nWe shall use following HTML script in this example \\n\\n<html>\\n   <body>\\n      <h2>Departmentwise Employees</h2>\\n      <ul id=\"dept\">\\n      <li>Accounts</li>\\n      <ul id=\\'acc\\'>\\n      <li>Anand</li>\\n      <li>Mahesh</li>\\n      </ul>\\n      <li>HR</li>\\n      <ol id=\"HR\">\\n      <li>Rani</li>\\n      <li>Ankita</li>\\n      </ol>\\n      </ul>\\n   </body>\\n</html>\\n\\nIn the following example, we find the name of the tag that is parent to the string \\'HR\\'.\\n\\nfrom bs4 import BeautifulSoup \\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nobj=soup.find(string=\\'HR\\')\\nprint (obj.find_parent().name)\\n\\nOutput\\n\\nli\\n\\nExample 2\\nThe <body> tag is always enclosed within the top level <html> tag. In the following example, we confirm this fact with find_parent() method \\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nobj=soup.find(\\'body\\')\\nprint (obj.find_parent().name)\\n\\nOutput\\n\\nhtml\\n\\nBeautiful Soup - find_next_siblings() Method\\nMethod Description\\nThe find_next_siblings() method is similar to next_sibling property. It finds all siblings at the same level of this PageElement that match the given criteria and appear later in the document.\\nSyntax\\n\\nfind_fnext_siblings(name, attrs, string, limit, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nstring  The string to search for (rather than tag).\\nlimit  Stop looking after specified number of occurrences have been found.\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Type\\nThe find_next_siblings() method returns a list of Tag objects or a NavigableString objects.\\nExample 1\\nLet us use the following HTML snippet for this purpose \\n\\n<p>\\n   <b>\\n      Excellent\\n   </b>\\n   <i>\\n      Python\\n   </i>\\n   <u>\\n      Tutorial\\n   </u>\\n</p>\\n\\nIn the code below, we try to find all the siblings of <b> tag. There are two more tags at the same level in the HTML string used for scraping.\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(\"<p><b>Excellent</b><i>Python</i><u>Tutorial</u></p>\", \\'html.parser\\')\\n\\ntag1 = soup.find(\\'b\\')\\nprint (\"next siblings:\")\\nfor tag in tag1.find_next_siblings():\\n    print (tag)\\n\\nOutput\\nThe ResultSet of find_next_siblings() is being iterated with the help of for loop.\\n\\nnext siblings:\\n<i>Python</i>\\n<u>Tutorial</u>\\n\\nExample 2\\nIf there are no siblings to be found after a tag, this method returns an empty list.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p><b>Excellent</b><i>Python</i><u>Tutorial</u></p>\", \\'html.parser\\')\\n\\ntag1 = soup.find(\\'u\\')\\nprint (\"next siblings:\")\\nprint (tag1.find_next_siblings())\\n\\nOutput\\n\\nnext siblings:\\n[]\\n\\nBeautiful Soup - find_next_sibling() Method\\nMethod Description\\nThe find_next_sibling() method in Beautiful Soup Find the closest sibling at the same level to this PageElement that matches the  given criteria and appears later in the document. This method is similar to next_sibling property.\\nSyntax\\n\\nfind_fnext_sibling(name, attrs, string, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nstring  The string to search for (rather than tag).\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Type\\nThe find_next_sibling() method returns Tag object or a NavigableString object.\\nExample 1\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p><b>Hello</b><i>Python</i></p>\", \\'html.parser\\')\\n\\ntag1 = soup.find(\\'b\\')\\nprint (\"next:\",tag1.find_next_sibling())\\n\\nOutput\\n\\nnext: <i>Python</i>\\n\\nExample 2\\nIf the next node doesn\\'t exist, the method returns None.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p><b>Hello</b><i>Python</i></p>\", \\'html.parser\\')\\n\\ntag1 = soup.find(\\'i\\')\\nprint (\"next:\",tag1.find_next_sibling())\\n\\nOutput\\n\\nnext: None\\n\\nBeautiful Soup - find_previous_siblings() Method\\nMethod Description\\nThe find_previous_siblings() method in Beautiful Soup package returns all siblings that appear earlier to this PAgeElement in the document and match the given criteria.\\nSyntax\\n\\nfind_previous_siblings(name, attrs, string, limit, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nstring  A filter for a NavigableString with specific text.\\nlimit  Stop looking after finding this many results.\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Value\\nThe find_previous_siblings() method a ResultSet of PageElements.\\nExample 1\\nLet us use the following HTML snippet for this purpose \\n\\n<p>\\n   <b>\\n      Excellent\\n   </b>\\n   <i>\\n      Python\\n   </i>\\n   <u>\\n      Tutorial\\n   </u>\\n</p>\\n\\nIn the code below, we try to find all the siblings of <> tag. There are two more tags at the same level in the HTML string used for scraping.\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(\"<p><b>Excellent</b><i>Python</i><u>Tutorial</u></p>\", \\'html.parser\\')\\n\\ntag1 = soup.find(\\'u\\')\\nprint (\"previous siblings:\")\\nfor tag in tag1.find_previous_siblings():\\n   print (tag)\\n\\nOutput\\n\\n<i>Python</i>\\n<b>Excellent</b>\\n\\nExample 2\\nThe web page (index.html) has a HTML form with three input elements. We locate one with id attribute as marks and then find its previous siblings.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.find(\\'input\\', {\\'id\\':\\'marks\\'})\\nsibs = tag.find_previous_sibling()\\nprint (sibs)\\n\\nOutput\\n\\n[<input id=\"age\" name=\"age\" type=\"text\"/>, <input id=\"nm\" name=\"name\" type=\"text\"/>]\\n\\nExample 3\\nThe HTML string has two <p> tags. We find out the siblings previous to the one with id1 as its id attribute.\\n\\nhtml = \\'\\'\\'\\n<p><b>Excellent</b><p>Python</p><p id=\\'id1\\'>Tutorial</p></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.find(\\'p\\', id=\\'id1\\')\\nptags = tag.find_previous_siblings()\\nfor ptag in ptags:\\n   print (\"Tag: {}, Text: {}\".format(ptag.name, ptag.text))\\n\\nOutput\\n\\nTag: p, Text: Python\\nTag: b, Text: Excellent\\n\\nBeautiful Soup - find_previous_sibling() Method\\nMethod Description\\nThe find_previous_sibling() method in Beautiful Soup returns the closest sibling to this PageElement that matches the given criteria and appears earlier in the document.\\nSyntax\\n\\nfind_previous_sibling(name, attrs, string, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nstring  A filter for a NavigableString with specific text.\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Value\\nThe find_previous_sibling() method returns a PageElement that could be a Tag or a NavigableString.\\nExample 1\\nFrom the HTML string used in the following example, we find out the previous sibling of <i> tag, having the tag name as \\'u\\'\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(\"<p><u>Excellent</u><b>Hello</b><i>Python</i></p>\", \\'html.parser\\')\\ntag = soup.i\\nsibling = tag.find_previous_sibling(\\'u\\')\\nprint (sibling)\\n\\nOutput\\n\\n<u>Excellent</u>\\n\\nExample 2\\nThe web page (index.html) has a HTML form with three input elements. We locate one with id attribute as marks and then find its previous sibling that had id set to nm.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.find(\\'input\\', {\\'id\\':\\'marks\\'})\\nsib = tag.find_previous_sibling(id=\\'nm\\')\\nprint (sib)\\n\\nOutput\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nExample 3\\nIn the code below, the HTML string has two <p> elements and a string inside the outer <p> tag. We use find_previous_string() method to search for the NavigableString object sibling of <p>Tutorial</p> tag.\\n\\nhtml = \\'\\'\\'\\n<p>Excellent<p>Python</p><p>Tutorial</p></p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\n\\ntag = soup.find(\\'p\\', string=\\'Tutorial\\')\\nptag = tag.find_previous_sibling(string=\\'Excellent\\')\\nprint (ptag, type(ptag))\\n\\nOutput\\n\\nExcellent <class \\'bs4.element.NavigableString\\'>\\n\\nBeautiful Soup - find_all_next() Method\\nMethod Description\\nThe find_all_next() method in Beautiful Soup finds all PageElements that match the given criteria and appear after this element in the document. This method returns tags or NavigableString objects and method takes in the exact same parameters as find_all().\\nSyntax\\n\\nfind_all_next(name, attrs, string, limit, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nrecursive  If this is True, find() a recursive search will be performed. Otherwise, only the direct children will be considered.\\nlimit  Stop looking after specified number of occurrences have been found.\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Value\\nThis method returns a ResultSet containing PageElements (Tags or NavigableString objects).\\nExample 1\\nUsing the index.html as the HTML document for this example, we first locate the <form> tag and collect all the elements after it with find_all_next() method.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.form\\ntags = tag.find_all_next()\\nprint (tags)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>, <input id=\"age\" name=\"age\" type=\"text\"/>, <input id=\"marks\" name=\"marks\" type=\"text\"/>]\\n\\nExample 2\\nHere, we apply a filter to the find_all_next() method to collect all the tags subsequent to <form>, with id being nm or age.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.form\\ntags = tag.find_all_next(id=[\\'nm\\', \\'age\\'])\\nprint (tags)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>, <input id=\"age\" name=\"age\" type=\"text\"/>]\\n\\nExample 3\\nIf we check the tags following the body tag, it includes a <h1> tag as well as <form> tag, that includes three input elements.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.body\\ntags = tag.find_all_next()\\nprint (tags)\\n\\nOutput\\n\\n<h1>TutorialsPoint</h1>\\n<form>\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n<input id=\"age\" name=\"age\" type=\"text\"/>\\n<input id=\"marks\" name=\"marks\" type=\"text\"/>\\n</form>\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n<input id=\"age\" name=\"age\" type=\"text\"/>\\n<input id=\"marks\" name=\"marks\" type=\"text\"/>\\n\\nBeautiful Soup - find_next() Method\\nMethod Description\\nThe find_next() method in Beautiful soup finds the first PageElement that matches the given criteria and appears later in the document. returns the first tag or NavigableString that comes after the current tag in the document. Like all other find methods, this method has the following syntax \\nSyntax\\n\\nfind_next(name, attrs, string, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nstring  A filter for a NavigableString with specific text.\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Value\\nThis find_next () method returns a Tag or a NavigableString\\nExample 1\\nA web page index.html with following script has been used for this example\\n\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      <h1>TutorialsPoint</h1>\\n      <form>\\n         <input type = \\'text\\' id = \\'nm\\' name = \\'name\\'>\\n         <input type = \\'text\\' id = \\'age\\' name = \\'age\\'>\\n         <input type = \\'text\\' id = \\'marks\\' name = \\'marks\\'>\\n      </form>\\n   </body>\\n</html>\\n\\nWe first locate the <form> tag and then the one next to it.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.h1\\nprint (tag.find_next())\\n\\nOutput\\n\\n<form>\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n<input id=\"age\" name=\"age\" type=\"text\"/>\\n<input id=\"marks\" name=\"marks\" type=\"text\"/>\\n</form>\\n\\nExample 2\\nIn this example, we first locate the <input> tag with its name=\\'age\\' and obtain its next tag.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.find(\\'input\\', {\\'name\\':\\'age\\'})\\nprint (tag.find_next())\\n\\nOutput\\n\\n<input id=\"marks\" name=\"marks\" type=\"text\"/>\\n\\nExample 3\\nThe tag next to the <head> tag happens to be <title> tag.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\n\\ntag = soup.head\\nprint (tag.find_next())\\n\\nOutput\\n\\n<title>TutorialsPoint</title>\\n\\nBeautiful Soup - find_all_previous() Method\\nMethod Description\\nThe find_all_previous() method in Beautiful Soup look backwards in the document from this PageElement and finds all the PageElements that match the given criteria and appear before the current element. It returns a ResultsSet of PageElements that comes before the current tag in the document. Like all other find methods, this method has the following syntax \\nSyntax\\n\\nfind_previous(name, attrs, string, limit, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nstring  A filter for a NavigableString with specific text.\\nlimit  Stop looking after finding this many results.\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Value\\nThe find_all_previous() method returns a ResultSet of Tag or NavigableString objects. If the limit parameter is 1, the method is equivalent to find_previous() method.\\nExample 1\\nIn this example, name property of each object that appears before the first input tag is displayed.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.find(\\'input\\')\\nfor t in tag.find_all_previous():\\n   print (t.name)\\n\\nOutput\\n\\nform\\nh1\\nbody\\ntitle\\nhead\\nhtml\\n\\nExample 2\\nIn the HTML document under consideration (index.html), there are three input elements. With the following code, we print the tag names of all preceding tags before thr <input> tag with nm attribute as marks. To differentiate between the two input tags before it, we also print the attrs property. Note that the other tags don\\'t have any attributes.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.find(\\'input\\', {\\'name\\':\\'marks\\'})\\npretags = tag.find_all_previous()\\nfor pretag in pretags:\\n   print (pretag.name, pretag.attrs)\\n\\nOutput\\n\\ninput {\\'type\\': \\'text\\', \\'id\\': \\'age\\', \\'name\\': \\'age\\'}\\ninput {\\'type\\': \\'text\\', \\'id\\': \\'nm\\', \\'name\\': \\'name\\'}\\nform {}\\nh1 {}\\nbody {}\\ntitle {}\\nhead {}\\nhtml {}\\n\\nExample 3\\nThe BeautifulSoup object stores the entire document\\'s tree. It doesn\\'t have any previous element, as the example below shows \\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntags = soup.find_all_previous()\\nprint (tags)\\n\\nOutput\\n\\n[]\\n\\nBeautiful Soup - find_previous() Method\\nMethod Description\\nThe find_previous() method in Beautiful Soup look backwards in the document from this PageElement and find the first PageElement that matches the given criteria. It returns the first tag or NavigableString that comes before the current tag in the document. Like all other find methods, this method has the following syntax \\nSyntax\\n\\nfind_previous(name, attrs, string, **kwargs)\\n\\nParameters\\n\\nname  A filter on tag name.\\nattrs  A dictionary of filters on attribute values.\\nstring  A filter for a NavigableString with specific text.\\nkwargs  A dictionary of filters on attribute values.\\n\\nReturn Value\\nThe find_previous() method returns a Tag or NavigableString object.\\nExample 1\\nIn the example below, we try to find which is the previous object before the <body> tag. It happens to be <title> element.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.body\\nprint (tag.find_previous())\\n\\nOutput\\n\\n<title>TutorialsPoint</title>\\n\\nExample 2\\nThere are three input elements in the HTML document used in this example. The following code locates the input element with name attribute = age and looks for its previous element.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.find(\\'input\\', {\\'name\\':\\'age\\'})\\nprint (tag.find_previous())\\n\\nOutput\\n\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n\\nExample 3\\nThe element before <title> happens to be <head> element.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\"index.html\")\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntag = soup.find(\\'title\\')\\nprint (tag.find_previous())\\n\\nOutput\\n\\n<head>\\n<title>TutorialsPoint</title>\\n</head>\\n\\nBeautiful Soup - select() Method\\nMethod Description\\nIn Beautiful Soup library, the select() method is an important tool for scraping the HTML/XML document. Similar to find() and find_*() methods, the select() method also helps in locating an element that satisfies a given criteria. The selection of an element in the document tree is done based on the CSS selector given to it as an argument.\\nBeautiful Soup also has select_one() method. Difference in select() and select_one() is that, select() returns a ResultSet of all the elements belonging to the PageElement and characterized by the CSS selector; whereas select_one() returns the first occurrence of the element satisfying the CSS selector based selection criteria.\\nPrior to Beautiful Soup version 4.7, the select() method used to be able to support only the common CSS selectors. With version 4.7, Beautiful Soup was integrated with Soup Sieve CSS selector library. As a result, much more selectors can now be used. In the version 4.12, a .css property has been added in addition to the existing convenience methods, select() and select_one().\\nSyntax\\n\\nselect(selector, limit, **kwargs)\\n\\nParameters\\n\\nselector  A string containing a CSS selector.\\nlimit  After finding this number of results, stop looking.\\nkwargs  Keyword arguments to be passed.\\n\\nIf the limit parameter is set to 1, it becomes equivalent to select_one() method.\\nReturn Value\\nThe select() method returns a ResultSet of Tag objects. The select_one() method returns a single Tag object.\\nThe Soup Sieve library has different types of CSS selectors. The basic CSS selectors are \\n\\nType selectors match elements by node name. For example \\n\\n\\ntags = soup.select(\\'div\\')\\n\\n\\nThe Universal selector (*) matches elements of any type. Example \\n\\n\\ntags = soup.select(\\'*\\')\\n\\n\\nThe ID selector matches an element based on its id attribute. The symbol # denotes the ID selector. Example \\n\\n\\ntags = soup.select(\"#nm\")\\n\\n\\nThe class selector matches an element based on the values contained in the class attribute. The . symbol prefixed to the class name is the CSS class selector. Example \\n\\n\\ntags = soup.select(\".submenu\")\\n\\nExample: Type Selector\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'\\'\\'\\n   <div id=\"Languages\">\\n      <p>Java</p> <p>Python</p> <p>C++</p>\\n   </div>\\n\\'\\'\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntags = soup.select(\\'div\\')\\nprint (tags)\\n\\nOutput\\n\\n[<div id=\"Languages\">\\n<p>Java</p> <p>Python</p> <p>C++</p>\\n</div>]\\n\\nExample: ID selector\\n\\nfrom bs4 import BeautifulSoup\\n\\nhtml = \\'\\'\\'\\n   <form>\\n      <input type = \\'text\\' id = \\'nm\\' name = \\'name\\'>\\n      <input type = \\'text\\' id = \\'age\\' name = \\'age\\'>\\n      <input type = \\'text\\' id = \\'marks\\' name = \\'marks\\'>\\n   </form>\\n\\'\\'\\'\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nobj = soup.select(\"#nm\")\\nprint (obj)\\n\\nOutput\\n\\n[<input id=\"nm\" name=\"name\" type=\"text\"/>]\\n\\nExample: class selector\\n\\nhtml = \\'\\'\\'\\n   <ul>\\n      <li class=\"mainmenu\">Accounts</li>\\n      <ul>\\n         <li class=\"submenu\">Anand</li>\\n         <li class=\"submenu\">Mahesh</li>\\n      </ul>\\n      <li class=\"mainmenu\">HR</li>\\n      <ul>\\n         <li class=\"submenu\">Rani</li>\\n         <li class=\"submenu\">Ankita</li>\\n      </ul>\\n   </ul>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntags = soup.select(\".mainmenu\")\\nprint (tags)\\n\\nOutput\\n\\n[<li class=\"mainmenu\">Accounts</li>, <li class=\"mainmenu\">HR</li>]\\n\\nBeautiful Soup - append() Method\\nMethod Description\\nThe append() method in Beautiful Soup adds a given string or another tag at the end of the current Tag object\\'s contents. The append() method works similar to the append() method of Python\\'s list object.\\nSyntax\\n\\nappend(obj)\\n\\nParameters\\n\\nobj  any PageElement, may be a string, a NavigableString object or a Tag object.\\n\\nReturn Type\\nThe append() method doesn\\'t return a new object.\\nExample 1\\nIn the following example, the HTML script has a <p> tag. With append(), additional text is appended.In the following example, the HTML script has a <p> tag. With append(), additional text is appended.\\n\\nfrom bs4 import BeautifulSoup\\n\\nmarkup = \\'<p>Hello</p>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\nprint (soup)\\ntag = soup.p\\n\\ntag.append(\" World\")\\nprint (soup) \\n\\nOutput\\n\\n<p>Hello</p>\\n<p>Hello World</p>\\n\\nExample 2\\nWith the append() method, you can add a new tag at the end of an existing tag. First create a new Tag object with new_tag() method and then pass it to the append() method.\\n\\nfrom bs4 import BeautifulSoup, Tag\\n\\nmarkup = \\'<b>Hello</b>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.b \\ntag1 = soup.new_tag(\\'i\\')\\ntag1.string = \\'World\\'\\ntag.append(tag1)\\nprint (soup.prettify()) \\n\\nOutput\\n\\n   <b>\\n      Hello\\n   <i>\\n      World\\n   </i>\\n</b>\\n\\nExample 3\\nIf you have to add a string to the document, you can append a NavigableString object.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Hello</b>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.b \\nnew_string = NavigableString(\" World\")\\ntag.append(new_string)\\nprint (soup.prettify())\\n\\nOutput\\n\\n<b>\\n   Hello\\n   World\\n</b>\\n\\nBeautiful Soup - extend() Method\\nMethod Description\\nThe extend() method in Beautiful Soup has been added to Tag class  from version 4.7 onwards. It adds all the elements in a list to the tag. This method is analogous to a standard Python List\\'s extend() method - it takes in an array of strings to append to the tag\\'s content.\\nSyntax\\n\\nextend(tags)\\n\\nParameters\\n\\ntags  A list of srings or NavigableString objects to be appended.\\n\\nReturn Type\\nThe extend() method doesn\\'t return any new object.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nmarkup = \\'<b>Hello</b>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\n\\ntag = soup.b \\nvals = [\\'World.\\', \\'Welcome to \\', \\'TutorialsPoint\\']\\ntag.extend(vals)\\nprint (soup.prettify())\\n\\nOutput\\n\\n<b>\\n   Hello\\n   World.\\n   Welcome to\\n   TutorialsPoint\\n</b>\\n\\nBeautiful Soup - NavigableString() Method\\nMethod Description\\nThe NavigableString() method in bs4 package is the constructor method for NavigableString class. A NavigableString represents the innermost child element of a parsed document. This method casts a regular Python string to a NavigableString. Conversely, the built-in str() method coverts NavigableString object to a Unicode string.\\nSyntax\\n\\nNavigableString(string)\\n\\nParameters\\n\\nstring  an object of Python\\'s str class.\\n\\nReturn Value\\nThe NavigableString() method returns a NavigableString object.\\nExample 1\\nIn the code below, the HTML string contains an empty <b> tag. We add a NavigableString object in it.\\n\\nhtml = \"\"\"\\n<p><b></b></p>\\n\"\"\"\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nnavstr = NavigableString(\"Hello World\")\\nsoup.b.append(navstr)\\nprint (soup)\\n\\nOutput\\n\\n<p><b>Hello World</b></p>\\n\\nExample 2\\nIn this example, we see that two NavigableString objects are appended to an empty <b> tag. The tag responds to strings property instead of string property. It is a generator of NavigableString objects.\\n\\nhtml = \"\"\"\\n<p><b></b></p>\\n\"\"\"\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nnavstr = NavigableString(\"Hello\")\\nsoup.b.append(navstr)\\nnavstr = NavigableString(\"World\")\\nsoup.b.append(navstr)\\nfor s in soup.b.strings:\\n   print (s, type(s))\\n\\nOutput\\n\\nHello <class \\'bs4.element.NavigableString\\'>\\nWorld <class \\'bs4.element.NavigableString\\'>\\n\\nExample 3\\nInstead of strings property, if we access the stripped_strings property of <b> tag object, we get a generator of Unicode strings i.e. str objects.\\n\\nhtml = \"\"\"\\n<p><b></b></p>\\n\"\"\"\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\nnavstr = NavigableString(\"Hello\")\\nsoup.b.append(navstr)\\nnavstr = NavigableString(\"World\")\\nsoup.b.append(navstr)\\nfor s in soup.b.stripped_strings:\\n   print (s, type(s))\\n\\nOutput\\n\\nHello <class \\'str\\'>\\nWorld <class \\'str\\'>\\n\\nBeautiful Soup - new_tag() Method\\nThe new_tag() method in Beautiful Soup library creates a new Tag object, that is associated with an existing BeautifulSoup object. You can use this factory method to append or insert the new tag into the document tree.\\nSyntax\\n\\nnew_tag(name, namespace, nsprefix, attrs, sourceline, sourcepos, **kwattrs)\\n\\nParameters\\n\\nname  The name of the new Tag.\\nnamespace  The URI of the new Tag\\'s XML namespace, optional.\\nprefix  The prefix for the new Tag\\'s XML namespace, optional.\\nattrs  A dictionary of this Tag\\'s attribute values.\\nsourceline  The line number where this tag was found in its source document.\\nsourcepos  The character position within `sourceline` where this tag was found.\\nkwattrs  Keyword arguments for the new Tag\\'s attribute values.\\n\\nReturn Value\\nThis method returns a new Tag object.\\nExample 1\\nThe following example shows the use of new_tag() method. A new tag for <a> element. The tag object is initialized with the href and string attributes and then inserted in the document tree.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\\'<p>Welcome to <b>online Tutorial library</b></p>\\', \\'html.parser\\')\\ntag = soup.new_tag(\\'a\\')\\ntag.attrs[\\'href\\'] = \"www.tutorialspoint.com\"\\ntag.string = \"Tutorialspoint\"\\nsoup.b.insert_before(tag)\\nprint (soup)\\n\\nOutput\\n\\n<p>Welcome to <a href=\"www.tutorialspoint.com\">Tutorialspoint</a><b>online Tutorial library</b></p>\\n\\nExample 2\\nIn the following example, we have a HTML form with two input elements. We create a new input tag and append it to the form tag.\\n\\nhtml = \\'\\'\\'\\n   <form>\\n      <input type = \\'text\\' id = \\'nm\\' name = \\'name\\'>\\n      <input type = \\'text\\' id = \\'age\\' name = \\'age\\'>\\n   </form>\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \\'html.parser\\')\\ntag = soup.form\\nnewtag=soup.new_tag(\\'input\\', attrs={\\'type\\':\\'text\\', \\'id\\':\\'marks\\', \\'name\\':\\'marks\\'})\\ntag.append(newtag)\\nprint (soup)\\n\\nOutput\\n\\n<form>\\n<input id=\"nm\" name=\"name\" type=\"text\"/>\\n<input id=\"age\" name=\"age\" type=\"text\"/>\\n<input id=\"marks\" name=\"marks\" type=\"text\"/></form>\\n\\nExample 3\\nHere we have an empty <p> tag in the HTML string. A new tag is inserted in it.\\n\\nfrom bs4 import BeautifulSoup\\nsoup = BeautifulSoup(\\'<p></p>\\', \\'html.parser\\')\\ntag = soup.new_tag(\\'b\\')\\ntag.string = \"Hello World\"\\nsoup.p.insert(0,tag)\\nprint (soup)\\n\\nOutput\\n\\n<p><b>Hello World</b></p>\\n\\nBeautiful Soup - insert() Method\\nMethod Description\\nThe insert() method in Beautiful Soup add an element at the given position in a the list of children of a Tag element. The insert() method in Beautiful Soup behaves similar to insert() on a Python list object.\\nSyntax\\n\\ninsert(position, child)\\n\\nParameters\\n\\nposition  The position at which the new PageElement should be inserted.\\nchild  A PageElement to be inserted.\\n\\nReturn Type\\nThe insert() method doesn\\'t return any new object.\\nExample 1\\nIn the following example, a new string is added to the <b> tag at position 1. The resultant parsed document shows the result. \\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Excellent </b><u>from TutorialsPoint</u>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.b\\n\\ntag.insert(1, \"Tutorial \")\\nprint (soup.prettify())\\n\\nOutput\\n\\n<b>\\n   Excellent\\n   Tutorial\\n</b>\\n<u>\\n   from TutorialsPoint\\n</u>\\n\\nExample 2\\nIn the following example, the insert() method is used to successively insert strings from a list to a <p> tag in HTML markup.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<p>Excellent Tutorials from TutorialsPoint</p>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\nlangs = [\\'Python\\', \\'Java\\', \\'C\\']\\ni=0\\nfor lang in langs:\\n   i+=1\\n   tag = soup.new_tag(\\'p\\')\\n   tag.string = lang\\n   soup.p.insert(i, tag)\\n\\n\\nprint (soup.prettify())\\n\\nOutput\\n\\n<p>\\n   Excellent Tutorials from TutorialsPoint\\n   <p>\\n   Python\\n   </p>\\n   <p>\\n      Java\\n   </p>\\n   <p>\\n      C\\n   </p>\\n</p>\\n\\nBeautiful Soup - insert_before() Method\\nMethod Description\\nThe insert_before() method in Beautiful soup inserts tags or strings immediately before something else in the parse tree. The inserted element becomes the immediate predecessor of this one. The inserted element can be a tag or a string.\\nSyntax\\n\\ninsert_before(*args)\\n\\nParameters\\n\\nargs  One or more elements, may be tag or a string.\\n\\nReturn Value\\nThis insert_before() method doesn\\'t return any new object.\\nExample 1\\nThe following example inserts a text \"Here is an\" before \"Excellent in the given HTML markup string.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<b>Excellent</b> Python Tutorial <u>from TutorialsPoint</u>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.b\\n\\ntag.insert_before(\"Here is an \")\\nprint (soup.prettify())\\n\\nOutput\\n\\nHere is an\\n<b>\\n   Excellent\\n</b>\\n   Python Tutorial\\n<u>\\n   from TutorialsPoint\\n</u>\\n\\nExample 2\\nYou can also insert a tag before another tag. Take a look at this example.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<P>Excellent <b>Tutorial</b> from TutorialsPoint</u>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.b\\ntag1 = soup.new_tag(\\'b\\')\\ntag1.string = \"Python \"\\ntag.insert_before(tag1)\\nprint (soup.prettify())\\n\\nOutput\\n\\n<p>\\n   Excellent\\n   <b>\\n      Python\\n   </b>\\n   <b>\\n      Tutorial\\n   </b>\\n   from TutorialsPoint\\n</p>\\n\\nExample 3\\nThe following code passes more than one strings to be inserted before the <b> tag.\\n\\nfrom bs4 import BeautifulSoup\\n\\nmarkup = \\'<p>There are <b>Tutorials</b> <u>from TutorialsPoint</u></p>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.b\\n\\ntag.insert_before(\"many \", \\'excellent \\')\\nprint (soup.prettify())\\n\\nOutput\\n\\n<p>\\n   There are\\n   many\\n   excellent\\n   <b>\\n      Tutorials\\n   </b>\\n   <u>\\n      from TutorialsPoint\\n   </u>\\n</p>\\n\\nBeautiful Soup - insert_after() Method\\nMethod Description\\nThe insert_after() method in Beautiful soup inserts tags or strings immediately after something else in the parse tree. The inserted element becomes the immediate successor of this one. The inserted element can be a tag or a string.\\nSyntax\\n\\ninsert_after(*args)\\n\\nParameters\\n\\nargs  One or more elements, may be tag or a string.\\n\\nReturn Value\\nThis insert_after() method doesn\\'t return any new object.\\nExample 1\\nFollowing code inserts a string \"Python\" after the first <b> tag.\\n\\nfrom bs4 import BeautifulSoup\\n\\nmarkup = \\'<p>An <b>Excellent</b> Tutorial <u>from TutorialsPoint</u>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.b\\n\\ntag.insert_after(\"Python \")\\nprint (soup.prettify())\\n\\nOutput\\n\\n<p>\\n   An\\n   <b>\\n      Excellent\\n   </b>\\n   Python\\n   Tutorial\\n   <u>\\n      from TutorialsPoint\\n   </u>\\n</p>\\n\\nExample 2\\nYou can also insert a tag before another tag. Take a look at this example.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<P>Excellent <b>Tutorial</b> from TutorialsPoint</p>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.b\\ntag1 = soup.new_tag(\\'b\\')\\ntag1.string = \"on Python \"\\ntag.insert_after(tag1)\\nprint (soup.prettify())\\n\\nOutput\\n\\n<p>\\n   Excellent\\n   <b>\\n      Tutorial\\n   </b>\\n   <b>\\n      on Python\\n   </b>\\n   from TutorialsPoint\\n</p>\\n\\nExample 3\\nMultiple tags or strings can be inserted after a certain tags.\\n\\nfrom bs4 import BeautifulSoup, NavigableString\\n\\nmarkup = \\'<P>Excellent <b>Tutorials</b> from TutorialsPoint</p>\\'\\nsoup = BeautifulSoup(markup, \\'html.parser\\')\\ntag = soup.p\\ntag1 = soup.new_tag(\\'i\\')\\ntag1.string = \\'and Java\\'\\ntag.insert_after(\"on Python\", tag1)\\nprint (soup.prettify())\\n\\nOutput\\n\\n<p>\\n   Excellent\\n   <b>\\n      Tutorials\\n   </b>\\n   from TutorialsPoint\\n</p>\\non Python\\n<i>\\n   and Java\\n</i>\\n\\nBeautiful Soup - clear() Method\\nMethod Description\\nThe clear() method in Beautiful Soup library removes the inner content of a tag, keeping the tag intact. If there are any child elements, extract() method is called on them. If decompose argument is set to True, then decompose() method is called instead of extract().\\nSyntax\\n\\nclear(decompose=False)\\n\\nParameters\\n\\ndecompose  If this is True, decompose() (a more destructive method) will be called instead of extract()\\n\\nReturn Value\\nThe clear() method doesn\\'t return any object.\\nExample 1\\nAs clear() method is called on the soup object that represents the entire document, all the content is removed, leaving the document blank.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      <p>Junk MTV quiz graced by fox whelps.</p>\\n      <p>Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\nsoup.clear()\\nprint(soup)\\n\\nOutput\\n\\n\\n\\nExample 2\\nIn the following example, we find all the <p> tags and call clear() method on each of them.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      <p>Junk MTV quiz graced by fox whelps.</p>\\n      <p>Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntags = soup.find_all(\\'p\\')\\nfor tag in tags:\\n   tag.clear() \\n\\nprint(soup)\\n\\nOutput\\nContents of each <p> .. </p> will be removed, the tags will be retained.\\n\\n<html>\\n<body>\\n<p></p>\\n<p></p>\\n<p></p>\\n<p></p>\\n</body>\\n</html>\\n\\nExample 3\\nHere we clear the contents of <body> tags with decompose argument set to Tue.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      <p>Junk MTV quiz graced by fox whelps.</p>\\n      <p>Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntags = soup.find(\\'body\\')\\nret = tags.clear(decompose=True)\\n\\nprint(soup)\\n\\nOutput\\n\\n<html>\\n<body></body>\\n</html>\\n\\nBeautiful Soup - extract() Method\\nMethod Description\\nThe extract() method in Beautiful Soup library is used to remove a tag or a string from the document tree. The extract() method returns the object that has been removed. It is similar to how a pop() method in Python list works.\\nSyntax\\n\\nextract(index)\\n\\nParameters\\n\\nIndex  The position of the element to be removed. None by default.\\n\\nReturn Type\\nThe extract() method returns the element that has been removed from the document tree.\\nExample 1\\n\\nhtml = \\'\\'\\'\\n   <div>\\n      <p>Hello Python</p>\\n   </div>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup=BeautifulSoup(html, \\'html.parser\\')\\n                \\ntag1 = soup.find(\"div\")\\ntag2 = tag1.find(\"p\")\\nret = tag2.extract()\\nprint (\\'Extracted:\\',ret)\\nprint (\\'original:\\',soup)\\n\\nOutput\\n\\nExtracted: <p>Hello Python</p>\\noriginal:\\n<div>\\n</div>\\n\\nExample 2\\nConsider the following HTML markup \\n\\n<html>\\n   <body>\\n      <p> The quick, brown fox jumps over a lazy dog.</p>\\n      <p> DJs flock by when MTV ax quiz prog.</p>\\n      <p> Junk MTV quiz graced by fox whelps.</p>\\n      <p> Bawds jog, flick quartz, vex nymphs./p>\\n   </body>\\n</html>\\n\\nHere is the code \\n\\nfrom bs4 import BeautifulSoup\\n\\nfp = open(\\'index.html\\')\\nsoup = BeautifulSoup(fp, \\'html.parser\\')\\ntags = soup.find_all()\\nfor tag in tags:\\n   obj = tag.extract()\\n   print (\"Extracted:\",obj)\\n\\nprint (soup)\\n\\nOutput\\n\\nExtracted: <html>\\n<body>\\n<p> The quick, brown fox jumps over a lazy dog.</p>\\n<p> DJs flock by when MTV ax quiz prog.</p>\\n<p> Junk MTV quiz graced by fox whelps.</p>\\n<p> Bawds jog, flick quartz, vex nymphs.</p>\\n</body>\\n</html>\\nExtracted: <body>\\n<p> The quick, brown fox jumps over a lazy dog.</p>\\n<p> DJs flock by when MTV ax quiz prog.</p>\\n<p> Junk MTV quiz graced by fox whelps.</p>\\n<p> Bawds jog, flick quartz, vex nymphs.</p>\\n</body>\\nExtracted: <p> The quick, brown fox jumps over a lazy dog.</p>\\nExtracted: <p> DJs flock by when MTV ax quiz prog.</p>\\nExtracted: <p> Junk MTV quiz graced by fox whelps.</p>\\nExtracted: <p> Bawds jog, flick quartz, vex nymphs.</p>\\n\\nExample 3\\nYou can also use extract() method along with find_next(), find_previous() methods and next_element, previous_element properties.\\n\\nhtml = \\'\\'\\'\\n<div>\\n<p><b>Hello</b><b>Python</b></p>\\n</div>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup=BeautifulSoup(html, \\'html.parser\\')\\n                \\ntag1 = soup.find(\"b\")\\nret = tag1.next_element.extract()\\nprint (\\'Extracted:\\',ret)\\nprint (\\'original:\\',soup)\\n\\nOutput\\n\\nExtracted: Hello\\noriginal:\\n<div>\\n<p><b></b><b>Python</b></p>\\n</div>\\n\\nBeautiful Soup - decompose() Method\\nMethod Description\\nThe decompose() method destroys current element along with its children, thus the element is removed from the tree, wiping it out and everything beneath it. You can check whether an element has been decomposed, by the `decomposed` property. It returns True if destroyed, false otherwise.\\nSyntax\\n\\ndecompose()\\n\\nParameters\\nNo parameters are defined for this method.\\nReturn Type\\nThe method doesn\\'t return any object.\\nExample 1\\nWhen we call descompose() method on the BeautifulSoup object itself, the entire content will be destroyed.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      <p>Junk MTV quiz graced by fox whelps.</p>\\n      <p>Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\nsoup.decompose()\\nprint (\"decomposed:\",soup.decomposed)\\nprint (soup)\\n\\nOutput\\n\\ndecomposed: True\\ndocument: Traceback (most recent call last):\\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~\\nTypeError: can only concatenate str (not \"NoneType\") to str\\n\\nSince the soup object is decomposed, it returns True, however, you get TypeError as shown above.\\nExample 2\\nThe code below makes use of decompose() method to remove all the occurrences of <p> tags in the HTML string used.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      <p>Junk MTV quiz graced by fox whelps.</p>\\n      <p>Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\np_all = soup.find_all(\\'p\\')\\n[p.decompose() for p in p_all]\\n\\nprint (\"document:\",soup)\\n\\nOutput\\nRest of the HTML document after removing all <p> tags will be printed.\\n\\ndocument: \\n<html>\\n<body>\\n\\n</body>\\n</html>\\n\\nExample 3\\nHere, we find the <body> tag from the HTML document tree and decompose the previous element which happens to be the <title> tag. The resultant document tree omits the <title> tag.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <head>\\n      <title>TutorialsPoint</title>\\n   </head>\\n   <body>\\n      Hello World\\n   </body>\\n</html>\\n\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntag = soup.body\\ntag.find_previous().decompose()\\n\\nprint (\"document:\",soup)\\n\\nOutput\\n\\ndocument: \\n<html>\\n<head>\\n\\n</head>\\n<body>\\nHello World\\n</body>\\n</html>\\n\\nBeautiful Soup - replace_with() Method\\nMethod Description\\nBeautiful Soup\\'s replace_with() method replaces a tag or string in an element with the provided tag or string.\\nSyntax\\n\\nreplace_with(tag/string)\\n\\nParameters\\nThe method accepts a tag object or a string as argument.\\nReturn Type\\nThe replace_method doesn\\'t return a new object.\\nExample 1\\nIn this example, the <p> tag is replaced by <b> with the use of replace_with() method.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntag1 = soup.find(\\'p\\')\\ntxt = tag1.string\\ntag2 = soup.new_tag(\\'b\\')\\ntag2.string = txt\\ntag1.replace_with(tag2)\\nprint (soup)\\n\\nOutput\\n\\n<html>\\n<body>\\n<b>The quick, brown fox jumps over a lazy dog.</b>\\n</body>\\n</html>\\n\\nExample 2\\nYou can simply replace the inner text of a tag with another string by calling replace_with() method on the tag.string object.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntag1 = soup.find(\\'p\\')\\ntag1.string.replace_with(\"DJs flock by when MTV ax quiz prog.\")\\nprint (soup)\\n\\nOutput\\n\\n<html>\\n<body>\\n<p>DJs flock by when MTV ax quiz prog.</p>\\n</body>\\n</html>\\n\\nExample 3\\nThe tag object to be used for replacement can be obtained by any of the find() methods. Here, we replace the text of the tag next to <p> tag.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, <b>brown</b> fox jumps over a lazy dog.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntag1 = soup.find(\\'p\\')\\ntag1.find_next(\\'b\\').string.replace_with(\\'black\\')\\nprint (soup)\\n\\nOutput\\n\\n<html>\\n<body>\\n<p>The quick, <b>black</b> fox jumps over a lazy dog.</p>\\n</body>\\n</html>\\n\\nBeautiful Soup - wrap() Method\\nMethod Description\\nThe wrap() method in Beautiful Soup encloses the element inside another element. You can wrap an existing tag element with another, or wrap the tag\\'s string with a tag.\\nSyntax\\n\\nwrap(tag)\\n\\nParameters\\nThe tag to be wrapped with.\\nReturn Type\\nThe method returns a new wrapper with the given tag.\\nExample 1\\nIn this example, the <b> tag is wrapped in <div> tag.\\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, <b>brown</b> fox jumps over a lazy dog.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntag1 = soup.find(\\'b\\')\\nnewtag = soup.new_tag(\\'div\\')\\ntag1.wrap(newtag)\\nprint (soup)\\n\\nOutput\\n\\n<html>\\n<body>\\n<p>The quick, <div><b>brown</b></div> fox jumps over a lazy dog.</p>\\n</body>\\n</html>\\n\\nExample 2\\nWe wrap the string inside the <p> tag with a wrapper tag.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p>tutorialspoint.com</p>\", \\'html.parser\\')\\nsoup.p.string.wrap(soup.new_tag(\"b\"))\\n\\nprint (soup)\\n\\nOutput\\n\\n<p><b>tutorialspoint.com</b></p>\\n\\nBeautiful Soup - unwrap() Method\\nMethod Description\\nThe unwrap() method is the opposite of wrap() method. It It replaces a tag with whatever\\'s inside that tag. It removes the tag from an element and returns it.\\nSyntax\\n\\nunwrap()\\n\\nParameters\\nThe method doesn\\'t require any parameter.\\nReturn Type\\nThe unwrap() method returns the tag that has been removed.\\nExample 1\\nIn the following example, the <b> tag from the html string is removed.\\n\\nhtml = \\'\\'\\'\\n<p>The quick, <b>brown</b> fox jumps over a lazy dog.</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntag1 = soup.find(\\'b\\')\\nnewtag = tag1.unwrap()\\n\\nprint (soup)\\n\\nOutput\\n\\n<p>The quick, brown fox jumps over a lazy dog.</p>\\n\\nExample 2\\nThe code below prints the returned value of unwrap() method.\\n\\nhtml = \\'\\'\\'\\n<p>The quick, <b>brown</b> fox jumps over a lazy dog.</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntag1 = soup.find(\\'b\\')\\nnewtag = tag1.unwrap()\\n\\nprint (newtag)\\n\\nOutput\\n\\n<b></b>\\n\\nExample 3\\nThe unwrap() method is useful for good for stripping out markup, as the following code shows \\n\\nhtml = \\'\\'\\'\\n<html>\\n   <body>\\n      <p>The quick, brown fox jumps over a lazy dog.</p>\\n      <p>DJs flock by when MTV ax quiz prog.</p>\\n      <p>Junk MTV quiz graced by fox whelps.</p>\\n      <p>Bawds jog, flick quartz, vex nymphs.</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\n#print (soup.unwrap())\\nfor tag in soup.find_all():\\n   tag.unwrap()\\nprint (soup)\\n\\nOutput\\n\\nThe quick, brown fox jumps over a lazy dog.\\nDJs flock by when MTV ax quiz prog.\\nJunk MTV quiz graced by fox whelps.\\nBawds jog, flick quartz, vex nymphs.\\n\\nBeautiful Soup - smooth() Method\\nMethod Description\\nAfter calling a bunch of methods that modify the parse tree, you may end up with two or more NavigableString objects next to each other. The smooth() method smooths out this element\\'s children by consolidating consecutive strings. This makes pretty-printed output look more natural following a lot of operations that modified the tree.\\nSyntax\\n\\nsmooth()\\n\\nParameters\\nThis method has no parameters.\\nReturn Type\\nThis method returns the given tag after smoothing.\\nExample 1\\n\\nhtml =\\'\\'\\'<html>\\n<head>\\n    <title>TutorislsPoint/title>\\n</head>\\n<body>\\nSome Text\\n    <div></div>\\n    <p></p>\\n    <div>Some more text</div>\\n    <b></b>\\n    <i></i> # COMMENT\\n</body>\\n</html>\\'\\'\\'\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\nsoup.find(\\'body\\').sm\\nfor item in soup.find_all():\\n   if not item.get_text(strip=True):\\n      p = item.parent\\n      item.replace_with(\\'\\')\\n      p.smooth()\\n\\nprint (soup.prettify())\\n\\nOutput\\n\\n<html>\\n   <head>\\n      <title>\\n         TutorislsPoint/title>\\n      </title>\\n   </head>\\n   <body>\\n      Some Text\\n      <div>\\n         Some more text\\n      </div>\\n      # COMMENT\\n   </body>\\n</html>\\n\\nExample 2\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"<p>Hello</p>\", \\'html.parser\\')\\nsoup.p.append(\", World\")\\n\\nsoup.smooth()\\nprint (soup.p.contents)\\n\\nprint(soup.p.prettify())\\n\\nOutput\\n\\n[\\'Hello, World\\']\\n<p>\\n   Hello, World\\n</p>\\n\\nBeautiful Soup - prettify() Method\\nMethod Description\\nTo get a nicely formatted Unicode string, use Beautiful Soup\\'s prettify() method. It formats the Beautiful Soup parse tree so that there each tag is on its own separate line with indentation. It allows to you to easily visualize the structure of the Beautiful Soup parse tree.\\nSyntax\\n\\nprettify(encoding, formatter)\\n\\nParameters\\n\\nencoding  The eventual encoding of the string. If this is None, a Unicode string will be returned.\\nA Formatter object, or a string naming one of the standard formatters.\\n\\nReturn Type\\nThe prettify() method returns a Unicode string (if encoding==None) or a bytestring (otherwise).\\nExample 1\\nConsider the following HTML string.\\n\\n<p>The quick, <b>brown fox</b> jumps over a lazy dog.</p>\\n\\nUsing the prettify() method we can better understand its structure \\n\\nhtml = \\'\\'\\'\\n<p>The quick, <b>brown fox</b> jumps over a lazy dog.</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"lxml\")\\nprint (soup.prettify())\\n\\nOutput\\n\\n<html>\\n   <body>\\n      <p>\\n         The quick,\\n      <b>\\n         brown fox\\n      </b>\\n         jumps over a lazy dog.\\n      </p>\\n   </body>\\n</html>\\n\\nExample 2\\nYou can call prettify() on on any of the Tag objects in the document.\\n\\nprint (soup.b.prettify())\\n\\nOutput\\n\\n<b>\\n   brown fox\\n</b>\\n\\nThe prettify() method is for understanding the structure of the document. However, it should not be used to reformat it, as it adds whitespace (in the form of newlines), and changes the meaning of an HTML document.\\nHe prettify() method can optionally be provided formatter argument to specify the formatting to be used.\\nThere are following possible values for the formatter.\\nformatter=\"minimal\"  This is the default. Strings will only be processed enough to ensure that Beautiful Soup generates valid HTML/XML.\\nformatter=\"html\"  Beautiful Soup will convert Unicode characters to HTML entities whenever possible.\\nformatter=\"html5\"  it\\'s similar to formatter=\"html\", but Beautiful Soup will omit the closing slash in HTML void tags like \"br\".\\nformatter=None  Beautiful Soup will not modify strings at all on output. This is the fastest option, but it may lead to Beautiful Soup generating invalid HTML/XML.\\nExample 3\\n\\nfrom bs4 import BeautifulSoup\\n\\nfrench = \"<p>Il a dit <<Sacr bleu!>></p>\"\\nsoup = BeautifulSoup(french, \\'html.parser\\')\\nprint (\"minimal: \")\\nprint(soup.prettify(formatter=\"minimal\"))\\nprint (\"html: \")\\nprint(soup.prettify(formatter=\"html\"))\\nprint (\"None: \")\\nprint(soup.prettify(formatter=None))\\n\\nOutput\\n\\nminimal: \\n<p>\\n Il a dit <\\n <sacr bleu!=\"\">\\n  >\\n </sacr>\\n</p>\\nhtml: \\n<p>\\n Il a dit <\\n <sacr bleu!=\"\">\\n  >\\n </sacr>\\n</p>\\nNone: \\n<p>\\n Il a dit <\\n <sacr bleu!=\"\">\\n  >\\n </sacr>\\n</p>\\n\\nBeautiful Soup - encode() Method\\nMethod Description\\nThe encode() method in Beautiful Soup renders a bytestring representation of the given PageElement and its contents.\\nThe prettify() method, which allows to you to easily visualize the structure of the Beautiful Soup parse tree, has the encoding argument. The encode() method plays the same role as the encoding in prettify() method has.\\nSyntax\\n\\nencode(encoding, indent_level, formatter, errors)\\n\\nParameters\\n\\nencoding  The destination encoding.\\nindent_level  Each line of the rendering will be\\nindented this many levels. Used internally in recursive calls while pretty-printing.\\nformatter  A Formatter object, or a string naming one of the standard formatters.\\nerrors  An error handling strategy.\\n\\nReturn Value\\nThe encode() method returns a byte string representation of the tag and its contents.\\nExample 1\\nThe encoding parameter is utf-8 by default. Following code shows the encoded byte string representation of the soup object.\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"Hello World!\", \\'html.parser\\')\\nprint (soup.encode(\\'utf-8\\'))\\n\\nOutput\\n\\nb\\'Hello \\\\xe2\\\\x80\\\\x9cWorld!\\\\xe2\\\\x80\\\\x9d\\'\\n\\nExample 2\\nThe formatter object has the following predefined values \\nformatter=\"minimal\"  This is the default. Strings will only be processed enough to ensure that Beautiful Soup generates valid HTML/XML.\\nformatter=\"html\"  Beautiful Soup will convert Unicode characters to HTML entities whenever possible.\\nformatter=\"html5\"  it\\'s similar to formatter=\"html\", but Beautiful Soup will omit the closing slash in HTML void tags like \"br\".\\nformatter=None  Beautiful Soup will not modify strings at all on output. This is the fastest option, but it may lead to Beautiful Soup generating invalid HTML/XML.\\nIn the following example, different formatter values are used as argument for encode() method.\\n\\nfrom bs4 import BeautifulSoup\\n\\nfrench = \"<p>Il a dit <<Sacr bleu!>></p>\"\\nsoup = BeautifulSoup(french, \\'html.parser\\')\\nprint (\"minimal: \")\\nprint(soup.p.encode(formatter=\"minimal\"))\\nprint (\"html: \")\\nprint(soup.p.encode(formatter=\"html\"))\\nprint (\"None: \")\\nprint(soup.p.encode(formatter=None))\\n\\nOutput\\n\\nminimal: \\nb\\'<p>Il a dit <<Sacr\\\\xc3\\\\xa9 bleu!>></p>\\'\\nhtml:\\nb\\'<p>Il a dit <<Sacr bleu!>></p>\\'\\nNone:\\nb\\'<p>Il a dit <<Sacr\\\\xc3\\\\xa9 bleu!>></p>\\'\\n\\nExample 3\\nThe following example uses Latin-1 as the encoding parameter.\\n\\nmarkup = \\'\\'\\'\\n<html>\\n   <head>\\n      <meta content=\"text/html; charset=ISO-Latin-1\" http-equiv=\"Content-type\" />\\n   </head>\\n   <body>\\n      <p>Sacr`e bleu!</p>\\n   </body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(markup, \\'lxml\\')\\nprint(soup.p.encode(\"latin-1\"))\\n\\nOutput\\n\\nb\\'<p>Sacr`e bleu!</p>\\'\\n\\nBeautiful Soup - decode() Method\\nMethod Description\\nThe decode() method in Beautiful Soup returns a string or Unicode representation of the parse tree as an HTML or XML document. The method decodes the bytes using the codec registered for encoding. Its function is opposite to that of encode() method. You call encode() to get a bytestring, and decode() to get Unicode. Let us study decode() method with some examples.\\nSyntax\\n\\ndecode(pretty_print, encoding, formatter, errors)\\n\\nParameters\\n\\npretty_print  If this is True, indentation will be used to make the document more readable.\\nencoding  The encoding of the final document. If this is None, the document will be a Unicode string.\\nformatter  A Formatter object, or a string naming one of the standard formatters.\\nerrors  The error handling scheme to use for the handling of decoding errors. Values are  \\'strict\\', \\'ignore\\' and \\'replace\\'.\\n\\nReturn Value\\nThe decode() method returns a Unicode String.\\nExample\\n\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(\"Hello World!\", \\'html.parser\\')\\nenc = soup.encode(\\'utf-8\\')\\nprint (enc)\\ndec = enc.decode()\\nprint (dec)\\n\\nOutput\\n\\nb\\'Hello \\\\xe2\\\\x80\\\\x9cWorld!\\\\xe2\\\\x80\\\\x9d\\'\\nHello \"World!\"\\n\\nBeautiful Soup - get_text() Method\\nMethod Description\\nThe get_text() method returns only the human-readable text from the entire HTML document or a given tag. All the child strings are concatenated by the given separator which is a null string by default.\\nSyntax\\n\\nget_text(separator, strip)\\n\\nParameters\\n\\nseparator  The child strings will be concatenated using this parameter. By default it is \"\".\\nstrip  The strings will be stripped before concatenation.\\n\\nReturn Type\\nThe get_Text() method returns a string.\\nExample 1\\nIn the example below, the get_text() method removes all the HTML tags.\\n\\nhtml = \\'\\'\\'\\n<html>\\n<body>\\n   <p> The quick, brown fox jumps over a lazy dog.</p>\\n   <p> DJs flock by when MTV ax quiz prog.</p>\\n   <p> Junk MTV quiz graced by fox whelps.</p>\\n   <p> Bawds jog, flick quartz, vex nymphs.</p>\\n</body>\\n</html>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntext = soup.get_text()\\nprint(text)\\n\\nOutput\\n\\nThe quick, brown fox jumps over a lazy dog.\\nDJs flock by when MTV ax quiz prog.\\nJunk MTV quiz graced by fox whelps.\\nBawds jog, flick quartz, vex nymphs.\\n\\nExample 2\\nIn the following example, we specify the separator argument of get_text() method as \\'#\\'.\\n\\nhtml = \\'\\'\\'\\n   <p>The quick, brown fox jumps over a lazy dog.</p>\\n   <p>DJs flock by when MTV ax quiz prog.</p>\\n   <p>Junk MTV quiz graced by fox whelps.</p>\\n   <p>Bawds jog, flick quartz, vex nymphs.</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntext = soup.get_text(separator=\\'#\\')\\nprint(text)\\n\\nOutput\\n\\n#The quick, brown fox jumps over a lazy dog.#\\n#DJs flock by when MTV ax quiz prog.#\\n#Junk MTV quiz graced by fox whelps.#\\n#Bawds jog, flick quartz, vex nymphs.#\\n\\nExample 3\\nLet us check the effect of strip parameter when it is set to True. By default it is False.\\n\\nhtml = \\'\\'\\'\\n   <p>The quick, brown fox jumps over a lazy dog.</p>\\n   <p>DJs flock by when MTV ax quiz prog.</p>\\n   <p>Junk MTV quiz graced by fox whelps.</p>\\n   <p>Bawds jog, flick quartz, vex nymphs.</p>\\n\\'\\'\\'\\nfrom bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(html, \"html.parser\")\\ntext = soup.get_text(strip=True)\\nprint(text)\\n\\nOutput\\n\\nThe quick, brown fox jumps over a lazy dog.DJs flock by when MTV ax quiz prog.Junk MTV quiz graced by fox whelps.Bawds jog, flick quartz, vex nymphs.\\n\\nBeautiful Soup - diagnose() Method\\nMethod Description\\nThe diagnose() method in Beautiful Soup is a diagnostic suite for isolating common problems. If you\\'re facing difficulty in understanding what Beautiful Soup is doing to a document, pass the document as argument to the diagnose() function. A report showing you how different parsers handle the document, and tell you if you\\'re missing a parser.\\nSyntax\\n\\ndiagnose(data)\\n\\nParameters\\n\\ndata  the document string.\\n\\nReturn Value\\nThe diagnose() method prints the result of parsing the given document according all the available parsers.\\nExample\\nLet us take this simple document for our exercise \\n\\n<h1>Hello World\\n<b>Welcome</b>\\n<P><b>Beautiful Soup</a> <i>Tutorial</i><p>\\n\\nThe following code runs the diagnostics on the above HTML script \\n\\nmarkup = \\'\\'\\'\\n<h1>Hello World\\n<b>Welcome</b>\\n<P><b>Beautiful Soup</a> <i>Tutorial</i><p>\\n\\'\\'\\'\\n\\nfrom bs4.diagnose import diagnose\\n\\ndiagnose(markup)\\n\\nThe diagonose() output starts with a message showing what all parsers are available \\n\\nDiagnostic running on Beautiful Soup 4.12.2\\nPython version 3.11.2 (tags/v3.11.2:878ead1, Feb  7 2023, 16:38:35) [MSC v.1934 64 bit (AMD64)]\\nFound lxml version 4.9.2.0\\nFound html5lib version 1.1\\n\\nIf the document to be diagnosed is a perfect HTML document, the result for all parsers is just about similar. However, in our example, there are many errors.\\nTo begin the built-in html.parser is take up. The report will be as follows \\n\\nTrying to parse your markup with html.parser\\nHere\\'s what html.parser did with the markup:\\n   <h1>\\n      Hello World\\n   <b>\\n      Welcome\\n   </b>\\n   <p>\\n      <b>\\n         Beautiful Soup\\n         <i>\\n            Tutorial\\n         </i>\\n         <p>\\n         </p>\\n      </b>\\n   </p>\\n</h1>\\n\\nYou can see that Python\\'s built-in parser doesn\\'t insert the <html> and <body> tags. The unclosed <h1> tag is provided with matching <h1> at the end.\\nBoth the html5lib and lxml parsers complete the document by wrapping it in <html>, <head> and <body> tags.\\n\\nTrying to parse your markup with html5lib\\nHere\\'s what html5lib did with the markup:\\n<html>\\n   <head>\\n   </head>\\n   <body>\\n      <h1>\\n         Hello World\\n         <b>\\n            Welcome\\n         </b>\\n         <p>\\n            <b>\\n               Beautiful Soup\\n               <i>\\n                  Tutorial\\n               </i>\\n            </b>\\n         </p>\\n         <p>\\n            <b>\\n            </b>\\n         </p>\\n      </h1>\\n   </body>\\n</html>\\n\\nWith lxml parser, note where the closing </h1> is inserted. Also the incomplete <b> tag is rectified, and the dangling </a> is removed.\\n\\nTrying to parse your markup with lxml\\nHere\\'s what lxml did with the markup:\\n<html>\\n   <body>\\n      <h1>\\n         Hello World\\n         <b>\\n            Welcome\\n         </b>\\n      </h1>\\n      <p>\\n         <b>\\n            Beautiful Soup\\n            <i>\\n               Tutorial\\n            </i>\\n         </b>\\n      </p>\\n      <p>\\n      </p>\\n   </body>\\n</html>\\n\\nThe diagnose() method parses the document as XML document also, which probably is superfluous in our case.\\n\\nTrying to parse your markup with lxml-xml\\nHere\\'s what lxml-xml did with the markup:\\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<h1>\\n   Hello World\\n   <b>\\n      Welcome\\n   </b>\\n   <P>\\n      <b>\\n         Beautiful Soup\\n      </b>\\n      <i>\\n         Tutorial\\n      </i>\\n   <p/>\\n   </P>\\n</h1>\\n\\nLet us give the diagnose() method a XML document instead of HTML document.\\n\\n<?xml version=\"1.0\" ?>\\n   <books>\\n      <book>\\n         <title>Python</title>\\n         <author>TutorialsPoint</author>\\n         <price>400</price>\\n      </book>\\n   </books>\\n\\nNow if we run the diagnostics, even if it\\'s a XML, the html parsers are applied.\\n\\nTrying to parse your markup with html.parser\\n\\nWarning (from warnings module):\\n  File \"C:\\\\Users\\\\mlath\\\\OneDrive\\\\Documents\\\\Feb23 onwards\\\\BeautifulSoup\\\\Lib\\\\site-packages\\\\bs4\\\\builder\\\\__init__.py\", line 545\\n    warnings.warn(\\nXMLParsedAsHTMLWarning: It looks like you\\'re parsing an XML document using an HTML parser. If this really is an HTML document (maybe it\\'s XHTML?), you can ignore or filter this warning. If it\\'s XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\\n\\nWith html.parser, a warning message is displayed. With html5lib, the fist line which contains XML version information is commented and rest of the document is parsed as if it is a HTML document.\\n\\nTrying to parse your markup with html5lib\\nHere\\'s what html5lib did with the markup:\\n<!--?xml version=\"1.0\" ?-->\\n<html>\\n   <head>\\n   </head>\\n   <body>\\n      <books>\\n         <book>\\n            <title>\\n               Python\\n            </title>\\n            <author>\\n               TutorialsPoint\\n            </author>\\n            <price>\\n               400\\n            </price>\\n         </book>\\n      </books>\\n   </body>\\n</html>\\n\\nThe lxml html parser doesn\\'t insert the comment, but parses it as HTML.\\n\\nTrying to parse your markup with lxml\\nHere\\'s what lxml did with the markup:\\n<?xml version=\"1.0\" ?>\\n<html>\\n   <body>\\n      <books>\\n         <book>\\n            <title>\\n               Python\\n            </title>\\n            <author>\\n               TutorialsPoint\\n            </author>\\n            <price>\\n               400\\n            </price>\\n         </book>\\n      </books>\\n   </body>\\n</html>\\n\\nThe lxml-xml parser parses the document as XML.\\n\\nTrying to parse your markup with lxml-xml\\nHere\\'s what lxml-xml did with the markup:\\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<?xml version=\"1.0\" ?>\\n   <books>\\n      <book>\\n         <title>\\n            Python\\n         </title>\\n         <author>\\n            TutorialsPoint\\n         </author>\\n         <price>\\n            400\\n         </price>\\n      </book>\\n   </books>\\n\\nThe diagnostics report may prove to be useful in finding errors in HTML/XML documents.\\n\\n\\n\\n      Print Page\\n   \\n\\n\\n\\n\\n      Previous\\n   \\n\\n\\nNext\\n   \\n\\n\\n\\n\\n\\n\\nAdvertisements\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTOP TUTORIALS\\n\\nPython Tutorial\\nJava Tutorial\\nC++ Tutorial\\nC Programming Tutorial\\nC# Tutorial\\nPHP Tutorial\\nR Tutorial\\nHTML Tutorial\\nCSS Tutorial\\nJavaScript Tutorial\\nSQL Tutorial\\n\\n\\n\\nTRENDING TECHNOLOGIES\\n\\nCloud Computing Tutorial\\nAmazon Web Services Tutorial\\nMicrosoft Azure Tutorial\\nGit Tutorial\\n Ethical Hacking Tutorial\\nDocker Tutorial\\nKubernetes Tutorial\\nDSA Tutorial\\nSpring Boot Tutorial\\nSDLC Tutorial\\nUnix Tutorial\\n\\n\\n\\nCERTIFICATIONS\\n\\nBusiness Analytics Certification\\nJava & Spring Boot Advanced Certification\\nData Science Advanced Certification\\nCloud Computing And DevOps\\nAdvanced Certification In Business Analytics\\nArtificial Intelligence And Machine Learning\\nDevOps Certification\\nGame Development Certification\\nFront-End Developer Certification\\nAWS Certification Training\\nPython Programming Certification\\n\\n\\n\\nCOMPILERS & EDITORS\\n\\nOnline Java Compiler\\nOnline Python Compiler\\nOnline Go Compiler\\nOnline C Compiler\\nOnline C++ Compiler\\nOnline C# Compiler\\nOnline PHP Compiler\\nOnline MATLAB Compiler\\nOnline Bash Compiler\\nOnline SQL Compiler\\nOnline Html Editor\\n\\n\\n\\n\\nABOUT US | \\nOUR TEAM | \\nCAREERS | \\nJOBS | \\nCONTACT US | \\nTERMS OF USE | \\nPRIVACY POLICY | \\nREFUND POLICY | \\nCOOKIES POLICY | \\nFAQ\\'S\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTutorials Point is a leading Ed Tech company striving to provide the best learning material on technical and non-technical subjects.\\n\\n Copyright 2024. All Rights Reserved.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
